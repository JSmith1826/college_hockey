{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "\n",
    "## This book parses a box score from collegehockeynews.com ans well as the advanced metrics from the same game\n",
    "# The seperate elements of the game box score are stored in a list of dataframes\n",
    "# the dataframes are then stored in a dictionary and output as a json file\n",
    "\n",
    "# Example box score link\n",
    "url_box = 'https://www.collegehockeynews.com/box/final/20230211/mic/msu/'\n",
    "\n",
    "# Example metrics link from same game\n",
    "url_metrics = 'https://www.collegehockeynews.com/box/metrics.php?gd=96398'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# PARSEING SCORING SUMMARY WITH BS4\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Get the HTML content\n",
    "# url_box = 'your_url_here'  # Replace this with your URL\n",
    "response = requests.get(url_box)\n",
    "html_content = response.text\n",
    "\n",
    "def parse_scoring_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the scoring div and table\n",
    "    scoring_div = soup.find('div', id='scoring')\n",
    "    if scoring_div is None:\n",
    "        return \"Scoring div not found\"\n",
    "\n",
    "    scoring_table = scoring_div.find('table')\n",
    "    if scoring_table is None:\n",
    "        return \"Scoring table not found\"\n",
    "\n",
    "    # Initialize list to store scoring events\n",
    "    scoring_events = []\n",
    "    period = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in scoring_table.find_all('tr'):\n",
    "        if 'stats-section' in row.get('class', []):\n",
    "            period = row.find('td').text.strip()\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                team = cols[0].text.strip()\n",
    "                pp = cols[1].text.strip()\n",
    "\n",
    "                player_data = cols[3].text.strip()\n",
    "                match = re.match(r\"(.+)\\s\\((\\d+)\\)\", player_data)\n",
    "                if match:\n",
    "                    player = match.group(1)\n",
    "                    goals = int(match.group(2))\n",
    "                else:\n",
    "                    player = player_data\n",
    "                    goals = None\n",
    "\n",
    "                assist_data = cols[4].text.strip().split(\", \")\n",
    "                assist1 = assist_data[0] if len(assist_data) > 0 else None\n",
    "                assist2 = assist_data[1] if len(assist_data) > 1 else None\n",
    "\n",
    "                time = cols[5].text.strip()\n",
    "\n",
    "                scoring_event = {\n",
    "                    'Period': period,\n",
    "                    'Team': team,\n",
    "                    'PP': pp,\n",
    "                    'Player': player,\n",
    "                    'Player_Goals': goals,\n",
    "                    'Assist1': assist1,\n",
    "                    'Assist2': assist2,\n",
    "                    'Time': time\n",
    "                }\n",
    "                scoring_events.append(scoring_event)\n",
    "\n",
    "    return scoring_events\n",
    "\n",
    "# # Parse the scoring summary and convert it to a DataFrame\n",
    "# scoring_summary = parse_scoring_summary(html_content)\n",
    "# df = pd.DataFrame(scoring_summary)\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Parse Penalty Summary WITH BS4 #######\n",
    "def parse_penalty_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the penalties div and table (assuming the structure is similar to the scoring section)\n",
    "    penalties_div = soup.find('div', id='penalties')\n",
    "    if penalties_div is None:\n",
    "        return \"Penalties div not found\"\n",
    "\n",
    "    penalties_table = penalties_div.find('table')\n",
    "    if penalties_table is None:\n",
    "        return \"Penalties table not found\"\n",
    "\n",
    "    # Initialize list to store penalty events\n",
    "    penalty_events = []\n",
    "    period = None\n",
    "    \n",
    "    # Loop through table rows\n",
    "    for row in penalties_table.find_all('tr'):\n",
    "        if 'stats-section' in row.get('class', []):\n",
    "            period = row.find('td').text.strip()\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                team = cols[0].text.strip()\n",
    "                player = cols[1].text.strip()\n",
    "                pen_length = cols[2].text.strip()\n",
    "                penalty_type = cols[3].text.strip()\n",
    "                time = cols[4].text.strip()\n",
    "\n",
    "                penalty_event = {\n",
    "                    'Period': period,\n",
    "                    'Team': team,\n",
    "                    'Player': player,\n",
    "                    'Pen_Length': pen_length,\n",
    "                    'Penalty_Type': penalty_type,\n",
    "                    'Time': time\n",
    "                }\n",
    "                penalty_events.append(penalty_event)\n",
    "\n",
    "    return penalty_events\n",
    "\n",
    "# # Use the function and convert the result to a DataFrame\n",
    "# penalty_summary = parse_penalty_summary(html_content)\n",
    "# df_penalties = pd.DataFrame(penalty_summary)\n",
    "# # print(df_penalties)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_goalie_stats(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the goalies div and table\n",
    "    goalies_div = soup.find('div', id='goalies')\n",
    "    if goalies_div is None:\n",
    "        return \"Goalies div not found\"\n",
    "\n",
    "    goalies_table = goalies_div.find('table')\n",
    "    if goalies_table is None:\n",
    "        return \"Goalies table not found\"\n",
    "\n",
    "    # Initialize list to store goalie stats\n",
    "    goalie_stats = []\n",
    "    team = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in goalies_table.find_all('tr'):\n",
    "        if 'stats-header' in row.get('class', []):\n",
    "            team = row.find('td').text.strip()\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                goalie = cols[0].text.strip()\n",
    "                sv = cols[1].text.strip()\n",
    "                ga = cols[2].text.strip()\n",
    "                minutes = cols[3].text.strip()\n",
    "\n",
    "                goalie_stat = {\n",
    "                    'Team': team,\n",
    "                    'Goalie': goalie,\n",
    "                    'SV': sv,\n",
    "                    'GA': ga,\n",
    "                    'Minutes': minutes\n",
    "                }\n",
    "                goalie_stats.append(goalie_stat)\n",
    "\n",
    "    return goalie_stats\n",
    "\n",
    "# # Use the function and convert the result to a DataFrame\n",
    "# goalie_stats_data = parse_goalie_stats(html_content)\n",
    "# df_goalie_stats = pd.DataFrame(goalie_stats_data)\n",
    "# print(df_goalie_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PARSE PLAYER STATS TABLE ####\n",
    "def parse_player_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the playersums div\n",
    "    playersums_div = soup.find('div', id='playersums')\n",
    "    if playersums_div is None:\n",
    "        return \"Player summaries div not found\"\n",
    "\n",
    "    # Initialize list to store player stats\n",
    "    player_stats = []\n",
    "\n",
    "    # Loop through each playersum div\n",
    "    for player_sum in playersums_div.find_all('div', class_='playersum'):\n",
    "        team = player_sum.find('td').text.strip()\n",
    "        \n",
    "        # Loop through table rows\n",
    "        for row in player_sum.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                player = cols[0].text.strip()\n",
    "                goals = cols[1].text.strip()\n",
    "                assists = cols[2].text.strip()\n",
    "                points = cols[3].text.strip()\n",
    "                plus_minus = cols[4].text.strip()\n",
    "                shots = cols[5].text.strip()\n",
    "                pim = cols[6].text.strip()\n",
    "                fowl = cols[7].text.strip() if len(cols) > 7 else None\n",
    "                \n",
    "                fow, fol = None, None\n",
    "                win_percentage = None\n",
    "                \n",
    "                \n",
    "\n",
    "                try:\n",
    "                    if fowl and '‑' in fowl:  # Checking if it contains a hyphen\n",
    "                        fow, fol = map(int, fowl.split('‑'))\n",
    "                        total_fo = fow + fol\n",
    "                        win_percentage = (fow / total_fo) * 100 if total_fo > 0 else 0\n",
    "                except ValueError:\n",
    "                    fow, fol, win_percentage = None, None, None\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                player_stat = {\n",
    "                    'Team': team,\n",
    "                    'Player': player,\n",
    "                    'G': goals,\n",
    "                    'A': assists,\n",
    "                    'Pt.': points,\n",
    "                    '+/-': plus_minus,\n",
    "                    'Sh': shots,\n",
    "                    'PIM': pim,\n",
    "                    'FOW': fow,\n",
    "                    'FOL': fol,\n",
    "                    'FO%': win_percentage\n",
    "                }\n",
    "                player_stats.append(player_stat)\n",
    "\n",
    "    return player_stats\n",
    "\n",
    "# # Use the function and convert the result to a DataFrame\n",
    "# player_stats_data = parse_player_summary(html_content)\n",
    "# df_player_stats = pd.DataFrame(player_stats_data)\n",
    "# # print(df_player_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def parse_advanced_metrics_tables(html_content):\n",
    "    # Initialize list to store DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Parse HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table', {'class': 'sortable metrics'})\n",
    "    \n",
    "    for table in tables:\n",
    "        # Initialize list to store column names and data\n",
    "        col_names = []\n",
    "        col_names_final = []\n",
    "        data = []\n",
    "        \n",
    "        # Get headers\n",
    "        headers = table.find_all('th')\n",
    "        for header in headers:\n",
    "            col_names.append(header.text)\n",
    "        \n",
    "        # Add TOTAL, EVEN STRENGTH, POWER PLAY, CLOSE to column names\n",
    "        section_headers = ['TOTAL', 'EVEN STRENGTH', 'POWER PLAY', 'CLOSE']\n",
    "        for col in col_names:\n",
    "            for section in section_headers:\n",
    "                if col in section_headers:\n",
    "                    temp_col = section\n",
    "                else:\n",
    "                    temp_col = f\"{section}_{col}\"\n",
    "            col_names_final.append(temp_col)\n",
    "        \n",
    "        print(f\"Length of final column names: {len(col_names_final)}\")  # Debug statement\n",
    "        \n",
    "        # Get data rows\n",
    "        rows = table.find_all('tr')[2:]  # skip header rows\n",
    "        for row in rows:\n",
    "            row_data = []\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "        \n",
    "        print(f\"Length of first row of data: {len(data[0])}\")  # Debug statement\n",
    "        \n",
    "        # Create DataFrame and append to list\n",
    "        df = pd.DataFrame(data, columns=col_names_final)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "# Placeholder for your actual HTML content\n",
    "# html_metrics_sample = '''...'''  # Replace with actual HTML content\n",
    "\n",
    "# Get the HTML content\n",
    "# url_metrics = 'https://www.collegehockeynews.com/box/metrics.php?gd=96211'  # Replace this with your URL\n",
    "# response = requests.get(url_metrics)\n",
    "# html_metrics_sample = response.text\n",
    "\n",
    "# # Parse and convert to DataFrames\n",
    "# # This will return a list of DataFrames, one for each team\n",
    "# # dfs[0] will be the DataFrame for the first team, dfs[1] for the second team\n",
    "# dfs = parse_advanced_metrics_tables(html_metrics_sample)\n",
    "\n",
    "# # To check the DataFrame for the first team\n",
    "# dfs[0].head()\n",
    "# dfs[1].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code for parsing the line chart information with specific positions for forwards and defensemen.\n",
    "\n",
    "\n",
    "def parse_line_chart(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    line_chart_div = soup.find('div', id='linechart')\n",
    "\n",
    "    line_data = []\n",
    "\n",
    "    for team_div in line_chart_div.find_all('div', recursive=False):\n",
    "        team_name = team_div.find('h3').text.strip()\n",
    "        for line_type_div in team_div.find_all('div', recursive=False):\n",
    "            line_type = line_type_div.get('class')[0]\n",
    "            if line_type == 'f':\n",
    "                position_types = ['Left Wing', 'Center', 'Right Wing']\n",
    "            elif line_type == 'd':\n",
    "                position_types = ['Left D', 'Right D']\n",
    "            elif line_type == 'x':\n",
    "                position_types = ['Extra']\n",
    "            elif line_type == 'g':\n",
    "                position_types = ['Goalie']\n",
    "                goalie_count = 1  # Initialize goalie count\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            players = line_type_div.find_all('div')\n",
    "            for i, player in enumerate(players):\n",
    "                player_name = player.text.strip()\n",
    "                # Remove (F) or (D) from extras\n",
    "                if line_type == 'x':\n",
    "                    player_name = player_name.split(' ')[0]\n",
    "                # Assign a line to goalies\n",
    "                if line_type == 'g':\n",
    "                    line_number = f\"Goalie {goalie_count}\"\n",
    "                    goalie_count += 1  # Increment goalie count\n",
    "                else:\n",
    "                    line_number = i // len(position_types) + 1\n",
    "\n",
    "                position = position_types[i % len(position_types)]\n",
    "                line_data.append({\n",
    "                    'Team': team_name,\n",
    "                    'Line': line_number,\n",
    "                    'Position': position,\n",
    "                    'Player': player_name\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(line_data)\n",
    "\n",
    "\n",
    "# # Use the function and convert the result to a DataFrame\n",
    "# line_chart_data = parse_line_chart(html_content)\n",
    "# df_line_chart = pd.DataFrame(line_chart_data)\n",
    "# df_line_chart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the Linescore Elements - Score, shots, ect by period####\n",
    "\n",
    "def parse_linescore(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    linescore_data = []\n",
    "    \n",
    "    # Parsing the Goals table\n",
    "    goals_table = soup.select_one(\"#goals table\")\n",
    "    rows = goals_table.select('tbody tr')\n",
    "    for row in rows:\n",
    "        team_data = {}\n",
    "        team_data['Team'] = row.select_one('td').text\n",
    "        goals = row.select('td')[1:]\n",
    "        for i, goal in enumerate(goals):\n",
    "            team_data[f'goals{i+1}' if i < len(goals) - 1 else 'goalsT'] = int(goal.text)\n",
    "        \n",
    "        linescore_data.append(team_data)\n",
    "    \n",
    "    # Parsing the Shots table\n",
    "    shots_table = soup.select_one(\"#shots table\")\n",
    "    rows = shots_table.select('tbody tr')\n",
    "    for i, row in enumerate(rows):\n",
    "        shots = row.select('td')[1:]\n",
    "        for j, shot in enumerate(shots):\n",
    "            linescore_data[i][f'shots{j+1}' if j < len(shots) - 1 else 'shotsT'] = int(shot.text.strip())\n",
    "    \n",
    "    # Parsing the PP table\n",
    "    pp_table = soup.select_one(\"#pp table\")\n",
    "    rows = pp_table.select('tbody tr')\n",
    "    for i, row in enumerate(rows):\n",
    "        pen_pim = row.select('td')[1].text.split('‑')\n",
    "        linescore_data[i]['Pen'] = int(pen_pim[0])\n",
    "        linescore_data[i]['PIM'] = int(pen_pim[1])\n",
    "        \n",
    "        ppg_ppo = row.select('td')[2].text.split('‑')\n",
    "        linescore_data[i]['PPG'] = int(ppg_ppo[0])\n",
    "        linescore_data[i]['PPO'] = int(ppg_ppo[1])\n",
    "        \n",
    "        fow_fol = row.select('td')[3].text.split('‑')\n",
    "        linescore_data[i]['FOW'] = int(fow_fol[0])\n",
    "        linescore_data[i]['FOL'] = int(fow_fol[1])\n",
    "        linescore_data[i]['FOW%'] = (linescore_data[i]['FOW'] / (linescore_data[i]['FOW'] + linescore_data[i]['FOL'])) * 100\n",
    "        \n",
    "    return pd.DataFrame(linescore_data)\n",
    "\n",
    "\n",
    "\n",
    "# # Use the function and get the DataFrame\n",
    "# df_linescore = parse_linescore(html_content)\n",
    "# df_linescore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Details</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ref1</th>\n",
       "      <th>Ref2</th>\n",
       "      <th>Asst_Ref1</th>\n",
       "      <th>Asst_Ref2</th>\n",
       "      <th>Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>February 11, 2023</td>\n",
       "      <td>Big Ten Game</td>\n",
       "      <td>Duel in the D</td>\n",
       "      <td>Little Caesars Arena, Detroit, Mich.</td>\n",
       "      <td>Jake Rekucki</td>\n",
       "      <td>Andrew Bruggeman</td>\n",
       "      <td>Bill Hancock</td>\n",
       "      <td>Jonathan Morrison</td>\n",
       "      <td>18325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day               Date    Conference        Details  \\\n",
       "0  Saturday  February 11, 2023  Big Ten Game  Duel in the D   \n",
       "\n",
       "                               Location          Ref1              Ref2  \\\n",
       "0  Little Caesars Arena, Detroit, Mich.  Jake Rekucki  Andrew Bruggeman   \n",
       "\n",
       "      Asst_Ref1          Asst_Ref2  Attendance  \n",
       "0  Bill Hancock  Jonathan Morrison       18325  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to parse game details\n",
    "\n",
    "def parse_game_details(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # Find the correct div\n",
    "    meta_div = soup.find('div', {'id': 'meta'})\n",
    "    game_details_div = meta_div.find_all('div')[-1]\n",
    "    \n",
    "    # Get the date and day of the week\n",
    "    date_str = game_details_div.h4.string\n",
    "    day_of_week, date = date_str.split(\", \", 1)\n",
    "    \n",
    "    # Get conference, details, and location\n",
    "    p_elements = game_details_div.find_all('p')\n",
    "    details_strs = p_elements[0].get_text(separator='|').split('|')\n",
    "    \n",
    "    conference = details_strs[0]\n",
    "    location = details_strs[-1].split('at ')[-1]\n",
    "    details = details_strs[1] if len(details_strs) > 2 else None\n",
    "    \n",
    "    # Get referees and attendance\n",
    "    refs_str = p_elements[1].strong.next_sibling\n",
    "    asst_refs_str = p_elements[1].find_all('strong')[1].next_sibling\n",
    "    attendance_str = p_elements[1].find_all('strong')[2].next_sibling\n",
    "    \n",
    "    refs = refs_str.split(', ')\n",
    "    asst_refs = asst_refs_str.split(', ')\n",
    "    # remove non letter characters and strip whitespace\n",
    "    refs = [re.sub(r'[^a-zA-Z ]+', '', ref).strip() for ref in refs]\n",
    "    asst_refs = [re.sub(r'[^a-zA-Z ]+', '', ref).strip() for ref in asst_refs]\n",
    "    \n",
    "    attendance = attendance_str.split(\": \")[-1]\n",
    "    # remove commas and convert to int\n",
    "    attendance = int(attendance.replace(',', ''))\n",
    "\n",
    "    # stripe line breaks ect from the Details\n",
    "    details = details.replace('\\n', '').strip()\n",
    "    details = re.sub('\\t', ' ', details)\n",
    "    \n",
    "    \n",
    "    game_details = {\n",
    "        'Day': day_of_week,\n",
    "        'Date': date,\n",
    "        'Conference': conference,\n",
    "        'Details': details,\n",
    "        'Location': location,\n",
    "        'Ref1': refs[0],\n",
    "        'Ref2': refs[1] if len(refs) > 1 else None,\n",
    "        'Asst_Ref1': asst_refs[0],\n",
    "        'Asst_Ref2': asst_refs[1] if len(asst_refs) > 1 else None,\n",
    "        'Attendance': attendance\n",
    "    }\n",
    "    \n",
    "    return game_details\n",
    "\n",
    "# # Parse and convert to DataFrame\n",
    "game_details = parse_game_details(html_content)\n",
    "df_game_details = pd.DataFrame([game_details])\n",
    "\n",
    "df_game_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of final column names: 23\n",
      "Length of first row of data: 23\n",
      "Length of final column names: 23\n",
      "Length of first row of data: 23\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\college_hockey\\workbook\\scratch book.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         json\u001b[39m.\u001b[39mdump(all_data_dict, f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Assuming full_score_df contains all your DataFrames\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m save_data_as_json(full_score_df)\n",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\college_hockey\\workbook\\scratch book.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m keys \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mscoring_summary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpenalty_summary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgoalie_stats\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mplayer_stats\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mline_chart\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlinescore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgame_details\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, df \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(keys, all_dfs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     all_data_dict[key] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mto_dict(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mall_game_data.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#X23sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(all_data_dict, f)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def parse_box_score(box_score_html):\n",
    "    # Parse box score into DataFrames\n",
    "    \n",
    "    scoring_summary = parse_scoring_summary(box_score_html)\n",
    "    penalty_summary = parse_penalty_summary(box_score_html)\n",
    "    goalie_stats = parse_goalie_stats(box_score_html)\n",
    "    player_stats = parse_player_summary(box_score_html)\n",
    "    line_chart = parse_line_chart(box_score_html)\n",
    "    linescore = parse_linescore(box_score_html)\n",
    "    game_details = parse_game_details(box_score_html)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Combine DataFrames into a list\n",
    "    all_dfs = [game_details, scoring_summary, penalty_summary, goalie_stats, player_stats, line_chart, linescore]\n",
    "    \n",
    "\n",
    "    \n",
    "    return all_dfs\n",
    "\n",
    "def fetch_and_save_data(box_score_url, advanced_metrics_url):\n",
    "    # Fetch HTML content for box score\n",
    "    box_score_response = requests.get(box_score_url)\n",
    "    box_score_html = box_score_response.text\n",
    "    \n",
    "    # Fetch HTML content for advanced metrics\n",
    "    advanced_metrics_response = requests.get(advanced_metrics_url)\n",
    "    advanced_metrics_html = advanced_metrics_response.text\n",
    "    \n",
    "    # Parse box score into DataFrame\n",
    "    box_score_df = parse_box_score(box_score_html)\n",
    "    \n",
    "    # Parse advanced metrics into list of DataFrames\n",
    "    advanced_metrics_dfs = parse_advanced_metrics_tables(advanced_metrics_html)\n",
    "    \n",
    "    # Combine all DataFrames into a list\n",
    "    full_score_df = [box_score_df] + advanced_metrics_dfs\n",
    "    \n",
    "\n",
    "    return full_score_df\n",
    "\n",
    "# Replace with actual URLs\n",
    "box_score_url = 'https://www.collegehockeynews.com/box/final/20230211/mic/msu/'\n",
    "advanced_metrics_url = 'https://www.collegehockeynews.com/box/metrics.php?gd=96211'\n",
    "\n",
    "# Fetch, parse, and save data\n",
    "full_score_df = fetch_and_save_data(box_score_url, advanced_metrics_url)\n",
    "\n",
    "import json\n",
    "\n",
    "def save_data_as_json(all_dfs):\n",
    "    all_data_dict = {}\n",
    "    keys = ['scoring_summary', 'penalty_summary', 'goalie_stats', 'player_stats', 'line_chart', 'linescore', 'game_details']\n",
    "    \n",
    "    for key, df in zip(keys, all_dfs):\n",
    "        all_data_dict[key] = df.to_dict(orient='split')\n",
    "        \n",
    "    with open('all_game_data.json', 'w') as f:\n",
    "        json.dump(all_data_dict, f)\n",
    "\n",
    "# Assuming full_score_df contains all your DataFrames\n",
    "save_data_as_json(full_score_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[5]\n",
    "\n",
    "# keep first four columns drop the rest\n",
    "df = df.iloc[:,0:4]\n",
    "\n",
    "# output to csv\n",
    "df.to_csv('../TEMP/goalie_score_example.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables[4]\n",
    "\n",
    "# df = tables[4].copy()\n",
    "# # save TEMP file\n",
    "# # df.to_csv('../TEMP/box_score_example.csv')\n",
    "\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_penalty_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\college_hockey\\workbook\\scratch book.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m tables[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## Test code\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m clean_penalty_summary(df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/scratch%20book.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_penalty_summary' is not defined"
     ]
    }
   ],
   "source": [
    "df = tables[4].copy()\n",
    "\n",
    "## Test code\n",
    "df = clean_penalty_summary(df)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
