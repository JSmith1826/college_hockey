{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Score Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Links\n",
    "\n",
    "### All of these metrics were created and scaled to approximate a corilation to Points in a game. \n",
    "Inspired by this article I found about a metric that was developed in 2016, Dom Luszczyszyn which is intended to provide a single number that approximates a player’s performance in a given game. In that original story, he included the formula for the metric and how he arrived at it, so it’s inspired various adaptations since then.\n",
    "https://hockey-graphs.com/2016/07/13/measuring-single-game-productivity-an-introduction-to-game-score/\n",
    "\n",
    "The stats I used are goals, primary assists, secondary assists, shots on goal, blocked shots, penalty differential, faceoffs, 5-on-5 corsi differential, 5-on-5 goal differential.\n",
    "\n",
    "Player Game Score = (0.75 * G) + (0.7 * A1) + (0.55 * A2) + (0.075 * SOG) + (0.05 * BLK) + (0.15 * PD) – (0.15 * PT) + (0.01 * FOW) – (0.01 * FOL) + (0.05 * CF) – (0.05 * CA) + (0.15 * GF) – (0.15* GA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted / Simplified\n",
    "- found on the blog frshice.substack.com\n",
    "- Bailey Johnson created her simplified version to work on college hockey data because not all of the factors (specifically the defensive portion of the Corsi Metric) is not track or is not available for NCAA games\n",
    "\n",
    "### Original\n",
    "For clarity’s sake, this was my original formula after removing stats I didn’t have access to from Dom’s: Player Game Score = (0.75*G)+(0.7*A1)+(0.55*A2)+(0.075*SOG)+(0.05*BLK)+(0.01*FOW)–(0.01*FOL)+(0.15*GF)–(0.15*GA)\n",
    "\n",
    "### Bailey Final\n",
    "- I also followed Shawn’s method from his NWHL game score work and used league-wide power-play percentage to weight the impact of taking a penalty.\n",
    "\n",
    "- Dom scaled his formula down 75% to make the game scores roughly equivalent to points so people would be familiar with what the game score represented, and I kept to that methodology here because I used some of the same weights he did. Also keep in mind that the goals for and goals against are just goals scored at even strength — it does not include special teams, empty-net or extra-attacker goals.\n",
    "\n",
    "Player Game Score = (G*0.75)+(A1*0.715)+(A2*0.555)+(SOG*0.075)+(BLK*0.05)+(FOW*0.01)-(FOL*0.01)+(GF*0.15)-(GA*0.15)-(PNT*0.138)\n",
    "\n",
    "### PNT*.138\n",
    "- FROM SOURCE: I took the frequency of powerplay goals to penalties, otherwise known as PP%. (https://hockey-graphs.com/2018/03/22/an-introduction-to-nwhl-game-score/)\n",
    "- this is her attempt to account for penalties - CHN NCAA stats don't include penalties drawn \n",
    "- PNT is penalties taken so I will want to grab the penalty incidents, not the minutes. \n",
    "- The 0.138 factor come from the league's power play percentage \n",
    "    - Want to use a static figure like overall average PP % for entire NCAA \n",
    "        - could update it to be dynamic and create a new average every time the data is called\n",
    "\n",
    "        - IDEA: Could create a custom factor for each team in each game \n",
    "            - teams power play effectiveness can vary greatly, as can a teams PK%\n",
    "            - Take the each teams previous success on PP or even on both PP and PK\n",
    "            - Compare to NCAA wide average\n",
    "            - get a factor that could be used and could scale the danger of taking a penalty based on how good the opponent is on PP or how poor your team is on PP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blocking out the Game Score formula\n",
    "\n",
    "#### METRIC Formula\n",
    "# \n",
    "# METRIC = SCORE [ (Goals*0.75) + (Assist1*0.715) + (Assist2*0.555) ] \n",
    "#               + SHOTS [ (Shot_On_Net*0.075) + (Shots_Off_Net*0.075) - (Shots_Blocked*0.075) ]\n",
    "#               + FACEOFFS [ (Faceoff_Wins*0.01) - (Faceoff_Losses*0.01) ]\n",
    "#               + TEAM [ (Goals_For_Team*0.15) + (Goals_Against_Team*0.15) ]\n",
    "#               -  [ (Penalties_Taken * Overall_PP_Success_Rate) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map to each factor in the Game_Stats Database\n",
    "\n",
    "## Calculating a Game Score for each player on each team for each game\n",
    "Each Game has a unique Game_ID column in every relevant table\n",
    "\n",
    "scoring_summary table\n",
    "    Goals - in scoring_summary - count of player's name in Player Column\n",
    "    Assist1 - scoring_summary - Count in Assist1\n",
    "    Assist2 - scoring_summary - Count in Assist2\n",
    "\n",
    "\n",
    "abdvanced_metrics_combined table\n",
    "    Shots_On_Net -  - EVEN_Saved + EVEN_Goals\n",
    "    Shots_Off_Net = EVENE_Miss\n",
    "    Shots_Blocked = EVEN_Block\n",
    "\n",
    "    Defensive_Blocks = D_Blocks\n",
    "\n",
    "player_stats\n",
    "    Faceoff_Wins = FO_W\n",
    "    Faceoff_Loses = FO_L\n",
    "\n",
    "### This takes into account team goals for and goals against but only counts Even strength goals in close games (+/- 1)\n",
    "- can get it from the advanced metrics combined\n",
    "\n",
    "advanced_metrics_\n",
    "    Goals_For_Team = SUM of CLOSE_Goals grouped by Team -NOTE\n",
    "#### NOTE- need to filter out any rows in the advanced_metrics_combined with player = 'TOTAL'\n",
    "    Goals_Against_Team - do the same but for the opposing team - if Game_ID matches and Team =/= the player's team\n",
    "\n",
    "penalty_summary\n",
    "    Penalties_Taken = Count of Player's name in \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "db_path ='../data/2023_YTD_Game_Stats.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "\n",
    "# Connect to the provided database\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve the list of tables in the database\n",
    "tables = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "tables = [table[0] for table in tables]\n",
    "\n",
    "# Retrieve the columns from each table to get a better understanding of the data structure\n",
    "table_columns = {}\n",
    "for table in tables:\n",
    "    columns = cursor.execute(f\"PRAGMA table_info({table});\").fetchall()\n",
    "    table_columns[table] = [column[1] for column in columns]\n",
    "\n",
    "# table_columns\n",
    "\n",
    "\n",
    "# Create an empty dataframe to store the data\n",
    "compiled_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the code to clean the 'advanced_metrics_combined' table by removing 'TOTAL' rows\n",
    "\n",
    "# Load the 'advanced_metrics_combined' table into a DataFrame excluding 'TOTAL' rows\n",
    "df_amc = pd.read_sql(\"SELECT * FROM advanced_metrics_combined WHERE player != 'TOTAL'\", conn)\n",
    "\n",
    "# Convert columns to numeric for calculations (replacing empty strings with 0)\n",
    "columns_to_convert = ['EVEN_Saved', 'EVEN_Goals', 'EVEN_Miss', 'EVEN_Block', 'D_Blocks']\n",
    "for col in columns_to_convert:\n",
    "    df_amc[col] = pd.to_numeric(df_amc[col].replace('', '0'))\n",
    "\n",
    "# Calculate required columns\n",
    "df_amc['Shots_On_Net'] = df_amc['EVEN_Saved'] + df_amc['EVEN_Goals']\n",
    "df_amc['Shots_Off_Net'] = df_amc['EVEN_Miss']\n",
    "df_amc['Shots_Blocked'] = df_amc['EVEN_Block']\n",
    "df_amc['Defensive_Blocks'] = df_amc['D_Blocks']\n",
    "\n",
    "# Create a DataFrame with only the desired columns\n",
    "# shots_df = df_amc[['Player', 'Team', 'Shots_On_Net', 'Shots_Off_Net', 'Shots_Blocked', 'Defensive_Blocks', 'Game_ID']]\n",
    "\n",
    "# Create a DataFrame with only the desired columns - LEAVE OFF TEAM AND TRY TO ADD IT LATER\n",
    "shots_df = df_amc[['Player', 'Team', 'Shots_On_Net', 'Shots_Off_Net', 'Shots_Blocked', 'Defensive_Blocks', 'Game_ID']]\n",
    "\n",
    "# Display the column names of the shots_df\n",
    "shots_df.columns\n",
    "\n",
    "shots_df.head(25)\n",
    "\n",
    "# Merge into the compiled_df\n",
    "compiled_df = shots_df.copy()\n",
    "\n",
    "# # Team Name Split\n",
    "# team_name_split = compiled_df['Game_ID'].str.split('-').str[-2:]\n",
    "# compiled_df['Temp_Team_1'] = team_name_split.str[0]\n",
    "# compiled_df['Temp_Team_2'] = team_name_split.str[1]\n",
    "\n",
    "# # If Home/Away is Away Then Team is Temp_Team_1\n",
    "# # If Home/Away is Home Then Team is Temp_Team_2\n",
    "# compiled_df['Team'] = np.where(compiled_df['Home/Away'] == 'Away', compiled_df['Temp_Team_1'], compiled_df['Temp_Team_2'])\n",
    "\n",
    "# # Drop Temp Columns\n",
    "# compiled_df.drop(['Temp_Team_1', 'Temp_Team_2'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "compiled_df.head(45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Master_Roster To Get Player to Team Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## See column names from master_roster table\n",
    "# cursor.execute(\"SELECT * FROM master_roster\")\n",
    "# col_names = [description[0] for description in cursor.description]\n",
    "# col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting all the player names from the master_roster table\n",
    "# all_player_names_master_roster = set(pd.read_sql(\"SELECT Clean_Name FROM master_roster\", conn)['Clean_Name'])\n",
    "\n",
    "# # Finding the intersection of player names between compiled_df and master_roster\n",
    "# common_names = set(compiled_df['Player']).intersection(all_player_names_master_roster)\n",
    "\n",
    "# # Take out those annoying character if there are any\n",
    "# # Replace non-breaking spaces with regular spaces in the player names\n",
    "# compiled_df['Player'] = compiled_df['Player'].str.replace(u'\\xa0', u' ')\n",
    "\n",
    "\n",
    "# # Finding names in compiled_df that are not in master_roster\n",
    "# missing_names = set(compiled_df['Player']) - all_player_names_master_roster\n",
    "\n",
    "# len(common_names), len(missing_names), list(missing_names)[:10]  # Displaying the first 10 missing names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a DataFrame with the missing names\n",
    "# missing_names_df = compiled_df[compiled_df['Player'].isin(missing_names)]\n",
    "\n",
    "# missing_names_df.head(25)\n",
    "\n",
    "# ## unique Game_IDs in the missing_names_df\n",
    "# missing_names_df['Game_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many Nan Values are there in the Team Column?\n",
    "compiled_df['Team'].isna().sum()\n",
    "\n",
    "# Value Count of the Team Column\n",
    "# compiled_df['Team'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Goal, Assist1 and Assist2\n",
    "- Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separately calculate Goals, Assist1, and Assist2\n",
    "\n",
    "# Goals\n",
    "goals_df = pd.read_sql(\"\"\"\n",
    "SELECT \n",
    "    Player,\n",
    "    Game_ID,\n",
    "    COUNT(Player) AS Goals\n",
    "FROM \n",
    "    scoring_summary\n",
    "GROUP BY \n",
    "    Player, Game_ID;\n",
    "\"\"\", conn)\n",
    "\n",
    "# Assist1\n",
    "assist1_df = pd.read_sql(\"\"\"\n",
    "SELECT \n",
    "    Assist1 AS Player,\n",
    "    Game_ID,\n",
    "    COUNT(Assist1) AS Assist1\n",
    "FROM \n",
    "    scoring_summary\n",
    "WHERE \n",
    "    Assist1 IS NOT NULL AND Assist1 != ''\n",
    "GROUP BY \n",
    "    Assist1, Game_ID;\n",
    "\"\"\", conn)\n",
    "\n",
    "# Assist2\n",
    "assist2_df = pd.read_sql(\"\"\"\n",
    "SELECT \n",
    "    Assist2 AS Player,\n",
    "    Game_ID,\n",
    "    COUNT(Assist2) AS Assist2\n",
    "FROM \n",
    "    scoring_summary\n",
    "WHERE \n",
    "    Assist2 IS NOT NULL AND Assist2 != ''\n",
    "GROUP BY \n",
    "    Assist2, Game_ID;\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# goals_df.head(25)\n",
    "# Merge the dataframes together\n",
    "merged_df = goals_df.merge(assist1_df, on=['Player', 'Game_ID'], how='outer')\n",
    "merged_df = merged_df.merge(assist2_df, on=['Player', 'Game_ID'], how='outer')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "# Convert columns to int\n",
    "merged_df['Goals'] = merged_df['Goals'].astype(int)\n",
    "merged_df['Assist1'] = merged_df['Assist1'].astype(int)\n",
    "merged_df['Assist2'] = merged_df['Assist2'].astype(int)\n",
    "\n",
    "# # Sort by Player\n",
    "goal_assist_df = merged_df.sort_values(by=['Player'])\n",
    "\n",
    "# # Display the first few rows\n",
    "goal_assist_df.head(20)\n",
    "\n",
    "\n",
    "\n",
    "# # Merge the Goal and Assist info into the compiled_df join left\n",
    "# compiled_df = pd.merge(compiled_df, goal_assist_df, on=['Player', 'Game_ID'], how='outer')\n",
    "\n",
    "\n",
    "compiled_df.sample(10)\n",
    "compiled_df.info()\n",
    "\n",
    "\n",
    "\n",
    "# # Histogram of the compiled_df\n",
    "# compiled_df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Value count of Teams\n",
    "compiled_df['Team'].value_counts()\n",
    "\n",
    "# How many Nan Values are there in the Team Column?\n",
    "compiled_df['Team'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-breaking spaces with regular spaces in the Player column of compiled_df\n",
    "compiled_df['Player'] = compiled_df['Player'].str.replace('\\xa0', ' ')\n",
    "\n",
    "# Merge the dataframes again\n",
    "new_merged_df = pd.merge(compiled_df, goal_assist_df, on=['Player', 'Game_ID'], how='left')\n",
    "\n",
    "# Fill NaN values with 0 for the Goals, Assist1, and Assist2 columns\n",
    "new_merged_df[['Goals', 'Assist1', 'Assist2']] = new_merged_df[['Goals', 'Assist1', 'Assist2']].fillna(0).astype(int)\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "merged_df.head()\n",
    "\n",
    "new_merged_df.info()\n",
    "\n",
    "# RENAME BACK TO COMPILED_DF FOR USE LATER\n",
    "compiled_df = new_merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_merged_df['Goals'].hist()\n",
    "\n",
    "# new_merged_df.sample(20)\n",
    "\n",
    "# Value Counts of Teams\n",
    "compiled_df['Team'].value_counts()\n",
    "\n",
    "# How many Nan values are in the Team column?\n",
    "compiled_df['Team'].isna().sum()\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUTPUT CSVS\n",
    "\n",
    "# # Save the compiled_df to a csv\n",
    "compiled_df.to_csv('../TEMP/PRELIM_compiled_df.csv', index=False)\n",
    "\n",
    "# # Save the goal_assist_df to a csv\n",
    "goal_assist_df.to_csv('../TEMP/PRELIM_goal_assist_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Faceoff Metrics for each player in each game\n",
    "\n",
    "query_faceoff_metrics = \"\"\"\n",
    "SELECT \n",
    "    Player,\n",
    "    Game_ID,\n",
    "    FOW AS Faceoff_Wins,\n",
    "    FOL AS Faceoff_Losses\n",
    "FROM \n",
    "    player_stats;\n",
    "\"\"\"\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "\n",
    "\n",
    "\n",
    "faceoff_metrics_data = cursor.execute(query_faceoff_metrics).fetchall()\n",
    "\n",
    "# Preview the first few rows of the result\n",
    "faceoff_metrics_data[:5]\n",
    "\n",
    "# Create DataFrame with the results\n",
    "faceoff_metrics_df = pd.DataFrame(faceoff_metrics_data, columns=['Player', 'Game_ID', 'Faceoff_Wins', 'Faceoff_Losses'])\n",
    "\n",
    "# Take out those annoying character if there are any\n",
    "# Replace non-breaking spaces with regular spaces in the Player column of compiled_df\n",
    "faceoff_metrics_df['Player'] = faceoff_metrics_df['Player'].str.replace('\\xa0', ' ')\n",
    "\n",
    "# Replace non-breaking spaces with regular spaces in the Player column of compiled_df\n",
    "compiled_df['Team'] = compiled_df['Team'].str.replace('\\xa0', ' ')\n",
    "\n",
    "# Drop old indicator column to make way for new one\n",
    "# compiled_df = compiled_df.drop(columns=['_merge'])\n",
    "compiled_df = compiled_df.merge(faceoff_metrics_df, on=['Player', 'Game_ID'], how='inner', indicator=True)\n",
    "\n",
    "# Histogram of the compiled_df\n",
    "compiled_df.hist()\n",
    "\n",
    "compiled_df.info()\n",
    "# compiled_df.head(25)\n",
    "\n",
    "# compiled_df.columns\n",
    "\n",
    "# compiled_df['Team'].value_counts()\n",
    "\n",
    "# compiled_df['Team'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall PP Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the Overall Power Play Success rate for the entire database\n",
    "\n",
    "# Count the total number of Power Play (PP) goals from the scoring_summary table.\n",
    "pp_goals_count = cursor.execute(\"SELECT COUNT(*) FROM scoring_summary WHERE PP != '';\").fetchone()[0]\n",
    "\n",
    "# Count the total number of Power Plays from the penalty_summary table.\n",
    "total_pp_count = cursor.execute(\"SELECT COUNT(*) FROM penalty_summary;\").fetchone()[0]\n",
    "\n",
    "# Calculate the Power Play success rate.\n",
    "pp_success_rate = pp_goals_count / total_pp_count\n",
    "\n",
    "\n",
    "## OVERALL NCAA WIDE POWER PLAY SUCCESS RATE TO USE IN FACTOR\n",
    "pp_success_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even_strength_goals_refined_df.shape\n",
    "\n",
    "# Drop indicator column before new merge\n",
    "compiled_df = compiled_df.drop(columns=['_merge'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Save the compiled_df to a csv\n",
    "compiled_df.to_csv('../TEMP/NEW_PRELIM_compiled_df.csv', index=False)\n",
    "\n",
    "compiled_df['Team'].value_counts()\n",
    "\n",
    "compiled_df['Team'].isna().sum()\n",
    "\n",
    "# compiled_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Goals Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Team_Goals_For and Team_Goals_Against for each player in each game\n",
    "## Only include EVEN_STRENGTH goals\n",
    "## Access the EVEN_STRENGTH goals advanced_metrics_combined table from the TOTAL row from each team and apply it to each player in the game\n",
    "## EVEN Strength goals for the team should be stored in 'Goals_For_Team' and the opponent's EVEN Strength goals should be stored in 'Goals_Against_Team'\n",
    "\n",
    "# Extracting EVEN_STRENGTH goals (where PP column is blank) for each team\n",
    "even_strength_goals_query_refined = \"\"\"\n",
    "SELECT \n",
    "    Game_ID,\n",
    "    Team,\n",
    "    COUNT(*) AS Goals_For_Team\n",
    "FROM \n",
    "    scoring_summary\n",
    "WHERE \n",
    "    PP = ''\n",
    "GROUP BY \n",
    "    Game_ID, Team\n",
    "\"\"\"\n",
    "\n",
    "even_strength_goals_refined_df = pd.read_sql(even_strength_goals_query_refined, conn)\n",
    "\n",
    "# Correct the values in the Team column so we can effectively join the dataframes\n",
    "\n",
    "# Create a new column for the row number grouped by Game_ID\n",
    "even_strength_goals_refined_df['row_number'] = even_strength_goals_refined_df.groupby('Game_ID').cumcount() + 1\n",
    "\n",
    "# Function to assign the correct team name based on the row number\n",
    "def assign_team_name(row):\n",
    "    return row['Team_1'] if row['row_number'] == 1 else row['Team_2']\n",
    "\n",
    "# Splitting the Game_ID column again to extract team names\n",
    "team_names_split = even_strength_goals_refined_df['Game_ID'].str.split('-').str[-2:]\n",
    "even_strength_goals_refined_df['Team_1'] = team_names_split.str[0]\n",
    "even_strength_goals_refined_df['Team_2'] = team_names_split.str[1]\n",
    "\n",
    "# Applying the function to assign the correct team name\n",
    "even_strength_goals_refined_df['Team'] = even_strength_goals_refined_df.apply(assign_team_name, axis=1)\n",
    "\n",
    "# Dropping the extra columns again\n",
    "even_strength_goals_refined_df.drop(columns=['Team_1', 'Team_2', 'row_number'], inplace=True)\n",
    "\n",
    "# Creating a new column 'Opponent_Goals' which will be used to determine the goals against each team\n",
    "even_strength_goals_refined_df = even_strength_goals_refined_df.merge(\n",
    "    even_strength_goals_refined_df[['Game_ID', 'Team', 'Goals_For_Team']], \n",
    "    on='Game_ID',\n",
    "    suffixes=('', '_Opponent')\n",
    ")\n",
    "\n",
    "# Filtering out rows where Team is the same as the opponent team\n",
    "even_strength_goals_refined_df = even_strength_goals_refined_df[even_strength_goals_refined_df['Team'] != even_strength_goals_refined_df['Team_Opponent']]\n",
    "\n",
    "# Assigning the 'Goals_For_Team_Opponent' to a new column 'Goals_Against_Team'\n",
    "even_strength_goals_refined_df['Goals_Against_Team'] = even_strength_goals_refined_df['Goals_For_Team_Opponent']\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "even_strength_goals_refined_df.drop(columns=['Team_Opponent', 'Goals_For_Team_Opponent'], inplace=True)\n",
    "\n",
    "even_strength_goals_refined_df.head(25)\n",
    "# Take out those annoying character if there are any\n",
    "# Replace non-breaking spaces with regular spaces in the Player column of compiled_df\n",
    "even_strength_goals_refined_df['Team'] = even_strength_goals_refined_df['Team'].str.replace('\\xa0', ' ')\n",
    "\n",
    "## SAVE A CSV \n",
    "even_strength_goals_refined_df.to_csv('../TEMP/NEW_PRELIM_even_strength_goals_refined_df.csv', index=False)\n",
    "\n",
    "# # Displaying the dataframe with the newly computed 'Goals_Against_Team' values\n",
    "even_strength_goals_refined_df.sample(25)\n",
    "\n",
    "\n",
    "# # print(compiled_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on Game_ID and Team\n",
    "merged_df_new = pd.merge(compiled_df, even_strength_goals_refined_df, on=['Game_ID', 'Team'], how='outer')\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "merged_df_new.head(25)\n",
    "\n",
    "merged_df_new.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Convert columns to int\n",
    "# int_cols = [ 'Shots_On_Net', 'Shots_Off_Net', 'Shots_Blocked',\n",
    "#        'Defensive_Blocks',  'Goals', 'Assist1', 'Assist2',\n",
    "#        'Faceoff_Wins', 'Faceoff_Losses', 'Goals_For_Team',\n",
    "#        'Goals_Against_Team']\n",
    "\n",
    "# for col in int_cols:\n",
    "#     compiled_df[col] = compiled_df[col].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# print(f'New Shape: {compiled_df.shape}')\n",
    "\n",
    "# ####\n",
    "# # # Merge into the compiled_df\n",
    "# compiled_df = compiled_df.merge(even_strength_goals_refined_df, on=['Game_ID', 'Team'], how='outer', indicator=True)\n",
    "\n",
    "# compiled_df.columns\n",
    "\n",
    "# # compiled_df['Goals'].hist()\n",
    "# # compiled_df['Assist1'].hist()\n",
    "# compiled_df['Assist2'].hist()\n",
    "\n",
    "# compiled_df.sample(25)\n",
    "\n",
    "# # Team value count\n",
    "# compiled_df['Team'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHow just the rows where the Goals_Against_Team is NaN\n",
    "trouble_df = merged_df_new[merged_df_new['Goals_Against_Team'].isna()]\n",
    "\n",
    "# Value Counts of Teams\n",
    "trouble_df['Team'].value_counts()\n",
    "\n",
    "# I think what is going on is thes are instanced when the player was not on the roster the day of the game?\n",
    "\n",
    "## Do any of these have values in Goals or Assists?\n",
    "trouble_df[trouble_df['Goals'] > 0]\n",
    "\n",
    "trouble_df[trouble_df['Assist1'] > 0]\n",
    "\n",
    "## Could be games when no even strength goals were scored - That must be it. fill with 0\n",
    "merged_df_new['Goals_Against_Team'] = merged_df_new['Goals_Against_Team'].fillna(0)\n",
    "# Same for Goals_For_Team\n",
    "merged_df_new['Goals_For_Team'] = merged_df_new['Goals_For_Team'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_new.hist()\n",
    "\n",
    "merged_df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Joining the dataframe with itself to compute EVEN_STRENGTH goals against each team\n",
    "# team_goals_refined_df = even_strength_goals_refined_df.merge(\n",
    "#     even_strength_goals_refined_df, on='Game_ID', suffixes=('', '_Opponent')\n",
    "# )\n",
    "\n",
    "# # Filtering out rows where Team is the same as the opponent team\n",
    "# team_goals_refined_df = team_goals_refined_df[team_goals_refined_df['Team'] != team_goals_refined_df['Team_Opponent']]\n",
    "\n",
    "# # Dropping unnecessary columns and renaming for clarity\n",
    "# team_goals_refined_df = team_goals_refined_df[['Game_ID', 'Team', 'Goals_For_Team', 'Goals_For_Team_Opponent']]\n",
    "# team_goals_refined_df = team_goals_refined_df.rename(columns={'Goals_For_Team_Opponent': 'Goals_Against_Team'})\n",
    "\n",
    "# # Joining with advanced_metrics_combined to assign the values to each player\n",
    "# player_goals_refined_df = player_goals_df.merge(team_goals_refined_df, on=['Game_ID', 'Team'], how='left')\n",
    "\n",
    "# # Display the first few rows of the resulting dataframe\n",
    "# player_goals_refined_df[['Player', 'Game_ID', 'Team', 'Goals_For_Team', 'Goals_Against_Team']].head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Penalty Component\n",
    "\n",
    "# Count the number of penalties taken by each player in each game\n",
    "penalty_count_query = \"\"\"\n",
    "SELECT\n",
    "    Game_ID,\n",
    "    Player,\n",
    "    COUNT(*) AS Penalties_Taken\n",
    "FROM\n",
    "    penalty_summary\n",
    "WHERE\n",
    "    Player != 'TOTAL'\n",
    "GROUP BY\n",
    "    Game_ID, Player;\n",
    "\"\"\"\n",
    "\n",
    "## Rename the new version of the df back to this name to use later\n",
    "\n",
    "compiled_df = merged_df_new.copy()\n",
    "\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "penalty_count_df = pd.read_sql(penalty_count_query, conn)\n",
    "\n",
    "# Preview the first few rows of the result\n",
    "penalty_count_df.head()\n",
    "\n",
    "penalty_count_df['Penalties_Taken'].hist()\n",
    "\n",
    "# Convert to int\n",
    "penalty_count_df['Penalties_Taken'] = penalty_count_df['Penalties_Taken'].astype(int)\n",
    "\n",
    "# penalty_count_df.describe()\n",
    "\n",
    "# merge it into the compiled_df\n",
    "compiled_df = compiled_df.merge(penalty_count_df, on=['Player', 'Game_ID'], how='left')\n",
    "\n",
    "# Fill NaN values in 'Penalties_Taken' with 0\n",
    "compiled_df['Penalties_Taken'].fillna(0, inplace=True)\n",
    "\n",
    "# compiled_df.head(25)\n",
    "\n",
    "\n",
    "# compiled_df.hist()\n",
    "\n",
    "compiled_df.columns\n",
    "\n",
    "# Output CSV\n",
    "compiled_df.to_csv('../TEMP/GAME_SCORE_compiled_df.csv', index=False)\n",
    "\n",
    "\n",
    "compiled_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in 'Penalties_Taken' with 0\n",
    "compiled_df['Penalties_Taken'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate each component of the game score formula\n",
    "player_goals_refined_df = compiled_df.copy()\n",
    "\n",
    "# SCORE Component\n",
    "player_goals_refined_df['SCORE'] = (player_goals_refined_df['Goals'] * 0.75) + \\\n",
    "                                  (player_goals_refined_df['Assist1'] * 0.715) + \\\n",
    "                                  (player_goals_refined_df['Assist2'] * 0.555)\n",
    "\n",
    "# SHOTS Component\n",
    "player_goals_refined_df['SHOTS'] = (player_goals_refined_df['Shots_On_Net'] * 0.075) + \\\n",
    "                                  (player_goals_refined_df['Shots_Off_Net'] * 0.075) - \\\n",
    "                                  (player_goals_refined_df['Shots_Blocked'] * 0.075)\n",
    "\n",
    "# FACEOFFS Component\n",
    "player_goals_refined_df['FACEOFFS'] = (player_goals_refined_df['Faceoff_Wins'] * 0.01) - \\\n",
    "                                     (player_goals_refined_df['Faceoff_Losses'] * 0.01)\n",
    "# Fill NaN values in 'Faceoff_Wins' and 'Faceoff_Losses' with 0\n",
    "player_goals_refined_df['FACEOFFS'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# TEAM Component\n",
    "player_goals_refined_df['TEAM'] = (player_goals_refined_df['Goals_For_Team'] * 0.15) - \\\n",
    "                                 (player_goals_refined_df['Goals_Against_Team'] * 0.15)\n",
    "# Fill\n",
    "\n",
    "\n",
    "# PENALTIES Component -  Negative because it is a penalty\n",
    "player_goals_refined_df['PENALTIES'] = (player_goals_refined_df['Penalties_Taken'] * pp_success_rate) * -1\n",
    "\n",
    "## Fill all Nan Values with 0\n",
    "player_goals_refined_df.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the overall game score\n",
    "player_goals_refined_df['Game_Score'] = player_goals_refined_df['SCORE'] + \\\n",
    "                                       player_goals_refined_df['SHOTS'] + \\\n",
    "                                       player_goals_refined_df['FACEOFFS'] + \\\n",
    "                                       player_goals_refined_df['TEAM'] - \\\n",
    "                                       player_goals_refined_df['PENALTIES']\n",
    "\n",
    "# Display the first few rows of the dataframe with the newly computed 'Game_Score' values\n",
    "player_goals_refined_df[['Player', 'Game_ID', 'Team', 'Game_Score']].head(25)\n",
    "\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "player_goals_refined_df.to_csv('../TEMP/GAME_SCORE_player_goals_refined_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot the big Game Score Table into individual teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate team-specific tables using a pivot table\n",
    "team_tables = {}\n",
    "\n",
    "unique_teams = player_goals_refined_df['Team'].unique()\n",
    "\n",
    "for team in unique_teams:\n",
    "    team_df = player_goals_refined_df[player_goals_refined_df['Team'] == team]\n",
    "    pivot_table = team_df.pivot(index='Player', columns='Game_ID', values='Game_Score')\n",
    "    team_tables[team] = pivot_table\n",
    "\n",
    "\n",
    "# Print List of Teams\n",
    "unique_teams\n",
    "\n",
    "\n",
    "# Fill NaN values with 0\n",
    "for team in unique_teams:\n",
    "    team_tables[team] = team_tables[team].fillna(0)\n",
    "\n",
    "# Display the first team's table as an example\n",
    "# team_tables[unique_teams[21]].head(40)\n",
    "\n",
    "### MSU Is In Index Position 21 in this case outputing csv for MSU\n",
    "# team_tables[unique_teams[21]] = team_tables[unique_teams[21]].fillna(0)\n",
    "# team_tables[unique_teams[21]].to_csv('../data/Nov_2_MSU_GAME_SCORES.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables of Game Scores for Every Player and Every Team should all be stored now if it ran cleanly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first team's table as an example\n",
    "team_tables[unique_teams[7]].head(40)\n",
    "\n",
    "ohio_state_df = team_tables[unique_teams[7]].copy()\n",
    "\n",
    "# Clean Column Headers\n",
    "# split on - and take the last 2 elements\n",
    "# ohio_state_df.columns = ohio_state_df.columns.str.split('-').str[-2:]\n",
    "\n",
    "ohio_state_df.head(25)\n",
    "\n",
    "# Get a list of the column names\n",
    "column_names = ohio_state_df.columns.tolist()\n",
    "# Clean up column names by Removing 'Ohio State' and any digits of dashes\n",
    "column_names = [name.replace('Ohio State', '') for name in column_names]\n",
    "column_names = [name.replace('-', '') for name in column_names]\n",
    "column_names = [name.replace(' ', '') for name in column_names]\n",
    "\n",
    "# Use regex to remove any digits\n",
    "import re\n",
    "\n",
    "column_names = [re.sub(r'\\d+', '', name) for name in column_names]\n",
    "\n",
    "\n",
    "\n",
    "# Replace the column names\n",
    "ohio_state_df.columns = column_names\n",
    "\n",
    "ohio_state_df.head(25)\n",
    "\n",
    "# Save to CSV\n",
    "ohio_state_df.to_csv('../TEMP/GAME_SCORE_OHIO_STATE.csv', index=True)\n",
    "\n",
    "### MSU Is In Index Position 21 in this case outputing csv for MSU\n",
    "# team_tables[unique_teams[21]] = team_tables[unique_teams[21]].fillna(0)\n",
    "# team_tables[unique_teams[21]].to_csv('../data/Nov_2_MSU_GAME_SCORES.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One of THe Michigan Games is Absent From The OSU DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohio_state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dataframes from the team_tables dictionary\n",
    "team_tables_list = [team_tables[team] for team in unique_teams]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save To an Excell File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming unique_teams and team_tables are lists and of the same length\n",
    "import xlsxwriter\n",
    "\n",
    "# Create a workbook and add a worksheet for each team\n",
    "workbook = xlsxwriter.Workbook('../data/Nov_2_GAME_SCORES.xlsx')\n",
    "\n",
    "for team, table in team_tables_dict.items():\n",
    "    # Create a new worksheet with the team name\n",
    "    worksheet = workbook.add_worksheet(team)\n",
    "    \n",
    "    # Write the headers\n",
    "    for col_num, column in enumerate(table.columns):\n",
    "        worksheet.write(0, col_num, column)\n",
    "    \n",
    "    # Write the data\n",
    "    for row_num, row_data in enumerate(table.values):\n",
    "        for col_num, cell_data in enumerate(row_data):\n",
    "            worksheet.write(row_num + 1, col_num, cell_data)  # +1 to skip the header\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "# NOTE: The above code is structured to work with the provided mock data. Adjustments might be needed based on actual data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the team tables to a dictionary\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blocking out the Game Score formula\n",
    "\n",
    "#### METRIC Formula\n",
    "# \n",
    "# METRIC = SCORE [ (Goals*0.75) + (Assist1*0.715) + (Assist2*0.555) ] \n",
    "#               + SHOTS [ (Shot_On_Net*0.075) + (Shots_Off_Net*0.075) - (Shots_Blocked*0.075) ]\n",
    "#               + FACEOFFS [ (Faceoff_Wins*0.01) - (Faceoff_Losses*0.01) ]\n",
    "#               + TEAM [ (Goals_For_Team*0.15) + (Goals_Against_Team*0.15) ]\n",
    "#               -  [ (Penalties_Taken * Overall_PP_Success_Rate) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to find these values in my DB\n",
    "scoring_summary\n",
    "    - Goals\n",
    "    -First Assist\n",
    "    -Second Assist\n",
    "\n",
    "player_stats\n",
    "    - Shots on Goal\n",
    "    - FOW\n",
    "    - FOL\n",
    "    - PIM \n",
    "        - (Maybe worth weighting differently based on period and time it was taken)\n",
    "        - Penalty late in a close game hurts a team more than something taken in the first perios\n",
    "        - a penalty that is taken when already short handed hurts much more than one 5-on-5\n",
    "            - I should be able to seperate out these types of occurences in the data from penalty_summary\n",
    "\n",
    "CAN'T Get Penalties Drawn from current data\n",
    "\n",
    "### Formulating the final 3 factors\n",
    "GA & GF should only use even strength goals - need to figure out how to filter those\n",
    "\n",
    "Shots blocked (overall - defensive) can be found in advanced metrics as well as SOG, Offensive shots blocked and shots missed net for each of these situations (total, close, even and PP)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corsi Differnal = Corsi For - Corsi Defence\n",
    "Corsi is an advanced statistic used in the game of ice hockey to measure shot attempt differential while at even strength play. This includes shots on goal, missed shots on goal, and blocked shot attempts towards the opposition's net minus the same shot attempts directed at your own team's net.\n",
    "\n",
    "History\n",
    "The Corsi number was named by Tim Barnes, a financial analyst from Chicago working under the pseudonym Vic Ferrari. He had heard former Buffalo Sabres general manager Darcy Regier talking about shot differential on the radio, and then proceeded to develop a formula to accurately display shot differential. Ferrari originally wanted to name it the Regier number, but he didn't think it sounded right. He then considered calling it the Ruff number after former Buffalo Sabres head coach Lindy Ruff but he didn't think that was appropriate either. Ferrari ended up searching Buffalo Sabres staff, found a picture of Jim Corsi, and chose his name because he liked Corsi's mustache.[1]\n",
    "\n",
    "Formulae\n",
    "Corsi For (CF) = Shot attempts for at even strength: Shots + Blocks + Misses[2]\n",
    "Corsi Against (CA) = Shot attempts against at even strength: Shots + Blocks + Misses\n",
    "Corsi (C) = CF - CA\n",
    "Corsi For % (CF%) = CF / (CF + CA)\n",
    "Corsi For % Relative (CF% Rel) = CF% - CFOff%\n",
    "Corsi Per 60 Minutes at Even Strength (C/60) = (CF - CA) * 60 / TOI\n",
    "Relative Corsi per 60 Minutes at Even Strength (Crel/60) = CF/60 - CFoff/60 = On-Ice Corsi For / 60 Minutes - Off-Ice Corsi For / 60 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
