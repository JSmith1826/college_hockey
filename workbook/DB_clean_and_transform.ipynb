{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook takes the database created by the raw scrape of game results, cleans up some problems with the data \n",
    "\n",
    "### Task List\n",
    "- the advanced metrics tables should have the team name added to each player's row\n",
    "    - can also probably store as a single table instead of two tables\n",
    "        - would also want to add home or away to each row along with Team Name\n",
    "        Should be able to do it with a rather simple if then and the team names in the Game_ID\n",
    "\n",
    "- Import the master rosters that are scraped and stored as CSV into the database so we can join data on age, class rank, ect \n",
    "    - I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "db_path = '../data/2022-2023 Season Data.db' # Set FOr 2022-2023 Season\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Roster data\n",
    "folder = '../data/rosters/'\n",
    "\n",
    "df_2023 = pd.read_csv(folder + '2023_master_roster.csv')\n",
    "df_2022 = pd.read_csv(folder + '2022_master_roster.csv')\n",
    "df_2021 = pd.read_csv(folder + '2021_master_roster.csv')\n",
    "df_2020 = pd.read_csv(folder + '2020_master_roster.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Transform Advanced Metrics\n",
    "- add, Team and Home-Away columns, combine the two tables into a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scoring_summary',\n",
       " 'penalty_summary',\n",
       " 'goalie_stats',\n",
       " 'line_chart',\n",
       " 'linescore',\n",
       " 'advanced_metrics_team1',\n",
       " 'advanced_metrics_team2',\n",
       " 'player_stats',\n",
       " 'master_roster_2022',\n",
       " 'game_details',\n",
       " 'player_stats_ytd',\n",
       " 'master_roster',\n",
       " 'advanced_metrics_combined']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the advanced metrics tables\n",
    "query_team1 = \"SELECT * FROM advanced_metrics_team1;\"\n",
    "query_team2 = \"SELECT * FROM advanced_metrics_team2;\"\n",
    "\n",
    "df_advanced_team1 = pd.read_sql_query(query_team1, conn)\n",
    "df_advanced_team2 = pd.read_sql_query(query_team2, conn)\n",
    "\n",
    "# # Show some sample data to verify\n",
    "# df_advanced_team1.head(), df_advanced_team2.head()\n",
    "\n",
    "# Correctly extract team names from Game_ID\n",
    "df_advanced_team1['Team'] = df_advanced_team1['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_advanced_team1['Home/Away'] = 'Away'  # Team1 is the away team\n",
    "df_advanced_team2['Team'] = df_advanced_team2['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "df_advanced_team2['Home/Away'] = 'Home'  # Team2 is the home team\n",
    "\n",
    "# Recombine the two dataframes into a single one, again\n",
    "df_advanced_combined_corrected = pd.concat([df_advanced_team1, df_advanced_team2], ignore_index=True)\n",
    "\n",
    "# Show some sample data to verify the correction\n",
    "# df_advanced_combined_corrected.sample(10)\n",
    "\n",
    "# Save the combined and corrected dataframe back to the database as a new table\n",
    "new_table_name = 'advanced_metrics_combined'\n",
    "df_advanced_combined_corrected.to_sql(new_table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Drop the original advanced metrics tables from the database\n",
    "drop_table1_query = \"DROP TABLE IF EXISTS advanced_metrics_team1;\"\n",
    "drop_table2_query = \"DROP TABLE IF EXISTS advanced_metrics_team2;\"\n",
    "\n",
    "# conn.execute(drop_table1_query)\n",
    "# conn.execute(drop_table2_query)\n",
    "\n",
    "# Verify by listing all the tables in the database again\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(tables_query).fetchall()\n",
    "table_names = [table[0] for table in tables]\n",
    "table_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional cleaning steps for the advanced metrics table\n",
    "# Remove rows where Player is \"TOTAL\"\n",
    "df_advanced_combined_cleaned = df_advanced_combined_corrected[df_advanced_combined_corrected['Player'] != 'TOTAL']\n",
    "df_advanced_combined_cleaned = df_advanced_combined_cleaned[df_advanced_combined_cleaned['Player'] != 'Name: Clean_Name, dtype: object,']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Home and Away Columns to game_details table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1062"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Read the game_details table into a DataFrame\n",
    "df_game_details = pd.read_sql(\"SELECT * FROM game_details\", conn)\n",
    "\n",
    "# Step 2: Create new columns for Home and Away Teams by parsing Game_ID\n",
    "df_game_details['Away_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_game_details['Home_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "# Step 3: Write this updated DataFrame back to the game_details table\n",
    "df_game_details.to_sql('game_details', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up The Column Names in the Player Stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "player_stats_df.rename(columns={'Pt.':'Pts'}, inplace=True)\n",
    "player_stats_df.rename(columns={'+/-':'plus_minus'}, inplace=True)\n",
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A NEW TABLE WITH AGGRIGATED PLAYER STATS YEAR TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14260\\1149497493.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_player_stats_cleaned[col] = pd.to_numeric(df_player_stats_cleaned[col], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>Games_Played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. Hodges</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.J. Macaulay</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ Casperson</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AJ Vanderbeck</td>\n",
       "      <td>Northern Michigan</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>-5</td>\n",
       "      <td>148</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Bohlinger</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clean_Player               Team   G   A  Pts  plus_minus   Sh  PIM  \\\n",
       "0      A.J. Hodges     Michigan State   0   0    0           1    2    0   \n",
       "1    A.J. Macaulay             Alaska   2   7    9          13   31   12   \n",
       "2     AJ Casperson        Long Island   0   2    2           1    2   10   \n",
       "3    AJ Vanderbeck  Northern Michigan  13  19   32          -5  148   33   \n",
       "4  Aaron Bohlinger      Massachusetts   2   7    9           1   28    6   \n",
       "\n",
       "   Games_Played  \n",
       "0             9  \n",
       "1            33  \n",
       "2             7  \n",
       "3            35  \n",
       "4            22  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the player_stats table from the database\n",
    "query_player_stats = \"SELECT * FROM player_stats;\"\n",
    "df_player_stats = pd.read_sql_query(query_player_stats, conn)\n",
    "\n",
    "# Clean up the name format in player_stats for easier matching\n",
    "# Replace the non-breaking space with a regular space\n",
    "df_player_stats['Clean_Player'] = df_player_stats['Player'].apply(lambda x: x.replace('\\xa0', ' '))\n",
    "\n",
    "# Remove rows where Player is the team name (e.g., \"Michigan State\")\n",
    "df_player_stats_cleaned = df_player_stats[df_player_stats['Player'] != df_player_stats['Team']]\n",
    "\n",
    "# Convert relevant columns to integers for correct aggregation\n",
    "cols_to_convert = ['G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM']\n",
    "for col in cols_to_convert:\n",
    "    df_player_stats_cleaned[col] = pd.to_numeric(df_player_stats_cleaned[col], errors='coerce')\n",
    "\n",
    "# Aggregate the data for year-to-date stats\n",
    "# Add a column for counting the number of games each player has played\n",
    "agg_player_stats_corrected_with_games = df_player_stats_cleaned.groupby(['Clean_Player', 'Team']).agg({\n",
    "    'G': 'sum',\n",
    "    'A': 'sum',\n",
    "    'Pts': 'sum',\n",
    "    'plus_minus': 'sum',\n",
    "    'Sh': 'sum',\n",
    "    'PIM': 'sum',\n",
    "    'Game_ID': 'count'  # Counting the number of unique Game_IDs for each player\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the Game_ID column to Games_Played\n",
    "agg_player_stats_corrected_with_games.rename(columns={'Game_ID': 'Games_Played'}, inplace=True)\n",
    "\n",
    "# Save the updated aggregated data back to the database, replacing the existing table\n",
    "agg_player_stats_corrected_with_games.to_sql('player_stats_ytd', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Verify by loading some sample data from the updated table\n",
    "sample_updated_ytd = pd.read_sql_query(\"SELECT * FROM player_stats_ytd LIMIT 5;\", conn)\n",
    "sample_updated_ytd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Roster data from the CSVs to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## SET THE ROSTER DATAFRAME TO THE CORRECT YEAR ####################\n",
    "## MATCH THE DATAFRAME NAMES\n",
    "df_master_roster = df_2022\n",
    "\n",
    "## Season Year Value\n",
    "season_year = 2022\n",
    "\n",
    "# Clean up the name formats for joining\n",
    "# Master roster: Convert \"Last Name, First Name\" to \"First Name Last Name\"\n",
    "df_master_roster['Clean_Name'] = df_master_roster['Name'].apply(lambda x: ' '.join(reversed(x.split(', '))))\n",
    "\n",
    "# Clean up the Team column, remove '-' and replace with ' '\n",
    "df_master_roster['School'] = df_master_roster['School'].apply(lambda x: x.replace('-', ' '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scoring_summary',\n",
       " 'penalty_summary',\n",
       " 'goalie_stats',\n",
       " 'line_chart',\n",
       " 'linescore',\n",
       " 'advanced_metrics_team1',\n",
       " 'advanced_metrics_team2',\n",
       " 'player_stats',\n",
       " 'master_roster_2022',\n",
       " 'advanced_metrics_combined',\n",
       " 'game_details',\n",
       " 'player_stats_ytd',\n",
       " 'master_roster']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finally add the roster to the database as it's own table\n",
    "\n",
    "df_master_roster['SeasonYear'] = season_year\n",
    "\n",
    "# Save the roster data as a new table in the database\n",
    "roster_table_name = 'master_roster'\n",
    "df_master_roster.to_sql(roster_table_name, conn, if_exists='replace', index=False)\n",
    "############################################################\n",
    "\n",
    "# Verify by listing all the tables in the database again\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(tables_query).fetchall()\n",
    "table_names_updated = [table[0] for table in tables]\n",
    "table_names_updated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a backup of the transformed database and proceed to adding the roster info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../TEMP//2022_Game_Stats_Cleaned_Backup.db'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the current state of the database to a new SQLite file in the temp folder\n",
    "backup_db_path = '../TEMP//2022_Game_Stats_Cleaned_Backup.db'\n",
    "\n",
    "# Create a new SQLite database for backup and connect to it\n",
    "conn_backup = sqlite3.connect(backup_db_path)\n",
    "\n",
    "# Copy each table from the original database to the backup database\n",
    "for table in table_names:\n",
    "    query = f\"SELECT * FROM {table};\"\n",
    "    df_table = pd.read_sql_query(query, conn)\n",
    "    df_table.to_sql(table, conn_backup, if_exists='replace', index=False)\n",
    "\n",
    "# Close the backup database connection\n",
    "conn_backup.close()\n",
    "\n",
    "backup_db_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
