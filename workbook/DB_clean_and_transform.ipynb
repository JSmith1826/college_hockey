{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Code is now integrated to the end of the Scrapper Notebook\n",
    "\n",
    "## This notebook takes the database created by the raw scrape of game results, cleans up some problems with the data \n",
    "\n",
    "### Task List\n",
    "- the advanced metrics tables should have the team name added to each player's row\n",
    "    - can also probably store as a single table instead of two tables\n",
    "        - would also want to add home or away to each row along with Team Name\n",
    "        Should be able to do it with a rather simple if then and the team names in the Game_ID\n",
    "\n",
    "- Import the master rosters that are scraped and stored as CSV into the database so we can join data on age, class rank, ect \n",
    "    - I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# db_path = '../data/2022-2023 Season Data.db' # Set FOr 2022-2023 Season\n",
    "\n",
    "# db_path = '../TEMP/2023_Season_Nov 2_Game_Stats.db' # Set For 2023-2024 Season\n",
    "\n",
    "# db_path = '../data/db/Current_Season_YTD_Game_Stats.db' # Set For 2023-2024 Season\n",
    "\n",
    "# db_path = '../TEMP/2022_Game_Stats.db' # 2022 Season\n",
    "\n",
    "# db_path = '../data/db/2021_Season_v1_Game_Stats.db' # 2021 Season\n",
    "\n",
    "db_path = '../TEMP/2021_Full__Game_Stats.db'\n",
    "\n",
    "# db_path = '../TEMP/MAR_18_Current_YTD_Stats_Game_Stats.db'\n",
    "\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Roster data\n",
    "folder = '../data/rosters/'\n",
    "\n",
    "df_2023 = pd.read_csv(folder + '2023_master_roster.csv')\n",
    "df_2022 = pd.read_csv(folder + '2022_master_roster.csv')\n",
    "df_2021 = pd.read_csv(folder + '2021_master_roster.csv')\n",
    "df_2020 = pd.read_csv(folder + '2020_master_roster.csv')\n",
    "\n",
    "\n",
    "# Load the Correct Roster into the database\n",
    "roster_df = df_2022.copy()\n",
    "\n",
    "# Set the SeasonYear in the database_roster\n",
    "season_year_setting = 2022\n",
    "\n",
    "## Print tables in database\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of Team Primary Names to Abbreviations\n",
    "\n",
    "- Needed to Add IVY teams becuase of low amount of games. will have to do for harvard, yale, ect next week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe from SQL query\n",
    "df = pd.read_sql_query(\"SELECT * FROM advanced_metrics\", conn)\n",
    "\n",
    "# Function to count the occurrences of primary team names for unmatched abbreviations\n",
    "def count_primary_names_for_abbreviation(abbreviation):\n",
    "    filtered_rows = df[df['Team'] == abbreviation]\n",
    "    team_counts = {}\n",
    "    \n",
    "    for _, row in filtered_rows.iterrows():\n",
    "        teams = row['Game_ID'].split('-')[-2:]\n",
    "        for team in teams:\n",
    "            if team not in team_counts:\n",
    "                team_counts[team] = 0\n",
    "            team_counts[team] += 1\n",
    "            \n",
    "    return team_counts\n",
    "\n",
    "\n",
    "# Attempt to match abbreviations to primary names based on substrings and common naming conventions\n",
    "matched_dict = {}\n",
    "unmatched_abbreviations = []\n",
    "\n",
    "for abbreviation in df['Team'].unique():\n",
    "\n",
    "\n",
    "\n",
    "# Match the abbreviation to the primary team name with the highest occurrence\n",
    "\n",
    "    team_counts = count_primary_names_for_abbreviation(abbreviation)\n",
    "    # Get the team with the highest count\n",
    "    matched_team = max(team_counts, key=team_counts.get)\n",
    "    matched_dict[abbreviation] = matched_team\n",
    "\n",
    "# matched_dict\n",
    "\n",
    "# Manually fix the unmatched abbreviations - IVY League Teams with no of very few games throw a wrench in the above method\n",
    "# Brown: Brown\n",
    "# Cornell: Cornell\n",
    "\n",
    "# Make those substitutions\n",
    "matched_dict['Brown'] = 'Brown'\n",
    "matched_dict['Cornell'] = 'Cornell'\n",
    "# yale\n",
    "matched_dict['Yale'] = 'Yale'\n",
    "# princeton\n",
    "matched_dict['Princeton'] = 'Princeton'\n",
    "\n",
    "# harvard\n",
    "matched_dict['Harvard'] = 'Harvard'\n",
    "# columbia\n",
    "matched_dict['Columbia'] = 'Columbia'\n",
    "\n",
    "# dartmouth\n",
    "matched_dict['Dartmouth'] = 'Dartmouth'\n",
    "\n",
    "# penn\n",
    "matched_dict['Penn'] = 'Penn'\n",
    "\n",
    "# BC\n",
    "matched_dict['BC'] = 'Boston College'\n",
    "\n",
    "\n",
    "\n",
    "# matched_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Transform Advanced Metrics\n",
    "- add, Team and Home-Away columns, combine the two tables into a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW Handling of Advanced Stats\n",
    "# Create dataframe from SQL query\n",
    "df = pd.read_sql_query(\"SELECT * FROM advanced_metrics\", conn)\n",
    "\n",
    "# Rename columns\n",
    "new_names = ['Team', 'Player', 'TOTAL_Block', 'TOTAL_Miss', 'TOTAL_Saved', 'TOTAL_Goals', 'TOTAL_Total_Shots',\n",
    "                'EVEN_Block', 'EVEN_Miss', 'EVEN_Saved', 'EVEN_Goals', 'EVEN_Total_Shots',\n",
    "                'PP_Block', 'PP_Miss', 'PP_Saved', 'PP_Goals', 'PP_Total_Shots',\n",
    "                'CLOSE_Block', 'CLOSE_Miss', 'CLOSE_Saved', 'CLOSE_Goals', 'CLOSE_Total_Shots',\n",
    "\n",
    "                'D_Blocks', 'Faceoffs', 'Game_ID']\n",
    "\n",
    "df.columns = new_names\n",
    "\n",
    "# # Apply the matched_dict to the Team column\n",
    "df['Team'] = df['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "## Fill all NaN values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Display the dataframe\n",
    "df.head()\n",
    "\n",
    "# Save back to the database\n",
    "df.to_sql('advanced_metrics', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE SINCE NOV 2 BECAUSE OF UPDATE TO SCRAPING BOOK\n",
    "# ### NEW Simple - advanced metrics 1 and 2 now have a team column (still contains the secondary team name so will want to address that as well\n",
    "# ## Combine the two tables into advanced_metrics_combined\n",
    "\n",
    "# # Get entire first table of advanced metrics\n",
    "# adv_met_1 = pd.read_sql_query(\"SELECT * FROM advanced_metrics_team1\", conn)\n",
    "\n",
    "\n",
    "# # Get entire second table of advanced metrics\n",
    "# adv_met_2 = pd.read_sql_query(\"SELECT * FROM advanced_metrics_team2\", conn)\n",
    "\n",
    "\n",
    "# # Combine the two tables\n",
    "# adv_met_combined = pd.concat([adv_met_1, adv_met_2], axis=0)\n",
    "\n",
    "# # Apply the matched_dict to the Team column\n",
    "# adv_met_combined['Team'] = adv_met_combined['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "\n",
    "# # Fill NaNs with 0\n",
    "# adv_met_combined = adv_met_combined.fillna(0)\n",
    "\n",
    "# # Add to database\n",
    "# adv_met_combined.to_sql('advanced_metrics_combined', conn, if_exists='replace', index=False)\n",
    "\n",
    "# # View Sample and output CSV\n",
    "# adv_met_combined.head()\n",
    "\n",
    "# # adv_met_combined.to_csv('../TEMP/NEWNEW advanced_metrics_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Home and Away Columns to game_details table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the game_details table into a DataFrame\n",
    "df_game_details = pd.read_sql(\"SELECT * FROM game_details\", conn)\n",
    "\n",
    "# Step 2: Create new columns for Home and Away Teams by parsing Game_ID\n",
    "df_game_details['Away_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_game_details['Home_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "# Step 3: Write this updated DataFrame back to the game_details table\n",
    "df_game_details.to_sql('game_details', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up The Column Names and extra header rows in the Player Stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "# view sample\n",
    "player_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for column renaming\n",
    "column_renames = {\n",
    "    'Pt.': 'Pts',\n",
    "    '+/-': 'plus_minus'\n",
    "}\n",
    "\n",
    "# Rename columns based on the dictionary\n",
    "player_stats_df.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "\n",
    "# Drop rows where Team name is in the Player column\n",
    "player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "# Print the length of the dataframe\n",
    "len(player_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the Column names to be easy to work with\n",
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "if 'Pt.' in player_stats_df.columns:\n",
    "    player_stats_df.rename(columns={'Pt.': 'Pts'}, inplace=True)\n",
    "else:\n",
    "    print(\"Column 'Pt.' not found.\")\n",
    "\n",
    "if '+/-' in player_stats_df.columns:\n",
    "    player_stats_df.rename(columns={'+/-': 'plus_minus'}, inplace=True)\n",
    "else:\n",
    "    print(\"Column '+/-' not found.\")\n",
    "\n",
    "print(len(player_stats_df))\n",
    "\n",
    "# Drop rows if Team name is in the player column\n",
    "# If ['Team'] is the same as ['Player'] then drop that row\n",
    "player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "# add the dataframe back to the database\n",
    "player_stats_df.to_sql('player_stats', conn, if_exists='replace', index=False)\n",
    "\n",
    "# print(len(player_stats_df))\n",
    "#################################\n",
    "# player_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for other subsitu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "df_linescores = pd.read_sql(\"SELECT * FROM linescore\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "df_linescores['Team'] = df_linescores['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "df_linescores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Table & Scoring Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "\n",
    "df_penalty = pd.read_sql(\"SELECT * FROM penalty_summary\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "#$ Skip if not found\n",
    "\n",
    "df_penalty['Team'] = df_penalty['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "    \n",
    "\n",
    "# Apply same method to scorring_summary:\n",
    "df_scoring = pd.read_sql(\"SELECT * FROM scoring_summary\", conn)\n",
    "df_scoring['Team'] = df_scoring['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "# Add Home and Away Team columns to scoring_summary\n",
    "df_scoring['Away_Team'] = df_scoring['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_scoring['Home_Team'] = df_scoring['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "\n",
    "## Add each table back to database\n",
    "# Write the updated linescores DataFrame back to the linescore table\n",
    "df_linescores.to_sql('linescore', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated penalty DataFrame back to the penalty_summary table\n",
    "df_penalty.to_sql('penalty_summary', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated scoring DataFrame back to the scoring_summary table\n",
    "df_scoring.to_sql('scoring_summary', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A NEW TABLE WITH AGGRIGATED PLAYER STATS YEAR TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use player_stats_df from here on, instead of running another SQL query.\n",
    "df_player_stats = player_stats_df.copy()\n",
    "\n",
    "\n",
    "# Clean up the name format in player_stats for easier matching\n",
    "# Replace the non-breaking space with a regular space\n",
    "df_player_stats['Clean_Player'] = df_player_stats['Player'].apply(lambda x: x.replace('\\xa0', ' '))\n",
    "\n",
    "# Remove rows where Player is the team name (e.g., \"Michigan State\")\n",
    "df_player_stats_cleaned = df_player_stats[df_player_stats['Player'] != df_player_stats['Team']]\n",
    "\n",
    "# Convert relevant columns to integers for correct aggregation\n",
    "cols_to_convert = ['G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM']\n",
    "for col in cols_to_convert:\n",
    "    df_player_stats_cleaned[col] = pd.to_numeric(df_player_stats_cleaned[col], errors='coerce')\n",
    "\n",
    "# Aggregate the data for year-to-date stats\n",
    "# Add a column for counting the number of games each player has played\n",
    "agg_player_stats_corrected_with_games = df_player_stats_cleaned.groupby(['Clean_Player', 'Team']).agg({\n",
    "    'G': 'sum',\n",
    "    'A': 'sum',\n",
    "    'Pts': 'sum',\n",
    "    'plus_minus': 'sum',\n",
    "    'Sh': 'sum',\n",
    "    'PIM': 'sum',\n",
    "    'Game_ID': 'count'  # Counting the number of unique Game_IDs for each player\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the Game_ID column to Games_Played\n",
    "agg_player_stats_corrected_with_games.rename(columns={'Game_ID': 'Games_Played'}, inplace=True)\n",
    "\n",
    "# Save the updated aggregated data back to the database, replacing the existing table\n",
    "agg_player_stats_corrected_with_games.to_sql('player_stats_ytd', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Verify by loading some sample data from the updated table\n",
    "sample_updated_ytd = pd.read_sql_query(\"SELECT * FROM player_stats_ytd LIMIT 5;\", conn)\n",
    "sample_updated_ytd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Roster data from the CSVs to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## SET THE ROSTER DATAFRAME TO THE CORRECT YEAR ####################\n",
    "## MATCH THE DATAFRAME NAMES\n",
    "df_master_roster = roster_df.copy()\n",
    "\n",
    "## Season Year Value\n",
    "season_year = season_year_setting\n",
    "\n",
    "# Clean up the name formats for joining\n",
    "# Master roster: Convert \"Last Name, First Name\" to \"First Name Last Name\"\n",
    "# df_master_roster['Clean_Name'] = df_master_roster['Player'].apply(lambda x: ' '.join(reversed(x.split(', '))))\n",
    "\n",
    "# Rename Player to Clean_Name\n",
    "df_master_roster.rename(columns={'Player': 'Clean_Name'}, inplace=True)\n",
    "# Rename School to Team\n",
    "df_master_roster.rename(columns={'School': 'Team'}, inplace=True)\n",
    "\n",
    "# Clean up the Team column, remove '-' and replace with ' '\n",
    "# df_master_roster['School'] = df_master_roster['Team'].apply(lambda x: x.replace('-', ' '))\n",
    "\n",
    "## If there are an period in the column names, remove them\n",
    "df_master_roster.columns = df_master_roster.columns.str.replace('.', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finally add the roster to the database as it's own table\n",
    "\n",
    "df_master_roster['SeasonYear'] = season_year\n",
    "\n",
    "# Save the roster data as a new table in the database\n",
    "roster_table_name = 'master_roster'\n",
    "df_master_roster.to_sql(roster_table_name, conn, if_exists='replace', index=False)\n",
    "############################################################\n",
    "\n",
    "# Verify by listing all the tables in the database again\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(tables_query).fetchall()\n",
    "table_names_updated = [table[0] for table in tables]\n",
    "table_names_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a backup of the transformed database and proceed to adding the roster info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Output the current state of the database to a new SQLite file in the temp folder\n",
    "# # db_cleaned_path ='../TEMP/new_cleaned_db.db'\n",
    "\n",
    "# ## Save the database to a new file\n",
    "# conn_cleaned = sqlite3.connect(db_cleaned_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
