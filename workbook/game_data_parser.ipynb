{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "## This book parses a box score from collegehockeynews.com ans well as the advanced metrics from the same game\n",
    "# The seperate elements of the game box score are stored in a list of dataframes\n",
    "# the dataframes are then stored in a dictionary and output as a json file\n",
    "\n",
    "# Example box score link\n",
    "url_box = 'https://www.collegehockeynews.com/box/final/20230211/mic/msu/'\n",
    "\n",
    "# Example metrics link from same game\n",
    "url_metrics = 'https://www.collegehockeynews.com/box/metrics.php?gd=96398'\n",
    "\n",
    "box_score_url = 'https://www.collegehockeynews.com/box/final/20230211/mic/msu/'\n",
    "advanced_metrics_url = 'https://www.collegehockeynews.com/box/metrics.php?gd=96211'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HTML to feed into BeautifulSoup\n",
    "box_score_response = requests.get(box_score_url)\n",
    "box_score_html = box_score_response.text\n",
    "\n",
    "# box_score_response = requests.get(box_score_url)\n",
    "# box_score_html = box_score_response.text\n",
    "\n",
    "# advanced_metrics_response = requests.get(advanced_metrics_url)\n",
    "# advanced_metrics_html = advanced_metrics_response.text\n",
    "\n",
    "# html_content = box_score_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# PARSEING SCORING SUMMARY WITH BS4\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='scrape.log', level=logging.INFO)\n",
    "\n",
    "def parse_scoring_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the scoring div and table\n",
    "    scoring_div = soup.find('div', id='scoring')\n",
    "    if scoring_div is None:\n",
    "        logging.error(\"Scoring div not found\")\n",
    "        return None\n",
    "\n",
    "    scoring_table = scoring_div.find('table')\n",
    "    if scoring_table is None:\n",
    "        logging.error(\"Scoring table not found within the scoring div\")\n",
    "        return None\n",
    "\n",
    "    # Initialize list to store scoring events\n",
    "    scoring_events = []\n",
    "    period = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in scoring_table.find_all('tr'):\n",
    "        if 'stats-section' in row.get('class', []):\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                period = td.text.strip()\n",
    "            else:\n",
    "                logging.warning(\"Period name not found in 'stats-section' row\")\n",
    "                period = \"Unknown\"\n",
    "\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                team = cols[0].text.strip()\n",
    "                pp = cols[1].text.strip()\n",
    "\n",
    "                player_data = cols[3].text.strip()\n",
    "                match = re.match(r\"(.+)\\s\\((\\d+)\\)\", player_data)\n",
    "                if match:\n",
    "                    player = match.group(1)\n",
    "                    goals = int(match.group(2))\n",
    "                else:\n",
    "                    player = player_data\n",
    "                    goals = None\n",
    "\n",
    "                assist_data = cols[4].text.strip().split(\", \")\n",
    "                assist1 = assist_data[0] if len(assist_data) > 0 else None\n",
    "                assist2 = assist_data[1] if len(assist_data) > 1 else None\n",
    "\n",
    "                time = cols[5].text.strip()\n",
    "\n",
    "                scoring_event = {\n",
    "                    'Period': period,\n",
    "                    'Team': team,\n",
    "                    'PP': pp,\n",
    "                    'Player': player,\n",
    "                    'Player_Goals': goals,\n",
    "                    'Assist1': assist1,\n",
    "                    'Assist2': assist2,\n",
    "                    'Time': time\n",
    "                }\n",
    "                scoring_events.append(scoring_event)\n",
    "\n",
    "    return pd.DataFrame(scoring_events)\n",
    "\n",
    "# # Uncomment to test the function with actual HTML content\n",
    "# scoring_summary = parse_scoring_summary(box_score_html)\n",
    "# df = pd.DataFrame(scoring_summary)\n",
    "# print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='scrape.log', level=logging.INFO)\n",
    "\n",
    "def parse_penalty_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the penalties div and table\n",
    "    penalties_div = soup.find('div', id='penalties')\n",
    "    if penalties_div is None:\n",
    "        logging.error(\"Penalties div not found\")\n",
    "        return None\n",
    "\n",
    "    penalties_table = penalties_div.find('table')\n",
    "    if penalties_table is None:\n",
    "        logging.error(\"Penalties table not found within the penalties div\")\n",
    "        return None\n",
    "\n",
    "    # Initialize list to store penalty events\n",
    "    penalty_events = []\n",
    "    period = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in penalties_table.find_all('tr'):\n",
    "        if 'stats-section' in row.get('class', []):\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                period = td.text.strip()\n",
    "            else:\n",
    "                logging.warning(\"Period name not found in 'stats-section' row\")\n",
    "                period = \"Unknown\"\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                team = cols[0].text.strip()\n",
    "                player = cols[1].text.strip()\n",
    "                pen_length = cols[2].text.strip()\n",
    "                penalty_type = cols[3].text.strip()\n",
    "                time = cols[4].text.strip()\n",
    "\n",
    "                penalty_event = {\n",
    "                    'Period': period,\n",
    "                    'Team': team,\n",
    "                    'Player': player,\n",
    "                    'Pen_Length': pen_length,\n",
    "                    'Penalty_Type': penalty_type,\n",
    "                    'Time': time\n",
    "                }\n",
    "                penalty_events.append(penalty_event)\n",
    "\n",
    "    return pd.DataFrame(penalty_events)\n",
    "\n",
    "# Uncomment to test the function with actual HTML content\n",
    "# penalty_summary = parse_penalty_summary(box_score_html)\n",
    "# df_penalties = pd.DataFrame(penalty_summary)\n",
    "# print(df_penalties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Team         Goalie  SV GA Minutes\n",
      "0        Michigan  Erik Portillo  30  3   65:00\n",
      "1  Michigan State      EMPTY NET   0  0    0:03\n",
      "2  Michigan State  Dylan St. Cyr  26  4   64:57\n"
     ]
    }
   ],
   "source": [
    "def parse_goalie_stats(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the goalies div and table\n",
    "    goalies_div = soup.find('div', id='goalies')\n",
    "    if goalies_div is None:\n",
    "        return \"Goalies div not found\"\n",
    "\n",
    "    goalies_table = goalies_div.find('table')\n",
    "    if goalies_table is None:\n",
    "        return \"Goalies table not found\"\n",
    "\n",
    "    # Initialize list to store goalie stats\n",
    "    goalie_stats = []\n",
    "    team = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in goalies_table.find_all('tr'):\n",
    "        if 'stats-header' in row.get('class', []):\n",
    "            team = row.find('td').text.strip()\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                goalie = cols[0].text.strip()\n",
    "                sv = cols[1].text.strip()\n",
    "                ga = cols[2].text.strip()\n",
    "                minutes = cols[3].text.strip()\n",
    "\n",
    "                goalie_stat = {\n",
    "                    'Team': team,\n",
    "                    'Goalie': goalie,\n",
    "                    'SV': sv,\n",
    "                    'GA': ga,\n",
    "                    'Minutes': minutes\n",
    "                }\n",
    "                goalie_stats.append(goalie_stat)\n",
    "\n",
    "    return pd.DataFrame(goalie_stats)\n",
    "\n",
    "# # Use the function and convert the result to a DataFrame\n",
    "goalie_stats_data = parse_goalie_stats(box_score_html)\n",
    "df_goalie_stats = pd.DataFrame(goalie_stats_data)\n",
    "print(df_goalie_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Team         Goalie  SV GA Minutes\n",
      "0        Michigan  Erik Portillo  30  3   65:00\n",
      "1  Michigan State      EMPTY NET   0  0    0:03\n",
      "2  Michigan State  Dylan St. Cyr  26  4   64:57\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='scrape.log', level=logging.INFO)\n",
    "\n",
    "def parse_goalie_stats(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the goalies div and table\n",
    "    goalies_div = soup.find('div', id='goalies')\n",
    "    if goalies_div is None:\n",
    "        logging.error(\"Goalies div not found\")\n",
    "        return None\n",
    "\n",
    "    goalies_table = goalies_div.find('table')\n",
    "    if goalies_table is None:\n",
    "        logging.error(\"Goalies table not found within the goalies div\")\n",
    "        return None\n",
    "\n",
    "    # Initialize list to store goalie stats\n",
    "    goalie_stats = []\n",
    "    team = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in goalies_table.find_all('tr'):\n",
    "        if 'stats-header' in row.get('class', []):\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                team = td.text.strip()\n",
    "            else:\n",
    "                logging.warning(\"Team name not found in 'stats-header' row\")\n",
    "                team = \"Unknown\"\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                goalie = cols[0].text.strip()\n",
    "                sv = cols[1].text.strip()\n",
    "                ga = cols[2].text.strip()\n",
    "                minutes = cols[3].text.strip()\n",
    "\n",
    "                goalie_stat = {\n",
    "                    'Team': team,\n",
    "                    'Goalie': goalie,\n",
    "                    'SV': sv,\n",
    "                    'GA': ga,\n",
    "                    'Minutes': minutes\n",
    "                }\n",
    "                goalie_stats.append(goalie_stat)\n",
    "\n",
    "    return pd.DataFrame(goalie_stats)\n",
    "\n",
    "# Uncomment to test the function with actual HTML content\n",
    "goalie_stats_data = parse_goalie_stats(box_score_html)\n",
    "df_goalie_stats = pd.DataFrame(goalie_stats_data)\n",
    "print(df_goalie_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of final column names: 23\n",
      "Length of final column names: 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLOSE_Player</th>\n",
       "      <th>CLOSE_Bl</th>\n",
       "      <th>CLOSE_Mi</th>\n",
       "      <th>CLOSE_SV</th>\n",
       "      <th>CLOSE_G</th>\n",
       "      <th>CLOSE_TSA</th>\n",
       "      <th>CLOSE_Bl</th>\n",
       "      <th>CLOSE_Mi</th>\n",
       "      <th>CLOSE_SV</th>\n",
       "      <th>CLOSE_G</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE_SV</th>\n",
       "      <th>CLOSE_G</th>\n",
       "      <th>CLOSE_TSA</th>\n",
       "      <th>CLOSE_Bl</th>\n",
       "      <th>CLOSE_Mi</th>\n",
       "      <th>CLOSE_SV</th>\n",
       "      <th>CLOSE_G</th>\n",
       "      <th>CLOSE_TSA</th>\n",
       "      <th>CLOSE_BLKs</th>\n",
       "      <th>CLOSE_FO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Gucciardi</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karsen Dorwart</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tiernan Shoudy</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cole Krygier</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Basgall</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CLOSE_Player CLOSE_Bl CLOSE_Mi CLOSE_SV CLOSE_G CLOSE_TSA CLOSE_Bl  \\\n",
       "0  David Gucciardi        3        2        4                 9        3   \n",
       "1   Karsen Dorwart                 3        4                 7            \n",
       "2   Tiernan Shoudy        3        3                          6        3   \n",
       "3     Cole Krygier        2        1        3                 6        2   \n",
       "4     Matt Basgall        2        2        2                 6        2   \n",
       "\n",
       "  CLOSE_Mi CLOSE_SV CLOSE_G  ... CLOSE_SV CLOSE_G CLOSE_TSA CLOSE_Bl CLOSE_Mi  \\\n",
       "0        2        3          ...        1                 1        3        1   \n",
       "1        3        3          ...        1                 1                 3   \n",
       "2        3                   ...                          0        3        2   \n",
       "3        1        3          ...                          0        1        1   \n",
       "4        2                   ...        2                 2        2        1   \n",
       "\n",
       "  CLOSE_SV CLOSE_G CLOSE_TSA CLOSE_BLKs CLOSE_FO  \n",
       "0        2                 6                      \n",
       "1                          3               11-21  \n",
       "2                          5          2      5-7  \n",
       "3        3                 5          1           \n",
       "4                          3          1           \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def parse_advanced_metrics_tables(html_content):\n",
    "    # Initialize list to store DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Parse HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table', {'class': 'sortable metrics'})\n",
    "    \n",
    "    for table in tables:\n",
    "        # Initialize list to store column names and data\n",
    "        col_names = []\n",
    "        col_names_final = []\n",
    "        data = []\n",
    "        \n",
    "        # Get headers\n",
    "        headers = table.find_all('th')\n",
    "        for header in headers:\n",
    "            col_names.append(header.text)\n",
    "        \n",
    "        # Add TOTAL, EVEN STRENGTH, POWER PLAY, CLOSE to column names\n",
    "        section_headers = ['TOTAL', 'EVEN STRENGTH', 'POWER PLAY', 'CLOSE']\n",
    "        for col in col_names:\n",
    "            for section in section_headers:\n",
    "                if col in section_headers:\n",
    "                    temp_col = section\n",
    "                else:\n",
    "                    temp_col = f\"{section}_{col}\"\n",
    "            col_names_final.append(temp_col)\n",
    "        \n",
    "        print(f\"Length of final column names: {len(col_names_final)}\")  # Debug statement\n",
    "        \n",
    "        # Get data rows\n",
    "        rows = table.find_all('tr')[2:]  # skip header rows\n",
    "        for row in rows:\n",
    "            row_data = []\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "        \n",
    "        # print(f\"Length of first row of data: {len(data[0])}\")  # Debug statement\n",
    "        \n",
    "        # Create DataFrame and append to list\n",
    "        df = pd.DataFrame(data, columns=col_names_final)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "# Placeholder for your actual HTML content\n",
    "# html_metrics_sample = '''...'''  # Replace with actual HTML content\n",
    "\n",
    "## Get the HTML content\n",
    "url_metrics = 'https://www.collegehockeynews.com/box/metrics.php?gd=96211'  # Replace this with your URL\n",
    "response = requests.get(url_metrics)\n",
    "html_metrics_sample = response.text\n",
    "\n",
    "# Parse and convert to DataFrames\n",
    "# This will return a list of DataFrames, one for each team\n",
    "# dfs[0] will be the DataFrame for the first team, dfs[1] for the second team\n",
    "dfs = parse_advanced_metrics_tables(html_metrics_sample)\n",
    "\n",
    "# To check the DataFrame for the first team\n",
    "dfs[0].head()\n",
    "dfs[1].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code for parsing the line chart information with specific positions for forwards and defensemen.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='scrape.log', level=logging.INFO)\n",
    "\n",
    "def parse_line_chart(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    line_chart_div = soup.find('div', id='linechart')\n",
    "    \n",
    "    if line_chart_div is None:\n",
    "        logging.error(\"Line chart div not found\")\n",
    "        return None\n",
    "\n",
    "    line_data = []\n",
    "\n",
    "    for team_div in line_chart_div.find_all('div', recursive=False):\n",
    "        h3 = team_div.find('h3')\n",
    "        if h3 is None:\n",
    "            logging.warning(\"Team name not found\")\n",
    "            continue\n",
    "        \n",
    "        team_name = h3.text.strip()\n",
    "        \n",
    "        for line_type_div in team_div.find_all('div', recursive=False):\n",
    "            line_type = line_type_div.get('class')[0] if line_type_div.get('class') else None\n",
    "            if line_type is None:\n",
    "                logging.warning(\"Line type not found\")\n",
    "                continue\n",
    "            \n",
    "            if line_type == 'f':\n",
    "                position_types = ['Left Wing', 'Center', 'Right Wing']\n",
    "            elif line_type == 'd':\n",
    "                position_types = ['Left D', 'Right D']\n",
    "            elif line_type == 'x':\n",
    "                position_types = ['Extra']\n",
    "            elif line_type == 'g':\n",
    "                position_types = ['Goalie']\n",
    "                goalie_count = 1  # Initialize goalie count\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            players = line_type_div.find_all('div')\n",
    "            if not players:\n",
    "                logging.warning(f\"No players found for {team_name} in {line_type}\")\n",
    "                continue\n",
    "            \n",
    "            for i, player in enumerate(players):\n",
    "                player_name = player.text.strip()\n",
    "                if line_type == 'x':\n",
    "                    player_name = player_name.split(' ')[0]\n",
    "                if line_type == 'g':\n",
    "                    line_number = f\"Goalie {goalie_count}\"\n",
    "                    goalie_count += 1\n",
    "                else:\n",
    "                    line_number = i // len(position_types) + 1\n",
    "\n",
    "                position = position_types[i % len(position_types)]\n",
    "                line_data.append({\n",
    "                    'Team': team_name,\n",
    "                    'Line': line_number,\n",
    "                    'Position': position,\n",
    "                    'Player': player_name\n",
    "                })\n",
    "\n",
    "    if not line_data:\n",
    "        logging.error(\"No line data was collected\")\n",
    "\n",
    "    return pd.DataFrame(line_data)\n",
    "\n",
    "# # Uncomment to test the function with actual HTML content\n",
    "# line_chart_data = parse_line_chart(box_score_html)\n",
    "# df_line_chart = pd.DataFrame(line_chart_data)\n",
    "# print(df_line_chart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Team              Player  G  A  Pt.  +/-  Sh  PIM   FOW   FOL  \\\n",
      "0   Michigan State      Michigan State  G  A  Pt.  +/-  Sh  PIM   NaN   NaN   \n",
      "1   Michigan State        Matt Basgall  0  0    0    0   2    0   NaN   NaN   \n",
      "2   Michigan State      Tiernan Shoudy  0  0    0    1   0    0   5.0   7.0   \n",
      "3   Michigan State      Daniel Russell  0  1    1    0   4    0   NaN   NaN   \n",
      "4   Michigan State       Viktor Hurtig  0  0    0    0   0    0   NaN   NaN   \n",
      "5   Michigan State      Karsen Dorwart  0  0    0   -1   4    2  11.0  21.0   \n",
      "6   Michigan State        Tanner Kelly  0  2    2    1   0    0   1.0   1.0   \n",
      "7   Michigan State     Erik Middendorf  0  1    1   -1   2    0   NaN   NaN   \n",
      "8   Michigan State        Jesse Tucker  0  0    0    0   0    0   1.0   0.0   \n",
      "9   Michigan State     Jeremy Davidson  1  0    1   -1   4    0   NaN   NaN   \n",
      "10  Michigan State     David Gucciardi  0  0    0    0   4    2   NaN   NaN   \n",
      "11  Michigan State       Zach Dubinsky  0  0    0    0   0    2   7.0   6.0   \n",
      "12  Michigan State       Dylan St. Cyr  0  0    0    0   0    0   NaN   NaN   \n",
      "13  Michigan State   Christian Krygier  0  0    0   -1   1    0   NaN   NaN   \n",
      "14  Michigan State        Cole Krygier  0  1    1    0   3    2   NaN   NaN   \n",
      "15  Michigan State       Jagger Joshua  0  0    0   -1   2   12   1.0   0.0   \n",
      "16  Michigan State      Nicolas Muller  0  0    0   -1   0    0   9.0   7.0   \n",
      "17  Michigan State      Miroslav Mucha  1  0    1    2   3    0   NaN   NaN   \n",
      "18  Michigan State   Michael Underwood  1  0    1   -2   2    0   NaN   NaN   \n",
      "19  Michigan State       Justin Jallen  0  0    0    0   2    0   NaN   NaN   \n",
      "20        Michigan            Michigan  G  A  Pt.  +/-  Sh  PIM   NaN   NaN   \n",
      "21        Michigan     Frank Nazar III  1  0    1    2   4    0   0.0   2.0   \n",
      "22        Michigan       Luca Fantilli  0  1    1    1   0    0   NaN   NaN   \n",
      "23        Michigan       Kienan Draper  0  0    0    0   0    2   NaN   NaN   \n",
      "24        Michigan      Jackson Hallum  0  0    0    0   0    2   NaN   NaN   \n",
      "25        Michigan         T.J. Hughes  1  0    1    1   2    2  18.0  11.0   \n",
      "26        Michigan       Brendan Miles  0  0    0    0   0    0   NaN   NaN   \n",
      "27        Michigan      Gavin Brindley  0  0    0    1   2    0   6.0  10.0   \n",
      "28        Michigan         Mark Estapa  0  0    0   -1   2    0   9.0   4.0   \n",
      "29        Michigan       Ethan Edwards  0  0    0   -1   0    2   NaN   NaN   \n",
      "30        Michigan          Dylan Duke  1  0    1    0   1    2   0.0   2.0   \n",
      "31        Michigan         Luke Hughes  1  1    2    0   9    0   NaN   NaN   \n",
      "32        Michigan  Mackie Samoskevich  0  3    3    2   2    2   NaN   NaN   \n",
      "33        Michigan         Jay Keranen  0  1    1    1   2    0   NaN   NaN   \n",
      "34        Michigan         Nolan Moyle  0  0    0   -1   1    0   4.0   3.0   \n",
      "35        Michigan      Keaton Pehrson  0  0    0    1   0    0   NaN   NaN   \n",
      "36        Michigan      Nick Granowicz  0  0    0   -2   0    0   5.0   3.0   \n",
      "37        Michigan      Eric Ciccolini  0  0    0   -1   2    0   NaN   NaN   \n",
      "38        Michigan        Steven Holtz  0  0    0    1   3    0   NaN   NaN   \n",
      "39        Michigan       Erik Portillo  0  0    0    0   0    0   NaN   NaN   \n",
      "\n",
      "           FO%  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2    41.666667  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "5    34.375000  \n",
      "6    50.000000  \n",
      "7          NaN  \n",
      "8   100.000000  \n",
      "9          NaN  \n",
      "10         NaN  \n",
      "11   53.846154  \n",
      "12         NaN  \n",
      "13         NaN  \n",
      "14         NaN  \n",
      "15  100.000000  \n",
      "16   56.250000  \n",
      "17         NaN  \n",
      "18         NaN  \n",
      "19         NaN  \n",
      "20         NaN  \n",
      "21    0.000000  \n",
      "22         NaN  \n",
      "23         NaN  \n",
      "24         NaN  \n",
      "25   62.068966  \n",
      "26         NaN  \n",
      "27   37.500000  \n",
      "28   69.230769  \n",
      "29         NaN  \n",
      "30    0.000000  \n",
      "31         NaN  \n",
      "32         NaN  \n",
      "33         NaN  \n",
      "34   57.142857  \n",
      "35         NaN  \n",
      "36   62.500000  \n",
      "37         NaN  \n",
      "38         NaN  \n",
      "39         NaN  \n"
     ]
    }
   ],
   "source": [
    "#### PARSE PLAYER STATS TABLE ####\n",
    "def parse_player_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the playersums div\n",
    "    playersums_div = soup.find('div', id='playersums')\n",
    "    if playersums_div is None:\n",
    "        return \"Player summaries div not found\"\n",
    "\n",
    "    # Initialize list to store player stats\n",
    "    player_stats = []\n",
    "\n",
    "    # Loop through each playersum div\n",
    "    for player_sum in playersums_div.find_all('div', class_='playersum'):\n",
    "        team = player_sum.find('td').text.strip()\n",
    "        \n",
    "        # Loop through table rows\n",
    "        for row in player_sum.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                player = cols[0].text.strip()\n",
    "                goals = cols[1].text.strip()\n",
    "                assists = cols[2].text.strip()\n",
    "                points = cols[3].text.strip()\n",
    "                plus_minus = cols[4].text.strip()\n",
    "                shots = cols[5].text.strip()\n",
    "                pim = cols[6].text.strip()\n",
    "                fowl = cols[7].text.strip() if len(cols) > 7 else None\n",
    "                \n",
    "                fow, fol = None, None\n",
    "                win_percentage = None\n",
    "                \n",
    "                \n",
    "\n",
    "                try:\n",
    "                    if fowl and '‑' in fowl:  # Checking if it contains a hyphen\n",
    "                        fow, fol = map(int, fowl.split('‑'))\n",
    "                        total_fo = fow + fol\n",
    "                        win_percentage = (fow / total_fo) * 100 if total_fo > 0 else 0\n",
    "                except ValueError:\n",
    "                    fow, fol, win_percentage = None, None, None\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                player_stat = {\n",
    "                    'Team': team,\n",
    "                    'Player': player,\n",
    "                    'G': goals,\n",
    "                    'A': assists,\n",
    "                    'Pt.': points,\n",
    "                    '+/-': plus_minus,\n",
    "                    'Sh': shots,\n",
    "                    'PIM': pim,\n",
    "                    'FOW': fow,\n",
    "                    'FOL': fol,\n",
    "                    'FO%': win_percentage\n",
    "                }\n",
    "                player_stats.append(player_stat)\n",
    "\n",
    "    return pd.DataFrame(player_stats)\n",
    "\n",
    "# # Use the function and convert the result to a DataFrame\n",
    "player_stats_data = parse_player_summary(box_score_html)\n",
    "df_player_stats = pd.DataFrame(player_stats_data)\n",
    "print(df_player_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the Linescore Elements - Score, shots, ect by period####\n",
    "\n",
    "def parse_linescore(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    linescore_data = []\n",
    "    \n",
    "    # Parsing the Goals table\n",
    "    goals_table = soup.select_one(\"#goals table\")\n",
    "    if goals_table is None:\n",
    "        logging.error(\"Goals table not found\")\n",
    "        return None\n",
    "    \n",
    "    rows = goals_table.select('tbody tr')\n",
    "    if not rows:\n",
    "        logging.warning(\"No rows found in Goals table\")\n",
    "        return None\n",
    "    \n",
    "    for row in rows:\n",
    "        team_data = {}\n",
    "        td = row.select_one('td')\n",
    "        if td:\n",
    "            team_data['Team'] = td.text\n",
    "        else:\n",
    "            logging.warning(\"Team name not found in Goals table\")\n",
    "            continue\n",
    "\n",
    "        goals = row.select('td')[1:]\n",
    "        for i, goal in enumerate(goals):\n",
    "            team_data[f'goals{i+1}' if i < len(goals) - 1 else 'goalsT'] = int(goal.text)\n",
    "        \n",
    "        linescore_data.append(team_data)\n",
    "    \n",
    "\n",
    "    # Parsing the Shots table\n",
    "    shots_table = soup.select_one(\"#shots table\")\n",
    "    if shots_table is None:\n",
    "        logging.error(\"Shots table not found\")\n",
    "        return None\n",
    "\n",
    "    rows = shots_table.select('tbody tr')\n",
    "    if not rows:\n",
    "        logging.warning(\"No rows found in Shots table\")\n",
    "        return None\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        shots = row.select('td')[1:]\n",
    "        if not shots:\n",
    "            logging.warning(f\"No shot data found for row {i+1} in Shots table\")\n",
    "            continue\n",
    "\n",
    "        for j, shot in enumerate(shots):\n",
    "            try:\n",
    "                linescore_data[i][f'shots{j+1}' if j < len(shots) - 1 else 'shotsT'] = int(shot.text.strip())\n",
    "            except ValueError:\n",
    "                logging.warning(f\"Could not convert shot data to integer for row {i+1}, column {j+1}\")\n",
    "                linescore_data[i][f'shots{j+1}' if j < len(shots) - 1 else 'shotsT'] = None\n",
    "\n",
    "    # Parsing the PP table\n",
    "    pp_table = soup.select_one(\"#pp table\")\n",
    "    if pp_table is None:\n",
    "        logging.error(\"PP table not found\")\n",
    "        return None\n",
    "\n",
    "    rows = pp_table.select('tbody tr')\n",
    "    if not rows:\n",
    "        logging.warning(\"No rows found in PP table\")\n",
    "        return None\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            pen_pim = row.select('td')[1].text.split('‑')\n",
    "            linescore_data[i]['Pen'] = int(pen_pim[0])\n",
    "            linescore_data[i]['PIM'] = int(pen_pim[1])\n",
    "\n",
    "            ppg_ppo = row.select('td')[2].text.split('‑')\n",
    "            linescore_data[i]['PPG'] = int(ppg_ppo[0])\n",
    "            linescore_data[i]['PPO'] = int(ppg_ppo[1])\n",
    "\n",
    "            fow_fol = row.select('td')[3].text.split('‑')\n",
    "            linescore_data[i]['FOW'] = int(fow_fol[0])\n",
    "            linescore_data[i]['FOL'] = int(fow_fol[1])\n",
    "            linescore_data[i]['FOW%'] = (linescore_data[i]['FOW'] / (linescore_data[i]['FOW'] + linescore_data[i]['FOL'])) * 100\n",
    "\n",
    "        except (ValueError, IndexError) as e:\n",
    "            logging.warning(f\"Could not process PP data for row {i+1}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(linescore_data)\n",
    "\n",
    "\n",
    "\n",
    "# # # Use the function and get the DataFrame\n",
    "# df_linescore = parse_linescore(box_score_html)\n",
    "# df_linescore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to parse game details\n",
    "\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='scrape.log', level=logging.INFO)\n",
    "\n",
    "def parse_game_details(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    meta_div = soup.find('div', {'id': 'meta'})\n",
    "    if meta_div is None:\n",
    "        logging.error(\"Meta div not found\")\n",
    "        return None\n",
    "    \n",
    "    game_details_div = meta_div.find_all('div')[-1]\n",
    "    if game_details_div is None:\n",
    "        logging.error(\"Game details div not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        date_str = game_details_div.h4.string\n",
    "        day_of_week, date = date_str.split(\", \", 1)\n",
    "        \n",
    "        p_elements = game_details_div.find_all('p')\n",
    "        details_strs = p_elements[0].get_text(separator='|').split('|')\n",
    "        \n",
    "        conference = details_strs[0]\n",
    "        location = details_strs[-1].split('at ')[-1]\n",
    "        details = details_strs[1] if len(details_strs) > 2 else None\n",
    "        \n",
    "        refs_str = p_elements[1].strong.next_sibling\n",
    "        asst_refs_str = p_elements[1].find_all('strong')[1].next_sibling\n",
    "        attendance_str = p_elements[1].find_all('strong')[2].next_sibling\n",
    "        \n",
    "        refs = refs_str.split(', ')\n",
    "        asst_refs = asst_refs_str.split(', ')\n",
    "        refs = [re.sub(r'[^a-zA-Z ]+', '', ref).strip() for ref in refs]\n",
    "        asst_refs = [re.sub(r'[^a-zA-Z ]+', '', ref).strip() for ref in asst_refs]\n",
    "        \n",
    "        attendance = attendance_str.split(\": \")[-1]\n",
    "        attendance = int(attendance.replace(',', ''))\n",
    "        \n",
    "        details = details.replace('\\n', '').strip()\n",
    "        details = re.sub('\\t', ' ', details)\n",
    "        \n",
    "        game_details = {\n",
    "            'Day': day_of_week,\n",
    "            'Date': date,\n",
    "            'Conference': conference,\n",
    "            'Details': details,\n",
    "            'Location': location,\n",
    "            'Ref1': refs[0],\n",
    "            'Ref2': refs[1] if len(refs) > 1 else None,\n",
    "            'Asst_Ref1': asst_refs[0],\n",
    "            'Asst_Ref2': asst_refs[1] if len(asst_refs) > 1 else None,\n",
    "            'Attendance': attendance\n",
    "        }\n",
    "        \n",
    "        game_details_df = pd.DataFrame([game_details])\n",
    "        return game_details_df\n",
    "\n",
    "    except (AttributeError, IndexError, ValueError) as e:\n",
    "        logging.error(f\"Error while parsing game details: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# # Test the function\n",
    "# game_details_df = parse_game_details(box_score_html)\n",
    "# game_details_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_box_score(box_score_html):\n",
    "    # Parse box score into DataFrames\n",
    "    \n",
    "    scoring_summary = parse_scoring_summary(box_score_html)\n",
    "    penalty_summary = parse_penalty_summary(box_score_html)\n",
    "    goalie_stats = parse_goalie_stats(box_score_html)\n",
    "    player_stats = parse_player_summary(box_score_html)\n",
    "    line_chart = parse_line_chart(box_score_html)\n",
    "    linescore = parse_linescore(box_score_html)\n",
    "    game_details = parse_game_details(box_score_html)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Combine DataFrames into a list\n",
    "    all_dfs = [game_details, scoring_summary, penalty_summary, goalie_stats, player_stats, line_chart, linescore]\n",
    "    \n",
    "\n",
    "    \n",
    "    return all_dfs\n",
    "\n",
    "def rename_duplicate_columns(df):\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in df.columns[df.columns.duplicated()].unique(): \n",
    "        cols[df.columns.get_loc(dup)] = [f\"{dup}_{i}\" if i != 0 else dup for i in range(df.columns.get_loc(dup).sum())]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to save DataFrames to SQLite database\n",
    "def save_to_sqlite_db(df_list, table_names, db_name='../TEMP/test_hockey_data.db'):\n",
    "    engine = create_engine(f'sqlite:///{db_name}')\n",
    "    \n",
    "    for df, table in zip(df_list, table_names):\n",
    "        # Rename duplicate columns\n",
    "        df = rename_duplicate_columns(df)\n",
    "        df.to_sql(table, engine, if_exists='append', index=False)\n",
    "\n",
    "# Function to fetch and save data\n",
    "def fetch_and_save_data_to_db(box_score_url, advanced_metrics_url, db_name='../TEMP/hockey_data.db'):\n",
    "    # Fetch HTML content for box score\n",
    "    box_score_response = requests.get(box_score_url)\n",
    "    box_score_html = box_score_response.text\n",
    "    \n",
    "    # Fetch HTML content for advanced metrics\n",
    "    advanced_metrics_response = requests.get(advanced_metrics_url)\n",
    "    advanced_metrics_html = advanced_metrics_response.text\n",
    "    \n",
    "    # Parse box score into list of DataFrames\n",
    "    box_score_dfs = parse_box_score(box_score_html)\n",
    "    \n",
    "    # Parse advanced metrics into list of DataFrames\n",
    "    advanced_metrics_dfs = parse_advanced_metrics_tables(advanced_metrics_html)\n",
    "    \n",
    "    # Combine all DataFrames into a list\n",
    "    all_dfs = box_score_dfs + advanced_metrics_dfs\n",
    "    \n",
    "    # Define table names for these DataFrames\n",
    "    table_names = ['scoring_summary', 'penalty_summary', 'goalie_stats', 'player_stats', 'line_chart', 'linescore',\n",
    "                   'advanced_metrics_team1', 'advanced_metrics_team2']\n",
    "    # for df in all_dfs:\n",
    "    #     # print(type(df))\n",
    "    #     print(df.columns.tolist())\n",
    "\n",
    "    # Create a game_id for the game and apply it to all dataframes\n",
    "    \n",
    "    # Game ID YYYMMDD-HomeTeam-AwayTeam\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    for df in all_dfs:\n",
    "        df['Game_ID'] = game_id\n",
    "    \n",
    "    # Save DataFrames to SQLite database\n",
    "    save_to_sqlite_db(all_dfs, table_names, db_name)\n",
    "    \n",
    "    return all_dfs\n",
    "\n",
    "# Replace with actual URLs\n",
    "base_url = 'https://www.collegehockeynews.com'\n",
    "box_score_url = 'https://www.collegehockeynews.com/box/final/20230211/mic/msu/'\n",
    "advanced_metrics_url = 'https://www.collegehockeynews.com/box/metrics.php?gd=96211'\n",
    "\n",
    "# Fetch, parse, and save data\n",
    "# all_dfs = fetch_and_save_data_to_db(box_score_url, advanced_metrics_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Game_Notes</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Home_Team_Link</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Away_Team_Link</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>OT</th>\n",
       "      <th>Box_Link</th>\n",
       "      <th>Metrics_Link</th>\n",
       "      <th>Day</th>\n",
       "      <th>Game_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Providence</td>\n",
       "      <td>/reports/team/Providence/46</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/box/final/20221001/won/prv/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022-10-01_Western Ontario_Providence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>/reports/team/Lake-Superior/24</td>\n",
       "      <td>2</td>\n",
       "      <td>Michigan Tech</td>\n",
       "      <td>/reports/team/Michigan-Tech/33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/box/final/20221001/lss/mtu/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022-10-01_Lake Superior_Michigan Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>/reports/team/Quinnipiac/47</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/box/final/20221001/tor/qui/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022-10-01_Toronto_Quinnipiac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colgate</td>\n",
       "      <td>/reports/team/Colgate/15</td>\n",
       "      <td>4</td>\n",
       "      <td>Rensselaer</td>\n",
       "      <td>/reports/team/Rensselaer/48</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/box/final/20221001/clg/ren/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022-10-01_Colgate_Rensselaer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sacred Heart</td>\n",
       "      <td>/reports/team/Sacred-Heart/51</td>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>/reports/team/Massachusetts/27</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/box/final/20221001/sac/uma/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022-10-01_Sacred Heart_Massachusetts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  Conference Game_Notes        Home_Team  \\\n",
       "0           0  2022-10-01  Exhibition        NaN  Western Ontario   \n",
       "1           1  2022-10-01  Exhibition        NaN    Lake Superior   \n",
       "2           2  2022-10-01  Exhibition        NaN          Toronto   \n",
       "3           3  2022-10-01  Exhibition        NaN          Colgate   \n",
       "4           4  2022-10-01  Exhibition        NaN     Sacred Heart   \n",
       "\n",
       "                   Home_Team_Link  Home_Score      Away_Team  \\\n",
       "0                             NaN           2     Providence   \n",
       "1  /reports/team/Lake-Superior/24           2  Michigan Tech   \n",
       "2                             NaN           2     Quinnipiac   \n",
       "3        /reports/team/Colgate/15           4     Rensselaer   \n",
       "4   /reports/team/Sacred-Heart/51           3  Massachusetts   \n",
       "\n",
       "                   Away_Team_Link  Away_Score   OT  \\\n",
       "0     /reports/team/Providence/46           5  NaN   \n",
       "1  /reports/team/Michigan-Tech/33           5  NaN   \n",
       "2     /reports/team/Quinnipiac/47           4  NaN   \n",
       "3     /reports/team/Rensselaer/48           2  NaN   \n",
       "4  /reports/team/Massachusetts/27           2  NaN   \n",
       "\n",
       "                       Box_Link Metrics_Link       Day  \\\n",
       "0  /box/final/20221001/won/prv/          NaN  Saturday   \n",
       "1  /box/final/20221001/lss/mtu/          NaN  Saturday   \n",
       "2  /box/final/20221001/tor/qui/          NaN  Saturday   \n",
       "3  /box/final/20221001/clg/ren/          NaN  Saturday   \n",
       "4  /box/final/20221001/sac/uma/          NaN  Saturday   \n",
       "\n",
       "                                  Game_ID  \n",
       "0   2022-10-01_Western Ontario_Providence  \n",
       "1  2022-10-01_Lake Superior_Michigan Tech  \n",
       "2           2022-10-01_Toronto_Quinnipiac  \n",
       "3           2022-10-01_Colgate_Rensselaer  \n",
       "4   2022-10-01_Sacred Heart_Massachusetts  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### Load the table of all games from the season from csv file\n",
    "\n",
    "games_df = pd.read_csv('../TEMP/2022-2023_season.csv')\n",
    "                       \n",
    "\n",
    "games_df.head()\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n",
      "Length of final column names: 23\n"
     ]
    }
   ],
   "source": [
    "### New sampling loop with better error handling and reporting\n",
    "sampled_games = games_df.sample(50)\n",
    "\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='game_scrape.log', level=logging.INFO)\n",
    "\n",
    "# Initialize some variables for error tracking\n",
    "error_count = 0\n",
    "error_games = []\n",
    "\n",
    "# Loop over sampled games and fetch data\n",
    "for idx, row in sampled_games.iterrows():\n",
    "    retries = 3  # Number of retries\n",
    "    success = False\n",
    "    \n",
    "    while retries > 0 and not success:\n",
    "        try:\n",
    "            box_score_url = base_url + row['Box_Link']\n",
    "            advanced_metrics_url = base_url + row['Metrics_Link']\n",
    "\n",
    "            # create a unique game id\n",
    "            game_id = str(row['Date']) + '-' + str(row['Home_Team']) + '-' + str(row['Away_Team'])\n",
    "            \n",
    "            logging.info(f\"Fetching data for game: {row['Home_Team']} vs {row['Away_Team']}\")\n",
    "            \n",
    "            # Your existing function to fetch and save data\n",
    "            all_dfs = fetch_and_save_data_to_db(box_score_url, advanced_metrics_url)\n",
    "            \n",
    "            # Add a common game_id here (see next section)\n",
    "            \n",
    "            # If reached here, the fetching was successful\n",
    "            success = True\n",
    "            \n",
    "            # Adaptive rate limiting can be added here\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:  # Network-related errors\n",
    "            logging.error(f\"Network error for game: {row['Home_Team']} vs {row['Away_Team']}. Error: {e}\")\n",
    "            retries -= 1\n",
    "            time.sleep(10)  # Wait for 10 seconds before retrying\n",
    "        \n",
    "        except Exception as e:  # Other exceptions\n",
    "            logging.error(f\"An error occurred for game: {row['Home_Team']} vs {row['Away_Team']}. Error: {e}\")\n",
    "            error_count += 1\n",
    "            error_games.append((row['Home_Team'], row['Away_Team']))\n",
    "            break  # Break the while loop; no retries for these types of errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# # SAMPLE CODE FUNCTION FOR PARSING GAMES> 1\n",
    "\n",
    "# import time\n",
    "# import random\n",
    "\n",
    "# # Randomly sample 5 games for this example\n",
    "# sampled_games = games_df.sample(n=50, random_state=42)\n",
    "\n",
    "# # Initialize some variables for error tracking\n",
    "# error_count = 0\n",
    "# error_games = []\n",
    "\n",
    "# # Base URL for the box score and metrics\n",
    "# base_url = 'https://www.collegehockeynews.com'\n",
    "\n",
    "# # Loop over sampled games and fetch data\n",
    "# for idx, row in sampled_games.iterrows():\n",
    "#     try:\n",
    "#         box_score_url = base_url + row['Box_Link']\n",
    "#         advanced_metrics_url = base_url + row['Metrics_Link']\n",
    "        \n",
    "#         print(f\"Fetching data for game: {row['Home_Team']} vs {row['Away_Team']}\")\n",
    "        \n",
    "#         # Your existing function to fetch and save data\n",
    "#         all_dfs = fetch_and_save_data_to_db(box_score_url, advanced_metrics_url)\n",
    "        \n",
    "#         # Rate limiting: Sleep for 6 seconds to ensure we don't exceed 10 requests per minute\n",
    "#         time.sleep(6)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred for game: {row['Home_Team']} vs {row['Away_Team']}\")\n",
    "#         print(f\"Error details: {e}\")\n",
    "#         error_count += 1\n",
    "#         error_games.append((row['Home_Team'], row['Away_Team']))\n",
    "\n",
    "# print(f\"\\nCompleted with {error_count} errors.\")\n",
    "# if error_count > 0:\n",
    "#     print(f\"Errors occurred for the following games: {error_games}\")\n",
    "\n",
    "\n",
    "# # Cre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
