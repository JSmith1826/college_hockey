{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "### This notebook is used to collect all season results available on College Hockey News\n",
    "\n",
    "# There Records begin with the 1901-1902 season and end with the most recent completed season 2022-2023\n",
    "## Seasons begining in 2002-2003 have box score links in the results table - seasons from then on can \n",
    "## use the code develope4d in the other notbook, years before that will need some adjusted code\n",
    "\n",
    "## Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "## Example URL: https://www.collegehockeynews.com/schedules/?season=19851986\n",
    "\n",
    "base_url = 'https://www.collegehockeynews.com/schedules/?season='\n",
    "\n",
    "# Construct the url for each season and store in a list\n",
    "mod_seasons = []\n",
    "\n",
    "for i in range(2002, 2023):\n",
    "    mod_seasons.append(base_url + str(i) + str(i+1))\n",
    "\n",
    "print(len(mod_seasons))\n",
    "\n",
    "old_seasons = []\n",
    "\n",
    "for i in range(1901, 2002):\n",
    "    old_seasons.append(base_url + str(i) + str(i+1))\n",
    "\n",
    "print(len(old_seasons))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_10992\\3339462295.py:94: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2002-10-01_Windsor_Green' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[row.Index, 'Game_ID'] = game_id\n"
     ]
    }
   ],
   "source": [
    "### Scraping code from initial scrape_and_explore notebook\n",
    "\n",
    "############### Test with one season ######################\n",
    "url = 'https://www.collegehockeynews.com/schedules/?season=20012002'\n",
    "\n",
    "\n",
    "def parse_modern_season(url):\n",
    "    \n",
    "    # Get the page with requests\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # select the table or tables\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Initialize variables\n",
    "    current_date = None\n",
    "    current_conference = None\n",
    "    game_notes = None\n",
    "\n",
    "    # Initialize an empty list to hold the data\n",
    "    # data = []\n",
    "\n",
    "    # Parse the table with BeautifulSoup\n",
    "\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find relevant information\n",
    "    for row in rows:\n",
    "        # Check for date row\n",
    "        if row.get('class') == ['stats-section']:\n",
    "            current_date = row.find('td').text.strip()\n",
    "        # Check for conference row\n",
    "        elif row.get('class') == ['sked-header']:\n",
    "            current_conference = row.find('td').text.strip()\n",
    "        # Check for game notes\n",
    "        elif len(row.find_all('td')) == 2:\n",
    "            game_notes = row.find_all('td')[1].text.strip()\n",
    "        # Process rows with game data\n",
    "        elif row.get('valign') == 'top':\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 9:\n",
    "                home_team = cells[0].text.strip()\n",
    "                home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "                home_score = cells[1].text.strip()\n",
    "                away_team = cells[3].text.strip()\n",
    "                away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "                away_score = cells[4].text.strip()\n",
    "                ot = cells[5].text.strip()\n",
    "                box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "                metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "                # Capture Game Notes\n",
    "                game_notes_cell = cells[-1].find('small')\n",
    "                game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "                # Append data to the list\n",
    "                data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "                game_notes = None  # Reset game notes for the next row\n",
    "            \n",
    "\n",
    "## Try running the function on the list of urls and create dataframe after looping through all seasons\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data = []\n",
    "\n",
    "for url in mod_seasons:\n",
    "    parse_modern_season(url)\n",
    "    # wait 2 seconds between requests\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "# ## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# # remove day of the week from date\n",
    "# # format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "## Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Function to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    game_id = f'{row.Date}_{home_team_abbr}_{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}_{row.Home_Team}_{row.Away_Team}', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24022\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "\n",
    "df.head(20)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv('../data/results_table_2002_2022_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for seasons 2001-2002 and earlier\n",
    "\n",
    "example_url = 'https://www.collegehockeynews.com/schedules/?season=19811982'\n",
    "\n",
    "## list of old seasons is stored in old_seasons\n",
    "\n",
    "\n",
    "# Update the function to include game notes and overtime information\n",
    "def parse_pre_2002_season(url):\n",
    "    # Get the page with requests\n",
    "    response = requests.get(url)\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Initialize variables\n",
    "    current_date = None\n",
    "    current_conference = None\n",
    "\n",
    "    # Initialize an empty list to hold the data\n",
    "    # data = []\n",
    "\n",
    "    # Parse the table with BeautifulSoup\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find relevant information\n",
    "    for row in rows:\n",
    "        # Check for date row\n",
    "        if row.get('class') == ['stats-section']:\n",
    "            current_date = row.find('td').text.strip()\n",
    "        # Check for conference row\n",
    "        elif row.get('class') == ['sked-header']:\n",
    "            current_conference = row.find('td').text.strip()\n",
    "        # Process rows with game data\n",
    "        elif row.get('valign') == 'top':\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 5:\n",
    "                home_team = cells[0].text.strip()\n",
    "                home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "                home_score = cells[1].text.strip()\n",
    "                away_team = cells[3].text.strip()\n",
    "                away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "                away_score = cells[4].text.strip()\n",
    "                \n",
    "                # Extract overtime information\n",
    "                ot = cells[5].text.strip() if cells[5].text.strip() else None\n",
    "                \n",
    "                # Extract game notes\n",
    "                game_notes_cell = cells[-1].find('small')\n",
    "                game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "                # Append data to the list\n",
    "                data.append([current_date, current_conference, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, game_notes])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "## Loop through the list of urls and run the function on each one\n",
    "data = []\n",
    "\n",
    "for url in old_seasons:\n",
    "    parse_pre_2002_season(url)\n",
    "    # wait 2 seconds between requests\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# create a dataframe from the data\n",
    "columns = ['Date', 'Conference', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Game_Notes']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "## Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Function to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    game_id = f'{row.Date}_{home_team_abbr}_{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}_{row.Home_Team}_{row.Away_Team}', axis=1)\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# # remove day of the week from date\n",
    "# # format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dataframe to a csv file\n",
    "df.to_csv('../data/results_table_1901_2001_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
