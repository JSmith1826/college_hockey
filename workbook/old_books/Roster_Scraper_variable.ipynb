{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "https://www.collegehockeynews.com/reports/roster/Michigan/31/19841985\n",
      "https://www.collegehockeynews.com/reports/roster/St-Lawrence/53/19841985\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# CHANGED to collect roster data previous years, not the current season\n",
    "\n",
    "## EXAMPLE https://www.collegehockeynews.com/reports/roster/Wisconsin/58/20172018\n",
    "## EXAMPLE https://www.collegehockeynews.com/reports/roster/Michigan-State/32/20172018\n",
    "\n",
    "\n",
    "url = 'https://www.collegehockeynews.com/reports/roster/Michigan-State/32'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "## Load results for season to get team links\n",
    "# Read the CSV file\n",
    "results = pd.read_csv('../../data/year_over_year/results_table_1901_2001_new.csv')\n",
    "\n",
    "## FILTER FOR A SINGLE SEASON\n",
    "# Make sure Date is a datetime object\n",
    "results['Date'] = pd.to_datetime(results['Date'])\n",
    "\n",
    "# Filter for a single season (august 1 {season} to july 31 {season+1})\n",
    "season = 1984\n",
    "\n",
    "# String of the season\n",
    "season_str = str(season) + '-' + str(season+1)\n",
    "results = results[(results['Date'] > str(season-1)+'-08-01') & (results['Date'] < str(season)+'-07-31')]\n",
    "\n",
    "# Concatenate the unique values in 'Home_Team_Link' and 'Away_Team_Link'\n",
    "team_links = pd.concat([results['Home_Team_Link'], results['Away_Team_Link']])\n",
    "\n",
    "# Drop duplicates and NaN values\n",
    "team_links = team_links.drop_duplicates().dropna()\n",
    "\n",
    "# Clean up the links - drop everything before the third slash - keep the team name and the school ID as string\n",
    "team = team_links.str.split('/', expand=True)[3]\n",
    "# ORIGINAL\n",
    "number = team_links.str.split('/', expand=True)[4]\n",
    "\n",
    "# NEW - Create a string for the year '{season}{season+1}'\n",
    "year = str(season) + str(season+1)\n",
    "# reconstruct the link and store in a new column\n",
    "team_links = 'https://www.collegehockeynews.com/reports/roster/' + team + '/' + number + '/' + year\n",
    "\n",
    "# reset the index\n",
    "team_links = team_links.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "team_links\n",
    "\n",
    "# team[0]\n",
    "\n",
    "# print the first link\n",
    "# print(team_links[0])\n",
    "\n",
    "team_links[0]\n",
    "# results.head()\n",
    "\n",
    "print(len(team_links))\n",
    "print(team_links[0])\n",
    "print(team_links[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split \"Last Team\" into \"Team\" and \"League\" with edge case handling\n",
    "def split_last_team(last_team):\n",
    "    # Use regular expression to extract team and league\n",
    "    match = re.search(r'(.+) \\((.+)\\)', last_team)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        # If no league is specified, return the team as is and leave league blank\n",
    "        return last_team, \"\"\n",
    "\n",
    "# Updated function to correctly capture the player's position and handle edge cases in \"Last Team\"\n",
    "def parse_and_transform_roster(html_content):\n",
    "    # Initialize BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the table with the roster\n",
    "    roster_table = soup.find('table', {'id': 'players'})\n",
    "\n",
    "    # Check if the table exists\n",
    "    if roster_table is None:\n",
    "        print(\"Skipped: The table doesn't exist.\")\n",
    "        return None\n",
    "    \n",
    "    # Extract headers\n",
    "    header_row = roster_table.find('thead').find('tr')\n",
    "    headers = [header.text.strip() for header in header_row.find_all('th')]\n",
    "    headers.append('Position')  # Add the Position column to headers\n",
    "    \n",
    "    # Initialize data list and current_position variable\n",
    "    data = []\n",
    "    current_position = None  # Initialize as None to later filter out irrelevant rows\n",
    "    \n",
    "    # Iterate through each row in the table\n",
    "    for row in roster_table.find_all('tr'):\n",
    "        if 'class' in row.attrs and 'stats-section' in row.attrs['class']:\n",
    "            current_position = row.text.strip()\n",
    "        else:\n",
    "            cells = row.find_all('td')\n",
    "            if cells and current_position:\n",
    "                row_data = [cell.text.strip() for cell in cells]\n",
    "                row_data.append(current_position)  # Add the current position to the row data\n",
    "                data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Check if DataFrame is empty or if key columns are missing\n",
    "    if df.empty or 'Last Team' not in df.columns or 'NHL Draft' not in df.columns:\n",
    "        print(\"Skipped: The DataFrame is empty or missing key columns.\")\n",
    "        return None\n",
    "    \n",
    "    # Cleanup: Remove rows where 'No.' column is not numeric\n",
    "    df = df[df['No.'].str.isnumeric()]\n",
    "    \n",
    "    # Cleanup: Drop the 'Pos' column\n",
    "    df.drop(columns=['Pos'], inplace=True)\n",
    "    \n",
    "    # Transform Height to Inches\n",
    "    df['Height_Inches'] = df['Ht.'].apply(convert_to_inches)\n",
    "\n",
    "    # Transform NHL Draft to Draft_Year, NHL_Team, and D_Round\n",
    "    # Transform NHL Draft to Draft_Year, NHL_Team, and D_Round\n",
    "    draft_result = df['NHL Draft'].apply(split_nhl_draft)\n",
    "\n",
    "    # Check if there are enough values to unpack\n",
    "    if len(draft_result) > 0:\n",
    "        df['Draft_Year'], df['NHL_Team'], df['D_Round'] = zip(*draft_result)\n",
    "    else:\n",
    "        # Handle the case when result is empty\n",
    "        df['Draft_Year'], df['NHL_Team'], df['D_Round'] = [None] * len(df), [None] * len(df), [None] * len(df)\n",
    "\n",
    "    df.drop(columns=['NHL Draft'], inplace=True) # Drop the original NHL Draft column\n",
    "    \n",
    "    # Handle edge cases in \"Last Team\" to split into \"Team\" and \"League\"\n",
    "    df['Team'], df['League'] = zip(*df['Last Team'].apply(split_last_team))\n",
    "    df.drop(columns=['Last Team'], inplace=True)\n",
    "    \n",
    "    # Rename the trouble column Hometown\\nLast Team\\nNHL Draft\n",
    "    df.rename(columns={'Hometown\\nLast Team\\nNHL Draft': 'Hometown'}, inplace=True)\n",
    "\n",
    "    # assign data types No. Wt. and Height_Inches to int, DOB to datetime\n",
    "    int_list = ['No.', 'Wt.', 'Height_Inches']\n",
    "    # Convert columns to numeric, coercing errors to NaN\n",
    "    df[int_list] = df[int_list].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Replace NaNs with a default value for specific columns\n",
    "    default_value = 0\n",
    "    df[int_list] = df[int_list].fillna(value=default_value)\n",
    "\n",
    "    # Confirm that NaNs are filled\n",
    "    print(df[int_list].isna().sum())  # Should output all zeros\n",
    "\n",
    "    # Convert the columns to integers\n",
    "    df[int_list] = df[int_list].astype(int)\n",
    "\n",
    "    # df = df[df['Height_Inches'].notna()]  # Assuming convert_to_inches returns None for bad values\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to split \"NHL Draft\" into \"Draft_Year\", \"NHL_Team\", and \"D_Round\"\n",
    "def split_nhl_draft(nhl_draft):\n",
    "    try:\n",
    "        draft_year, nhl_team, d_round = nhl_draft.split('-')\n",
    "        return draft_year, nhl_team, d_round\n",
    "    except ValueError:\n",
    "        # Handle missing or incomplete data\n",
    "        return None, None, None\n",
    "\n",
    "# # Test the function\n",
    "# test_values = ['2022-WSH-7', '', '2021-DET']\n",
    "# [split_nhl_draft(val) for val in test_values]\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert height in \"ft-in\" format to total inches\n",
    "def convert_to_inches(height_str):\n",
    "    try:\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return (feet * 12) + inches\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END HIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 1 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 2 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 3 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 4 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 5 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 6 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 7 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 8 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 9 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 10 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 11 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 12 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 13 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 14 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 15 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 16 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 17 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 18 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 19 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 20 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 21 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 22 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 23 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 24 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 25 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 26 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 27 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 28 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 29 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 30 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 31 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 32 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 33 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 34 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 35 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 36 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 37 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 38 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 39 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n",
      "Processing team 40 of 40\n",
      "No.              0\n",
      "Wt.              0\n",
      "Height_Inches    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correcting the code to handle the 'Team' and 'Last Team' columns properly\n",
    "\n",
    "## Loop through the team links and parse the roster data \n",
    "### Notes: save the roster link to the dataframe and add the team name and school ID\n",
    "\n",
    "roster_dfs = []  # Assuming this list exists to store each roster DataFrame\n",
    "\n",
    "# Extract team names from team_links\n",
    "team_names = pd.Series(team_links).str.split('/', expand=True)[5]\n",
    "\n",
    "\n",
    "for i, link in enumerate(team_links):\n",
    "    print(f'Processing team {i+1} of {len(team_links)}')\n",
    "    \n",
    "    try:\n",
    "        # Make GET request to team link\n",
    "        r = requests.get(link)\n",
    "        r.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        html_content = r.text\n",
    "        \n",
    "        # Parse and transform the roster data\n",
    "        roster_df = parse_and_transform_roster(html_content)\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error during the request for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the data for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the DataFrame exists (i.e., the page had content)\n",
    "    if roster_df is None:\n",
    "        print(f\"Skipping team {i+1} due to missing or empty data.\")\n",
    "        continue  # Skip this iteration and move to the next one\n",
    "\n",
    "    try:\n",
    "        # Reset the index if it's not unique\n",
    "        roster_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Add the team name\n",
    "        current_team = team_names.iloc[i]  # Extract the current team name\n",
    "        roster_df['Current Team'] = current_team  # Add it to the DataFrame\n",
    "\n",
    "        # Add a column with the season\n",
    "        roster_df['Season'] = season\n",
    "        \n",
    "        # Add the roster DataFrame to the list\n",
    "        roster_dfs.append(roster_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error working with the DataFrame for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "\n",
    "# Assuming the last dataframe processed is the one of interest (can be adjusted later)\n",
    "# roster_df = roster_dfs[-1]\n",
    "\n",
    "# Add all the DataFrames in the list to a single DataFrame\n",
    "roster_df = pd.concat(roster_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height_Inches</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>NHL_Team</th>\n",
       "      <th>D_Round</th>\n",
       "      <th>Last Team</th>\n",
       "      <th>League</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Bill Brauer</td>\n",
       "      <td>0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>6-3</td>\n",
       "      <td>205</td>\n",
       "      <td>2/17/1964</td>\n",
       "      <td>Fort Bragg, N.C.</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Todd Carlile</td>\n",
       "      <td>0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>5-11</td>\n",
       "      <td>174</td>\n",
       "      <td>1/22/1964</td>\n",
       "      <td>St. Paul, Minn.</td>\n",
       "      <td>71</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mark Gobuty</td>\n",
       "      <td>0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td></td>\n",
       "      <td>5-10</td>\n",
       "      <td>187</td>\n",
       "      <td></td>\n",
       "      <td>Winnipeg, Man.</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Pat Goff</td>\n",
       "      <td>0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>6-1</td>\n",
       "      <td>185</td>\n",
       "      <td>6/29/1964</td>\n",
       "      <td>St. Paul, Minn.</td>\n",
       "      <td>73</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Greg Hudas</td>\n",
       "      <td>0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td></td>\n",
       "      <td>6-5</td>\n",
       "      <td>190</td>\n",
       "      <td>2/15/1964</td>\n",
       "      <td>Troy, Mich.</td>\n",
       "      <td>77</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Current Team        Player  No    Position  Yr    Ht   Wt        DOB  \\\n",
       "0     Michigan   Bill Brauer   0  Defensemen  Jr   6-3  205  2/17/1964   \n",
       "1     Michigan  Todd Carlile   0  Defensemen  Jr  5-11  174  1/22/1964   \n",
       "2     Michigan   Mark Gobuty   0  Defensemen      5-10  187              \n",
       "3     Michigan      Pat Goff   0  Defensemen  Jr   6-1  185  6/29/1964   \n",
       "4     Michigan    Greg Hudas   0  Defensemen       6-5  190  2/15/1964   \n",
       "\n",
       "           Hometown  Height_Inches Draft_Year NHL_Team D_Round Last Team  \\\n",
       "0  Fort Bragg, N.C.             75       None     None    None             \n",
       "1   St. Paul, Minn.             71       None     None    None             \n",
       "2    Winnipeg, Man.             70       None     None    None             \n",
       "3   St. Paul, Minn.             73       None     None    None             \n",
       "4       Troy, Mich.             77       None     None    None             \n",
       "\n",
       "  League  \n",
       "0         \n",
       "1         \n",
       "2         \n",
       "3         \n",
       "4         "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Further transformations\n",
    "roster_df.columns = roster_df.columns.str.replace('.', '')  # Remove periods in column names\n",
    "roster_df['Name'] = roster_df['Name'].str.split(',').str[::-1].str.join(' ')  # Convert 'Last, First' to 'First Last'\n",
    "roster_df['Player'] = roster_df['Name']  # Store the Player name as 'First Last'\n",
    "roster_df['Player'] = roster_df['Player'].str.replace(u'\\xa0', u' ').str.strip()  # Cleanup player name\n",
    "roster_df = roster_df.drop(['Name'], axis=1)  # Drop the original 'Name' column\n",
    "\n",
    "# Renaming 'Team' to 'Last Team' if it exists in the DataFrame\n",
    "if 'Team' in roster_df.columns:\n",
    "    roster_df.rename(columns={'Team': 'Last Team'}, inplace=True)\n",
    "\n",
    "# Checking if 'Last Team' exists in the dataframe before reordering\n",
    "if 'Last Team' not in roster_df.columns:\n",
    "    print(\"'Last Team' column not found in the DataFrame. Please check the data extraction process.\")\n",
    "else:\n",
    "    # Reorder columns without duplicate 'Team'\n",
    "    roster_df = roster_df[['Current Team', 'Player', 'No', 'Position', 'Yr', 'Ht', 'Wt', 'DOB', \n",
    "                           'Hometown', 'Height_Inches', 'Draft_Year', 'NHL_Team', 'D_Round', 'Last Team', 'League']]\n",
    "\n",
    "roster_df.head() if 'Last Team' in roster_df.columns else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tansforming some other output and save\n",
    "\n",
    "# Create a new column with the season\n",
    "roster_df['Season'] = season\n",
    "\n",
    "# roster_df.head()\n",
    "# Remove and dashes from the Current Team column\n",
    "roster_df['Current Team'] = roster_df['Current Team'].str.replace('-', ' ')\n",
    "# Rename to Team\n",
    "roster_df.rename(columns={'Current Team': 'Team'}, inplace=True)\n",
    "\n",
    "\n",
    "# Save the roster data to a CSV file\n",
    "roster_df.to_csv(f'../../TEMP/roster_data_{season}.csv', index=False)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the roster data to a CSV file\n",
    "# roster_df.to_csv('../../TEMP/roster_data_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Name Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\data\\rosters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m roster_df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m## Save to a CSV file\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mroster_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/rosters/2023_master_roster.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\data\\rosters'"
     ]
    }
   ],
   "source": [
    "# Remove any periods in the column names\n",
    "roster_df.columns = roster_df.columns.str.replace('.', '')\n",
    "\n",
    "# ## Change Name Column From Last, First to First Last\n",
    "# roster_df['Name'] = roster_df['Name'].str.split(',').str[::-1].str.join(' ')\n",
    "\n",
    "# # Store the Player name as First Last in a column called Player\n",
    "# roster_df['Player'] = roster_df['Name']\n",
    "\n",
    "\n",
    "# Take out those annoying character if there are any\n",
    "# Replace non-breaking spaces with regular spaces in the player names\n",
    "roster_df['Player'] = roster_df['Player'].str.replace(u'\\xa0', u' ')\n",
    "\n",
    "# Strip the leading and trailing whitespace\n",
    "roster_df['Player'] = roster_df['Player'].str.strip()\n",
    "\n",
    "# Drop Name column and Reorder columns\n",
    "# roster_df = roster_df.drop(['Name'], axis=1)\n",
    "\n",
    "# Reorder columns\n",
    "roster_df = roster_df[['Team', 'Player', 'No', 'Position', 'Yr', 'Ht', 'Wt', 'DOB', \n",
    "                       'Hometown', 'Position', 'Height_Inches', \n",
    "                       'Draft_Year', 'NHL_Team', 'D_Round', 'Last Team', 'League']]\n",
    "roster_df.head()\n",
    "\n",
    "## Save to a CSV file\n",
    "roster_df.to_csv('../data/rosters/2023_master_roster.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# #### \n",
    "# master_roster_df = pd.read_csv('..\\\\data\\\\rosters\\\\2023_master_roster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine the master DataFrame\n",
    "\n",
    "# Check the number of rows and columns\n",
    "print(master_roster_df.shape)\n",
    "\n",
    "# Check the data types\n",
    "print(master_roster_df.dtypes)\n",
    "\n",
    "# Check the first few rows\n",
    "master_roster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Valuecounts of Hometown, Last Team, League\n",
    "master_roster_df['Hometown'].value_counts()\n",
    "\n",
    "# master_roster_df['Last Team'].value_counts()\n",
    "\n",
    "# master_roster_df['League'].value_counts()\n",
    "\n",
    "# Unique Count of Home Towns\n",
    "master_roster_df['Hometown'].nunique()\n",
    "# store the unique hometowns in a list\n",
    "unique_hometowns = master_roster_df['Hometown'].unique()\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Show the ditrobution of birthdates by month\n",
    "\n",
    "# make sure the DOB column is a datetime\n",
    "master_roster_df['DOB'] = pd.to_datetime(master_roster_df['DOB'])\n",
    "# Extract the month from the DOB column\n",
    "master_roster_df['Month'] = master_roster_df['DOB'].dt.month\n",
    "\n",
    "# Plot the distribution of months\n",
    "master_roster_df['Month'].plot.hist(bins=12, title='Distribution of Birth Months')\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "## Show the distribution of weights\n",
    "master_roster_df['Wt.'].plot.hist(bins=20, range=(140,250), title='Distribution of Weights')\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "# Show the distribution of heights with range of 60 to 90 inches\n",
    "master_roster_df['Height_Inches'].plot.hist(bins=30, range=(65, 85), title='Distribution of Heights')\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Box Plot of Height by Position # y range is 65 to 90\n",
    "import seaborn as sns\n",
    "\n",
    "box_data = master_roster_df\n",
    "\n",
    "# filter to the\n",
    "# create a boxplot of height by position - limit the y range to 65 to 90\n",
    "\n",
    "sns.boxplot(x='Position', y='Height_Inches', data=box_data, showfliers=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## BIN PLAYERS BY HEIGHT AND SHOW THE DISTRIBUTION OF WEIGHTS IN EACH BIN\n",
    "\n",
    "# Create the bins\n",
    "master_roster_df['Height_Bins'] = pd.cut(master_roster_df['Height_Inches'], bins=range(65, 80, 1))\n",
    "\n",
    "# Group by bins and make lists of weights in each bin\n",
    "grouped = master_roster_df.groupby('Height_Bins')['Wt.'].apply(list)\n",
    "\n",
    "# Create a new DataFrame where each row corresponds to a bin\n",
    "# and each entry in the row is a weight from that bin\n",
    "df2 = pd.DataFrame({name: pd.Series(data) for name, data in grouped.items()})\n",
    "\n",
    "# Now you can create a horizontal boxplot\n",
    "df2.boxplot(showfliers=False, vert=False)\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height Bins')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a scatter plot of height vs weight just for Michigan State\n",
    "# Filter the DataFrame to just Michigan State\n",
    "msu_df = master_roster_df[master_roster_df['School'] == 'Michigan-State']\n",
    "\n",
    "# Create the scatter plot\n",
    "msu_df.plot.scatter(x='Height_Inches', y='Wt.', title='Michigan State Height vs Weight')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "BRAKE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Simple Map of Hometowns\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = master_roster_df\n",
    "\n",
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"hockey_hometowns\")\n",
    "\n",
    "# Geocode hometowns to get latitude and longitude - try then continue if error\n",
    "try:\n",
    "    df['Coordinates'] = df['Hometown'].apply(geolocator.geocode).apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Split coordinates into latitude and longitude\n",
    "df[['Latitude', 'Longitude', '_']] = pd.DataFrame(df['Coordinates'].tolist(), index=df.index)\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the geodataframe to a shapefile for use in QGIS\n",
    "gdf.to_file('..\\\\TEMP\\\\2023_master_roster_with coordinates.shp')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
