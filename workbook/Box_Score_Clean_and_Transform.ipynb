{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Cleaning Book To Use on pre 2021 Box Score File\n",
    "- these files don't have advanced metrics table \n",
    "\n",
    "- code adapted from original clean_and_transform workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_11416\\1389338785.py:12: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  roster = pd.read_csv(roster_path)\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to master roster file\n",
    "roster_path = os.path.join(os.getcwd(), \"..\", \"data\", 'rosters', 'all_time_combined_roster.csv')\n",
    "# Read in the master roster file\n",
    "roster = pd.read_csv(roster_path)\n",
    "# roster.head()\n",
    "\n",
    "# Set Path to db file \n",
    "db_path = os.path.join(os.getcwd(), \"..\", 'TEMP', 'Box_Scores_2002_v2.db')\n",
    "\n",
    "####################\n",
    "## Set the season \n",
    "\n",
    "season_year = 2002\n",
    "\n",
    "####################\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_path)\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "# Print table names to check connection\n",
    "# cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# print(cur.fetchall())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Filter the roster to the season of interest\n",
    "roster_df = roster[roster['Season'] == season_year]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of Team Primary Names to Abbreviations\n",
    "\n",
    "- Needed to Add IVY teams becuase of low amount of games. will have to do for harvard, yale, ect next week\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe from SQL query\n",
    "df = pd.read_sql_query(\"SELECT * FROM scoring_summary\", conn)\n",
    "\n",
    "# Function to count the occurrences of primary team names for unmatched abbreviations\n",
    "def count_primary_names_for_abbreviation(abbreviation):\n",
    "    filtered_rows = df[df['Team'] == abbreviation]\n",
    "    team_counts = {}\n",
    "    \n",
    "    for _, row in filtered_rows.iterrows():\n",
    "        teams = row['game_id'].split('-')[-2:]\n",
    "        for team in teams:\n",
    "            if team not in team_counts:\n",
    "                team_counts[team] = 0\n",
    "            team_counts[team] += 1\n",
    "            \n",
    "    return team_counts\n",
    "\n",
    "\n",
    "# Attempt to match abbreviations to primary names based on substrings and common naming conventions\n",
    "matched_dict = {}\n",
    "unmatched_abbreviations = []\n",
    "\n",
    "for abbreviation in df['Team'].unique():\n",
    "\n",
    "\n",
    "\n",
    "# Match the abbreviation to the primary team name with the highest occurrence\n",
    "\n",
    "    team_counts = count_primary_names_for_abbreviation(abbreviation)\n",
    "    # Get the team with the highest count\n",
    "    matched_team = max(team_counts, key=team_counts.get)\n",
    "    matched_dict[abbreviation] = matched_team\n",
    "\n",
    "# matched_dict\n",
    "\n",
    "# Manually fix the unmatched abbreviations - IVY League Teams with no of very few games throw a wrench in the above method\n",
    "# Brown: Brown\n",
    "# Cornell: Cornell\n",
    "\n",
    "# Make those substitutions\n",
    "matched_dict['Brown'] = 'Brown'\n",
    "matched_dict['Cornell'] = 'Cornell'\n",
    "# yale\n",
    "matched_dict['Yale'] = 'Yale'\n",
    "# princeton\n",
    "matched_dict['Princeton'] = 'Princeton'\n",
    "\n",
    "# harvard\n",
    "matched_dict['Harvard'] = 'Harvard'\n",
    "# columbia\n",
    "matched_dict['Columbia'] = 'Columbia'\n",
    "\n",
    "# dartmouth\n",
    "matched_dict['Dartmouth'] = 'Dartmouth'\n",
    "\n",
    "# penn\n",
    "matched_dict['Penn'] = 'Penn'\n",
    "\n",
    "# BC\n",
    "matched_dict['BC'] = 'Boston College'\n",
    "\n",
    "\n",
    "\n",
    "# matched_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('game_details',), ('scoring_summary',), ('penalty_summary',), ('goalie_stats',), ('player_stats',), ('linescore',)]\n"
     ]
    }
   ],
   "source": [
    "# Print database table names and check to see if they are locked\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cur.fetchall())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Home and Away Columns to game_details table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Read the game_details table into a DataFrame\n",
    "df_game_details = pd.read_sql(\"SELECT * FROM game_details\", conn)\n",
    "\n",
    "# Step 2: Create new columns for Home and Away Teams by parsing Game_ID\n",
    "df_game_details['Away_Team'] = df_game_details['game_id'].apply(lambda x: x.split('-')[3])\n",
    "df_game_details['Home_Team'] = df_game_details['game_id'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "# Step 3: Write this updated DataFrame back to the game_details table\n",
    "df_game_details.to_sql('game_details', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up The Column Names and extra header rows in the Player Stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "# Define a dictionary for column renaming\n",
    "column_renames = {\n",
    "    'Pt.': 'Pts',\n",
    "    '+/-': 'plus_minus'\n",
    "}\n",
    "\n",
    "# If There is a player_stats table in the database\n",
    "if len(player_stats_df) > 0:\n",
    "# Rename columns based on the dictionary\n",
    "    player_stats_df.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "\n",
    "# Drop rows where Team name is in the Player column\n",
    "    player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "## Change the Column names to be easy to work with\n",
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "    player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "    if 'Pt.' in player_stats_df.columns:\n",
    "        player_stats_df.rename(columns={'Pt.': 'Pts'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Column 'Pt.' not found.\")\n",
    "\n",
    "    if '+/-' in player_stats_df.columns:\n",
    "        player_stats_df.rename(columns={'+/-': 'plus_minus'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Column '+/-' not found.\")\n",
    "\n",
    "    print(len(player_stats_df))\n",
    "\n",
    "    # Drop rows if Team name is in the player column\n",
    "    # If ['Team'] is the same as ['Player'] then drop that row\n",
    "    player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "    # add the dataframe back to the database\n",
    "    player_stats_df.to_sql('player_stats', conn, if_exists='replace', index=False)\n",
    "\n",
    "    # print(len(player_stats_df))\n",
    "    #################################\n",
    "    # player_stats_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Iona'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df_linescores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM linescore\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Apply the dictionary to the Team column\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df_linescores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_linescores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatched_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m df_linescores\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m df_linescores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM linescore\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Apply the dictionary to the Team column\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df_linescores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_linescores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mmatched_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      8\u001b[0m df_linescores\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Iona'"
     ]
    }
   ],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "df_linescores = pd.read_sql(\"SELECT * FROM linescore\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "df_linescores['Team'] = df_linescores['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "df_linescores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Table & Scoring Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Team'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Team'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m df_penalty \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM penalty_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Apply the dictionary to the Team column\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#$ Skip if not found\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df_penalty[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_penalty\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: matched_dict[x])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Apply same method to scorring_summary:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m df_scoring \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM scoring_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Team'"
     ]
    }
   ],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "\n",
    "df_penalty = pd.read_sql(\"SELECT * FROM penalty_summary\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "#$ Skip if not found\n",
    "\n",
    "df_penalty['Team'] = df_penalty['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "    \n",
    "\n",
    "# Apply same method to scorring_summary:\n",
    "df_scoring = pd.read_sql(\"SELECT * FROM scoring_summary\", conn)\n",
    "df_scoring['Team'] = df_scoring['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "# Add Home and Away Team columns to scoring_summary\n",
    "df_scoring['Away_Team'] = df_scoring['game_id'].apply(lambda x: x.split('-')[3])\n",
    "df_scoring['Home_Team'] = df_scoring['game_id'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "\n",
    "## Add each table back to database\n",
    "# Write the updated linescores DataFrame back to the linescore table\n",
    "df_linescores.to_sql('linescore', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated penalty DataFrame back to the penalty_summary table\n",
    "df_penalty.to_sql('penalty_summary', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated scoring DataFrame back to the scoring_summary table\n",
    "df_scoring.to_sql('scoring_summary', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A NEW TABLE WITH AGGRIGATED PLAYER STATS YEAR TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use player_stats_df from here on, instead of running another SQL query.\n",
    "# df_player_stats = player_stats_df.copy()\n",
    "\n",
    "# # If the player_stats table is empty do the following\n",
    "# if len(df_player_stats) == 0:\n",
    "\n",
    "# # Clean up the name format in player_stats for easier matching\n",
    "# # Replace the non-breaking space with a regular space\n",
    "# df_player_stats['Clean_Player'] = df_player_stats['Player'].apply(lambda x: x.replace('\\xa0', ' '))\n",
    "\n",
    "# # Remove rows where Player is the team name (e.g., \"Michigan State\")\n",
    "# df_player_stats_cleaned = df_player_stats[df_player_stats['Player'] != df_player_stats['Team']]\n",
    "\n",
    "# # Convert relevant columns to integers for correct aggregation\n",
    "# cols_to_convert = ['G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM']\n",
    "# for col in cols_to_convert:\n",
    "#     df_player_stats_cleaned[col] = pd.to_numeric(df_player_stats_cleaned[col], errors='coerce')\n",
    "\n",
    "# # Aggregate the data for year-to-date stats\n",
    "# # Add a column for counting the number of games each player has played\n",
    "# agg_player_stats_corrected_with_games = df_player_stats_cleaned.groupby(['Clean_Player', 'Team']).agg({\n",
    "#     'G': 'sum',\n",
    "#     'A': 'sum',\n",
    "#     'Pts': 'sum',\n",
    "#     'plus_minus': 'sum',\n",
    "#     'Sh': 'sum',\n",
    "#     'PIM': 'sum',\n",
    "#     'game_id': 'count'  # Counting the number of unique Game_IDs for each player\n",
    "# }).reset_index()\n",
    "\n",
    "# # Rename the Game_ID column to Games_Played\n",
    "# agg_player_stats_corrected_with_games.rename(columns={'game_id': 'Games_Played'}, inplace=True)\n",
    "\n",
    "# # Save the updated aggregated data back to the database, replacing the existing table\n",
    "# agg_player_stats_corrected_with_games.to_sql('player_stats_ytd', conn, if_exists='replace', index=False)\n",
    "\n",
    "# # Verify by loading some sample data from the updated table\n",
    "# sample_updated_ytd = pd.read_sql_query(\"SELECT * FROM player_stats_ytd LIMIT 5;\", conn)\n",
    "# sample_updated_ytd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Roster data to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scoring_summary',\n",
       " 'penalty_summary',\n",
       " 'goalie_stats',\n",
       " 'player_stats',\n",
       " 'linescore',\n",
       " 'game_details',\n",
       " 'master_roster']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## SET THE ROSTER DATAFRAME TO THE CORRECT YEAR ####################\n",
    "## MATCH THE DATAFRAME NAMES\n",
    "df_master_roster = roster_df.copy()\n",
    "\n",
    "\n",
    "# Clean up the name formats for joining\n",
    "# Master roster: Convert \"Last Name, First Name\" to \"First Name Last Name\"\n",
    "# df_master_roster['Clean_Name'] = df_master_roster['Player'].apply(lambda x: ' '.join(reversed(x.split(', '))))\n",
    "\n",
    "# Rename Player to Clean_Name\n",
    "df_master_roster.rename(columns={'Player': 'Clean_Name'}, inplace=True)\n",
    "# Rename School to Team\n",
    "df_master_roster.rename(columns={'School': 'Team'}, inplace=True)\n",
    "\n",
    "# Clean up the Team column, remove '-' and replace with ' '\n",
    "# df_master_roster['School'] = df_master_roster['Team'].apply(lambda x: x.replace('-', ' '))\n",
    "\n",
    "## If there are an period in the column names, remove them\n",
    "df_master_roster.columns = df_master_roster.columns.str.replace('.', '')\n",
    "\n",
    "### Finally add the roster to the database as it's own table\n",
    "\n",
    "df_master_roster['SeasonYear'] = season_year\n",
    "\n",
    "# Save the roster data as a new table in the database\n",
    "roster_table_name = 'master_roster'\n",
    "df_master_roster.to_sql(roster_table_name, conn, if_exists='replace', index=False)\n",
    "############################################################\n",
    "\n",
    "# Verify by listing all the tables in the database again\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(tables_query).fetchall()\n",
    "table_names_updated = [table[0] for table in tables]\n",
    "table_names_updated\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
