{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Cleaning Book To Use on pre 2021 Box Score File\n",
    "- these files don't have advanced metrics table \n",
    "\n",
    "- code adapted from original clean_and_transform workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_6652\\2039794223.py:12: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  roster = pd.read_csv(roster_path)\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to master roster file\n",
    "roster_path = os.path.join(os.getcwd(), \"..\", \"data\", 'rosters', 'all_time_combined_roster.csv')\n",
    "# Read in the master roster file\n",
    "roster = pd.read_csv(roster_path)\n",
    "# roster.head()\n",
    "\n",
    "# Set Path to db file \n",
    "db_path = os.path.join(os.getcwd(), \"..\", 'TEMP', 'Box_Scores_2016_v1.db')\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_path)\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "# Print table names to check connection\n",
    "# cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# print(cur.fetchall())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## Set the season \n",
    "\n",
    "season_year = 2016\n",
    "\n",
    "####################\n",
    "\n",
    "# Filter the roster to the season of interest\n",
    "roster_df = roster[roster['Season'] == season_year]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of Team Primary Names to Abbreviations\n",
    "\n",
    "- Needed to Add IVY teams becuase of low amount of games. will have to do for harvard, yale, ect next week\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM scoring_summary': no such table: scoring_summary",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:2262\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2262\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: scoring_summary",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Create dataframe from SQL query\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM scoring_summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Function to count the occurrences of primary team names for unmatched abbreviations\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_primary_names_for_abbreviation\u001b[39m(abbreviation):\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:2326\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2317\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2324\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2326\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2327\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:2274\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2273\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM scoring_summary': no such table: scoring_summary"
     ]
    }
   ],
   "source": [
    "## Create dataframe from SQL query\n",
    "df = pd.read_sql_query(\"SELECT * FROM scoring_summary\", conn)\n",
    "\n",
    "# Function to count the occurrences of primary team names for unmatched abbreviations\n",
    "def count_primary_names_for_abbreviation(abbreviation):\n",
    "    filtered_rows = df[df['Team'] == abbreviation]\n",
    "    team_counts = {}\n",
    "    \n",
    "    for _, row in filtered_rows.iterrows():\n",
    "        teams = row['Game_ID'].split('-')[-2:]\n",
    "        for team in teams:\n",
    "            if team not in team_counts:\n",
    "                team_counts[team] = 0\n",
    "            team_counts[team] += 1\n",
    "            \n",
    "    return team_counts\n",
    "\n",
    "\n",
    "# Attempt to match abbreviations to primary names based on substrings and common naming conventions\n",
    "matched_dict = {}\n",
    "unmatched_abbreviations = []\n",
    "\n",
    "for abbreviation in df['Team'].unique():\n",
    "\n",
    "\n",
    "\n",
    "# Match the abbreviation to the primary team name with the highest occurrence\n",
    "\n",
    "    team_counts = count_primary_names_for_abbreviation(abbreviation)\n",
    "    # Get the team with the highest count\n",
    "    matched_team = max(team_counts, key=team_counts.get)\n",
    "    matched_dict[abbreviation] = matched_team\n",
    "\n",
    "# matched_dict\n",
    "\n",
    "# Manually fix the unmatched abbreviations - IVY League Teams with no of very few games throw a wrench in the above method\n",
    "# Brown: Brown\n",
    "# Cornell: Cornell\n",
    "\n",
    "# Make those substitutions\n",
    "matched_dict['Brown'] = 'Brown'\n",
    "matched_dict['Cornell'] = 'Cornell'\n",
    "# yale\n",
    "matched_dict['Yale'] = 'Yale'\n",
    "# princeton\n",
    "matched_dict['Princeton'] = 'Princeton'\n",
    "\n",
    "# harvard\n",
    "matched_dict['Harvard'] = 'Harvard'\n",
    "# columbia\n",
    "matched_dict['Columbia'] = 'Columbia'\n",
    "\n",
    "# dartmouth\n",
    "matched_dict['Dartmouth'] = 'Dartmouth'\n",
    "\n",
    "# penn\n",
    "matched_dict['Penn'] = 'Penn'\n",
    "\n",
    "# BC\n",
    "matched_dict['BC'] = 'Boston College'\n",
    "\n",
    "\n",
    "\n",
    "# matched_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print database table names and check to see if they are locked\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cur.fetchall())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Home and Away Columns to game_details table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the game_details table into a DataFrame\n",
    "df_game_details = pd.read_sql(\"SELECT * FROM game_details\", conn)\n",
    "\n",
    "# Step 2: Create new columns for Home and Away Teams by parsing Game_ID\n",
    "df_game_details['Away_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_game_details['Home_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "# Step 3: Write this updated DataFrame back to the game_details table\n",
    "df_game_details.to_sql('game_details', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up The Column Names and extra header rows in the Player Stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "# Define a dictionary for column renaming\n",
    "column_renames = {\n",
    "    'Pt.': 'Pts',\n",
    "    '+/-': 'plus_minus'\n",
    "}\n",
    "\n",
    "# Rename columns based on the dictionary\n",
    "player_stats_df.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "\n",
    "# Drop rows where Team name is in the Player column\n",
    "player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "## Change the Column names to be easy to work with\n",
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "if 'Pt.' in player_stats_df.columns:\n",
    "    player_stats_df.rename(columns={'Pt.': 'Pts'}, inplace=True)\n",
    "else:\n",
    "    print(\"Column 'Pt.' not found.\")\n",
    "\n",
    "if '+/-' in player_stats_df.columns:\n",
    "    player_stats_df.rename(columns={'+/-': 'plus_minus'}, inplace=True)\n",
    "else:\n",
    "    print(\"Column '+/-' not found.\")\n",
    "\n",
    "print(len(player_stats_df))\n",
    "\n",
    "# Drop rows if Team name is in the player column\n",
    "# If ['Team'] is the same as ['Player'] then drop that row\n",
    "player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "# add the dataframe back to the database\n",
    "player_stats_df.to_sql('player_stats', conn, if_exists='replace', index=False)\n",
    "\n",
    "# print(len(player_stats_df))\n",
    "#################################\n",
    "# player_stats_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "df_linescores = pd.read_sql(\"SELECT * FROM linescore\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "df_linescores['Team'] = df_linescores['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "df_linescores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Table & Scoring Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "\n",
    "df_penalty = pd.read_sql(\"SELECT * FROM penalty_summary\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "#$ Skip if not found\n",
    "\n",
    "df_penalty['Team'] = df_penalty['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "    \n",
    "\n",
    "# Apply same method to scorring_summary:\n",
    "df_scoring = pd.read_sql(\"SELECT * FROM scoring_summary\", conn)\n",
    "df_scoring['Team'] = df_scoring['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "# Add Home and Away Team columns to scoring_summary\n",
    "df_scoring['Away_Team'] = df_scoring['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_scoring['Home_Team'] = df_scoring['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "\n",
    "## Add each table back to database\n",
    "# Write the updated linescores DataFrame back to the linescore table\n",
    "df_linescores.to_sql('linescore', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated penalty DataFrame back to the penalty_summary table\n",
    "df_penalty.to_sql('penalty_summary', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated scoring DataFrame back to the scoring_summary table\n",
    "df_scoring.to_sql('scoring_summary', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A NEW TABLE WITH AGGRIGATED PLAYER STATS YEAR TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use player_stats_df from here on, instead of running another SQL query.\n",
    "df_player_stats = player_stats_df.copy()\n",
    "\n",
    "\n",
    "# Clean up the name format in player_stats for easier matching\n",
    "# Replace the non-breaking space with a regular space\n",
    "df_player_stats['Clean_Player'] = df_player_stats['Player'].apply(lambda x: x.replace('\\xa0', ' '))\n",
    "\n",
    "# Remove rows where Player is the team name (e.g., \"Michigan State\")\n",
    "df_player_stats_cleaned = df_player_stats[df_player_stats['Player'] != df_player_stats['Team']]\n",
    "\n",
    "# Convert relevant columns to integers for correct aggregation\n",
    "cols_to_convert = ['G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM']\n",
    "for col in cols_to_convert:\n",
    "    df_player_stats_cleaned[col] = pd.to_numeric(df_player_stats_cleaned[col], errors='coerce')\n",
    "\n",
    "# Aggregate the data for year-to-date stats\n",
    "# Add a column for counting the number of games each player has played\n",
    "agg_player_stats_corrected_with_games = df_player_stats_cleaned.groupby(['Clean_Player', 'Team']).agg({\n",
    "    'G': 'sum',\n",
    "    'A': 'sum',\n",
    "    'Pts': 'sum',\n",
    "    'plus_minus': 'sum',\n",
    "    'Sh': 'sum',\n",
    "    'PIM': 'sum',\n",
    "    'Game_ID': 'count'  # Counting the number of unique Game_IDs for each player\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the Game_ID column to Games_Played\n",
    "agg_player_stats_corrected_with_games.rename(columns={'Game_ID': 'Games_Played'}, inplace=True)\n",
    "\n",
    "# Save the updated aggregated data back to the database, replacing the existing table\n",
    "agg_player_stats_corrected_with_games.to_sql('player_stats_ytd', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Verify by loading some sample data from the updated table\n",
    "sample_updated_ytd = pd.read_sql_query(\"SELECT * FROM player_stats_ytd LIMIT 5;\", conn)\n",
    "sample_updated_ytd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Roster data to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## SET THE ROSTER DATAFRAME TO THE CORRECT YEAR ####################\n",
    "## MATCH THE DATAFRAME NAMES\n",
    "df_master_roster = roster_df.copy()\n",
    "\n",
    "\n",
    "# Clean up the name formats for joining\n",
    "# Master roster: Convert \"Last Name, First Name\" to \"First Name Last Name\"\n",
    "# df_master_roster['Clean_Name'] = df_master_roster['Player'].apply(lambda x: ' '.join(reversed(x.split(', '))))\n",
    "\n",
    "# Rename Player to Clean_Name\n",
    "df_master_roster.rename(columns={'Player': 'Clean_Name'}, inplace=True)\n",
    "# Rename School to Team\n",
    "df_master_roster.rename(columns={'School': 'Team'}, inplace=True)\n",
    "\n",
    "# Clean up the Team column, remove '-' and replace with ' '\n",
    "# df_master_roster['School'] = df_master_roster['Team'].apply(lambda x: x.replace('-', ' '))\n",
    "\n",
    "## If there are an period in the column names, remove them\n",
    "df_master_roster.columns = df_master_roster.columns.str.replace('.', '')\n",
    "\n",
    "### Finally add the roster to the database as it's own table\n",
    "\n",
    "df_master_roster['SeasonYear'] = season_year\n",
    "\n",
    "# Save the roster data as a new table in the database\n",
    "roster_table_name = 'master_roster'\n",
    "df_master_roster.to_sql(roster_table_name, conn, if_exists='replace', index=False)\n",
    "############################################################\n",
    "\n",
    "# Verify by listing all the tables in the database again\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(tables_query).fetchall()\n",
    "table_names_updated = [table[0] for table in tables]\n",
    "table_names_updated\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
