{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING AND COMBINING\n",
    "\n",
    "### College Hockey Box score scrape data\n",
    "\n",
    "-Opened 4/3/2024\n",
    "\n",
    "# NOTE - Current version creates combined db with lots of duplicate rows.\n",
    "## Run through the DB_DUP_CHECK_SCRATCH to remove until this can be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-8-24 NEW FIXES NEEDED\n",
    "- Missing Rosters for at least 2012 and 2017\n",
    "\n",
    "- Player still has captan information in some of the years '(C)' or '(A)' in between first and last name\n",
    "\n",
    "also need to remove double spaces in the Player Name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('scoring_summary',), ('penalty_summary',), ('goalie_stats',), ('player_stats',), ('linescore',), ('game_details',), ('player_stats_ytd',), ('line_chart',), ('advanced_metrics',), ('master_roster',)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height_Inches</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>NHL_Team</th>\n",
       "      <th>D_Round</th>\n",
       "      <th>Last Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama Huntsville</td>\n",
       "      <td>Richard Buri</td>\n",
       "      <td>33</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>6-5</td>\n",
       "      <td>215</td>\n",
       "      <td>1/12/1994</td>\n",
       "      <td>Nitra, Slovakia</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama Huntsville</td>\n",
       "      <td>Cody Champagne</td>\n",
       "      <td>5</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>5-11</td>\n",
       "      <td>185</td>\n",
       "      <td>4/9/1994</td>\n",
       "      <td>Brookfield, Conn.</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Topeka</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama Huntsville</td>\n",
       "      <td>Kurt Gosselin</td>\n",
       "      <td>28</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>6-1</td>\n",
       "      <td>200</td>\n",
       "      <td>11/30/1994</td>\n",
       "      <td>Brighton, Mich.</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberni Valley</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama Huntsville</td>\n",
       "      <td>Connor James</td>\n",
       "      <td>4</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>So</td>\n",
       "      <td>5-9</td>\n",
       "      <td>170</td>\n",
       "      <td>10/11/1996</td>\n",
       "      <td>Wainwright, Alb.</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spruce Grove</td>\n",
       "      <td>AJHL</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama Huntsville</td>\n",
       "      <td>Cam Knight</td>\n",
       "      <td>2</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>6-1</td>\n",
       "      <td>195</td>\n",
       "      <td>1/10/1995</td>\n",
       "      <td>North Reading, Mass.</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wichita Falls</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team          Player  No    Position  Yr    Ht   Wt  \\\n",
       "0  Alabama Huntsville    Richard Buri  33  Defensemen  Sr   6-5  215   \n",
       "1  Alabama Huntsville  Cody Champagne   5  Defensemen  Sr  5-11  185   \n",
       "2  Alabama Huntsville   Kurt Gosselin  28  Defensemen  Jr   6-1  200   \n",
       "3  Alabama Huntsville    Connor James   4  Defensemen  So   5-9  170   \n",
       "4  Alabama Huntsville      Cam Knight   2  Defensemen  Jr   6-1  195   \n",
       "\n",
       "          DOB              Hometown  Height_Inches  Draft_Year NHL_Team  \\\n",
       "0   1/12/1994       Nitra, Slovakia             77         NaN      NaN   \n",
       "1    4/9/1994     Brookfield, Conn.             71         NaN      NaN   \n",
       "2  11/30/1994       Brighton, Mich.             73         NaN      NaN   \n",
       "3  10/11/1996      Wainwright, Alb.             69         NaN      NaN   \n",
       "4   1/10/1995  North Reading, Mass.             73         NaN      NaN   \n",
       "\n",
       "   D_Round       Last Team League  Season  \n",
       "0      NaN       Minnesota   NAHL    2017  \n",
       "1      NaN          Topeka   NAHL    2017  \n",
       "2      NaN  Alberni Valley   BCHL    2017  \n",
       "3      NaN    Spruce Grove   AJHL    2017  \n",
       "4      NaN   Wichita Falls   NAHL    2017  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path = os.path.join('..', 'data', 'db', 'Cleaned_DB_AP_7.db')\n",
    "conn = sqlite3.connect(database_path)\n",
    "c = conn.cursor()\n",
    "\n",
    "# Print table names\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(c.fetchall())\n",
    "\n",
    "# Roster path\n",
    "roster_path = os.path.join('..', 'TEMP', 'roster_data_2017.csv')\n",
    "roster_df = pd.read_csv(roster_path)\n",
    "roster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = roster_df.copy()\n",
    "\n",
    "## Transform the Player column - contains captain and co-captain information in parentheses\n",
    "### Remove and store in new column called 'captain'\n",
    "#### example of '(C)' and '(A)' in the Player column - remove and the letter in parentheses in new column\n",
    "## Then Remove the parentheses and letter from the 'Player' column\n",
    "\n",
    "data['captain'] = data['Player'].str.extract(r'\\((\\w)\\)')\n",
    "data['Player'] = data['Player'].str.replace(r'\\(\\w\\)', '', regex=True)\n",
    "\n",
    "\n",
    "# Remove any leading or trailing white spaces from the 'Player' column\n",
    "data['Player'] = data['Player'].str.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Split the 'Player' column into 'First' and 'Last' columns\n",
    "# data[['First', 'Last']] = data['Player'].str.split(' ', 1, expand=True)\n",
    "\n",
    "data.tail(20)\n",
    "\n",
    "# value_counts() for 'captain' column\n",
    "data['captain'].value_counts()\n",
    "\n",
    "pre_filt1 = data.copy()  \n",
    "# Drop any rows with missing values in the 'Team' column\n",
    "data = data.dropna(subset=['Team'])\n",
    "pre_filt2 = data.copy()\n",
    "# Drop Rows with Empty Season\n",
    "data = data.dropna(subset=['Season'])\n",
    "prefilt3 = data.copy()\n",
    "# drop any rows with missing values in the 'Player' column\n",
    "data = data.dropna(subset=['Player'])\n",
    "\n",
    "# Make sure Season, Height_in & No are ints\n",
    "data['Season'] = data['Season'].astype(int)\n",
    "data['No'] = data['No'].astype(int)\n",
    "data['Height_Inches'] = data['Height_Inches'].astype(int)\n",
    "\n",
    "# If D_Round not Nan then convert to int\n",
    "data['D_Round'] = data['D_Round'].fillna(0)\n",
    "data['D_Round'] = data['D_Round'].astype(int)\n",
    "\n",
    "data['Draft_Year'] = data['Draft_Year'].fillna(0)\n",
    "data['Draft_Year'] = data['Draft_Year'].astype(int)\n",
    "\n",
    "\n",
    "# rename Player to Clean_Name for ease of join\n",
    "data = data.rename(columns={'Player': 'Clean_Name'})\n",
    "\n",
    "\n",
    "\n",
    "# data['D_Round'] = data['D_Round'].astype(str)\n",
    "\n",
    "# Drop any columns that are all NA\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# # Print lengths to check filter\n",
    "# print(len(pre_filt1))\n",
    "# print(len(pre_filt2))\n",
    "# print(len(prefilt3))\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1663"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the database connection and insert the cleaned single season roster to the master_roster table\n",
    "\n",
    "data.to_sql('master_roster', conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in the database does not match the inserted data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, let's fetch the data back from the database to compare\n",
    "query = \"SELECT * FROM master_roster WHERE Season = 2012;\"\n",
    "db_data = pd.read_sql(query, conn)\n",
    "\n",
    "# Assuming 'YOUR_SEASON_YEAR' is the season year of the data you just inserted.\n",
    "# Now, you might want to compare the 'db_data' DataFrame to your 'data' DataFrame to ensure they match\n",
    "\n",
    "# To compare, you can use the following:\n",
    "if db_data.equals(data):\n",
    "    print(\"The data in the database matches the inserted data.\")\n",
    "else:\n",
    "    print(\"The data in the database does not match the inserted data.\")\n",
    "\n",
    "# Close the connection when done\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Clean_Name column from master roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84961 entries, 0 to 84960\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Team           84961 non-null  object\n",
      " 1   Clean_Name     84961 non-null  object\n",
      " 2   No             84961 non-null  int64 \n",
      " 3   Position       84961 non-null  object\n",
      " 4   Yr             60645 non-null  object\n",
      " 5   Ht             84898 non-null  object\n",
      " 6   Wt             84961 non-null  int64 \n",
      " 7   DOB            61293 non-null  object\n",
      " 8   Hometown       76781 non-null  object\n",
      " 9   Height_Inches  84961 non-null  int64 \n",
      " 10  Draft_Year     84961 non-null  int64 \n",
      " 11  NHL_Team       4641 non-null   object\n",
      " 12  D_Round        84961 non-null  int64 \n",
      " 13  Last Team      43481 non-null  object\n",
      " 14  League         37197 non-null  object\n",
      " 15  Season         84961 non-null  int64 \n",
      " 16  file           78557 non-null  object\n",
      " 17  captain        2561 non-null   object\n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "master_roster_query = \"SELECT * FROM master_roster;\"\n",
    "# open the connection\n",
    "conn = sqlite3.connect(database_path)\n",
    "# read the data into a DataFrame\n",
    "\n",
    "\n",
    "master_roster_df = pd.read_sql(master_roster_query, conn)\n",
    "\n",
    "master_roster_df.head()\n",
    "master_roster_df.tail()\n",
    "master_roster_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = master_roster_df.copy()\n",
    "\n",
    "### Clean the Name COlumn of Captain and Co-Captain stuff\n",
    "data['captain'] = data['Clean_Name'].str.extract(r'\\((\\w)\\)')\n",
    "data['Clean_Name'] = data['Clean_Name'].str.replace(r'\\(\\w\\)', '', regex=True)\n",
    "\n",
    "\n",
    "# Remove any leading or trailing white spaces from the 'Player' column\n",
    "data['Clean_Name'] = data['Clean_Name'].str.strip()\n",
    "\n",
    "# Remove any ddouble spaces in the middle of the name\n",
    "data['Clean_Name'] = data['Clean_Name'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(10)\n",
    "# data.tail(10)\n",
    "\n",
    "# # Sort by season and show tail\n",
    "# data = data.sort_values(by=['Season', 'Team', 'Clean_Name'])\n",
    "# data.tail(10)\n",
    "\n",
    "# Overwrite the master_roster table with the cleaned data\n",
    "data.to_sql('master_roster', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths and setup\n",
    "\n",
    "roster_path = os.path.join('..', 'data', 'rosters', 'all_time_combined_roster.csv')\n",
    "# read in the roster\n",
    "roster = pd.read_csv(roster_path)\n",
    "# roster.info() # Display the data types of each column\n",
    "\n",
    "\n",
    "# Database folder path\n",
    "db_folder = os.path.join('..', 'data', 'db', 'box_scores')\n",
    "\n",
    "# list the db files in the directory\n",
    "db_files = os.listdir(db_folder)\n",
    "# db_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the roster data in each .db file\n",
    "### Make corrections - also add Season column to all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify and correct the data in the master_roster table of a .db file\n",
    "\n",
    "# Includes a check to make sure the table is present in the database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correct_db_file(db_file, roster_df):\n",
    "#     year = int(db_file[:4])  # Extract the year from the filename\n",
    "#     db_path = os.path.join(db_folder, db_file)\n",
    "#     conn = sqlite3.connect(db_path)\n",
    "    \n",
    "#     cursor = conn.cursor()\n",
    "#     # Check if master_roster table exists\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='master_roster';\")\n",
    "#     if cursor.fetchone():\n",
    "#         # Check if the Season column exists in the master_roster table\n",
    "#         cursor.execute(\"PRAGMA table_info(master_roster);\")\n",
    "#         columns = [row[1] for row in cursor.fetchall()]\n",
    "#         if \"Season\" not in columns:\n",
    "#             cursor.execute(\"ALTER TABLE master_roster ADD COLUMN Season INTEGER\")\n",
    "        \n",
    "#         # Correct the master_roster table if needed\n",
    "#         cursor.execute(\"SELECT DISTINCT Season FROM master_roster\")\n",
    "#         seasons = cursor.fetchall()\n",
    "#         if len(seasons) != 1 or seasons[0][0] != year:\n",
    "#             cursor.execute(\"DELETE FROM master_roster\")\n",
    "#             # Handle column name variations\n",
    "#             correct_roster = roster_df[roster_df['Season'] == year].copy()\n",
    "#             if 'Clean_Name' not in correct_roster.columns and 'Clean-Name' in correct_roster.columns:\n",
    "#                 correct_roster.rename(columns={'Clean-Name': 'Clean_Name'}, inplace=True)\n",
    "#             elif 'Clean_Name' not in correct_roster.columns and 'player' in correct_roster.columns:\n",
    "#                 correct_roster.rename(columns={'player': 'Clean_Name'}, inplace=True)\n",
    "#             correct_roster.to_sql('master_roster', conn, if_exists='append', index=False)\n",
    "    \n",
    "#     # Add Season column to all tables as redundancy, checking first if it exists\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     for table in tables:\n",
    "#         table_name = table[0]\n",
    "#         cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "#         columns = [row[1] for row in cursor.fetchall()]\n",
    "#         if \"Season\" not in columns:\n",
    "#             try:\n",
    "#                 cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN Season INTEGER\")\n",
    "#                 cursor.execute(f\"UPDATE {table_name} SET Season = {year}\")\n",
    "#             except sqlite3.OperationalError as e:\n",
    "#                 print(f\"Error updating table {table_name}: {str(e)}\")\n",
    "    \n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "#     print(f\"Database {db_file} has been corrected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for db_file in db_files:\n",
    "#     if db_file.endswith('.db'):  # Ensure it's a database file\n",
    "#         correct_db_file(db_file, roster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FIX ie - add season column to the two Full_Stats.db files' tables\n",
    "\n",
    "# # list the files in the directory that contain the string 'Full_Stats'\n",
    "# full_stats_files = [file for file in db_files if 'Full_Stats' in file]\n",
    "# full_stats_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_season_column_to_dbs(db_path, full_stats_files):\n",
    "#     for db_file in full_stats_files:\n",
    "#         year = int(db_file[:4])  # Extract the year from the filename\n",
    "#         full_db_path = os.path.join(db_path, db_file)  # Construct the full path to the database file\n",
    "#         conn = sqlite3.connect(full_db_path)\n",
    "#         cursor = conn.cursor()\n",
    "        \n",
    "#         # Retrieve all table names in the database\n",
    "#         cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "#         tables = cursor.fetchall()\n",
    "        \n",
    "#         for table in tables:\n",
    "#             table_name = table[0]\n",
    "#             # Check if the Season column exists\n",
    "#             cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "#             columns = [row[1] for row in cursor.fetchall()]\n",
    "#             if \"Season\" not in columns:\n",
    "#                 cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN Season INTEGER DEFAULT {year}\")\n",
    "#                 cursor.execute(f\"UPDATE {table_name} SET Season = {year}\")\n",
    "        \n",
    "#         conn.commit()\n",
    "#         conn.close()\n",
    "\n",
    "# # Assume db_path is the directory where your DB files are stored\n",
    "# db_path = '/mnt/data'  # Update this to your actual db directory path\n",
    "\n",
    "# # List of database filenames to process\n",
    "# full_stats_files = ['2021_Full_Stats.db', '2022_Full_Stats.db']\n",
    "\n",
    "# # Add Season column to each table in the listed databases\n",
    "# add_season_column_to_dbs(db_folder, full_stats_files)\n",
    "\n",
    "# print(\"Season column added to all tables in the listed databases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CODE\n",
    "# def adjust_table_schema(new_db_conn, source_conn, table_name):\n",
    "#     \"\"\"\n",
    "#     Adjusts the table schema in the new database based on the source table schema,\n",
    "#     adding any missing columns and renaming 'Clean_Name' to 'Player' if necessary.\n",
    "#     \"\"\"\n",
    "#     source_cur = source_conn.cursor()\n",
    "#     new_db_cur = new_db_conn.cursor()\n",
    "    \n",
    "#     # Get column info from the source table\n",
    "#     source_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "#     source_columns = source_cur.fetchall()\n",
    "    \n",
    "#     # Get column info from the new (combined) table\n",
    "#     new_db_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "#     new_columns = new_db_cur.fetchall()\n",
    "    \n",
    "#     # Convert fetched info into sets of column names for easy comparison\n",
    "#     source_column_names = {col[1] for col in source_columns}\n",
    "#     new_column_names = {col[1] for col in new_columns}\n",
    "    \n",
    "#     # Identify if we're dealing with a 'Clean_Name' to 'Player' transition\n",
    "#     rename_clean_name_to_player = \"Clean_Name\" in new_column_names and \"Player\" not in source_column_names\n",
    "    \n",
    "#     # Determine missing columns and add them to the new table\n",
    "#     missing_columns = source_column_names - new_column_names\n",
    "#     for col in source_columns:\n",
    "#         col_name, col_type = col[1], col[2]\n",
    "#         if col_name in missing_columns:\n",
    "#             # Handle the special case for renaming 'Clean_Name' to 'Player'\n",
    "#             if table_name == \"master_roster\" and rename_clean_name_to_player:\n",
    "#                 if col_name == \"Clean_Name\":\n",
    "#                     # If \"Clean_Name\" should be renamed to \"Player\" and doesn't exist, skip adding \"Clean_Name\"\n",
    "#                     continue\n",
    "#                 elif col_name == \"Player\":\n",
    "#                     # If dealing with \"Player\", ensure it's correctly added or renamed\n",
    "#                     alter_stmt = f\"ALTER TABLE \\\"{table_name}\\\" RENAME COLUMN \\\"Clean_Name\\\" TO \\\"Player\\\"\"\n",
    "#                     new_db_cur.execute(alter_stmt)\n",
    "#                     continue\n",
    "#             else:\n",
    "#                 # Regular column addition for non-special cases\n",
    "#                 alter_stmt = f\"ALTER TABLE \\\"{table_name}\\\" ADD COLUMN \\\"{col_name}\\\" {col_type}\"\n",
    "#                 new_db_cur.execute(alter_stmt)\n",
    "    \n",
    "#     new_db_conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_table_schema(new_db_conn, source_conn, table_name):\n",
    "    \"\"\"\n",
    "    Adjusts the table schema in the new database based on the source table schema,\n",
    "    adding any missing columns and ensuring no duplicate additions.\n",
    "    \"\"\"\n",
    "    source_cur = source_conn.cursor()\n",
    "    new_db_cur = new_db_conn.cursor()\n",
    "    \n",
    "    # Get column info from the source table\n",
    "    source_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    source_columns = source_cur.fetchall()\n",
    "    \n",
    "    # Get column info from the new (combined) table\n",
    "    new_db_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    new_columns = new_db_cur.fetchall()\n",
    "    \n",
    "    new_column_names = {col[1] for col in new_columns}\n",
    "    \n",
    "    for col in source_columns:\n",
    "        col_name, col_type = col[1], col[2]\n",
    "        \n",
    "        # Check directly if the column already exists in the new table\n",
    "        if col_name not in new_column_names:\n",
    "            # Proceed with adding the column\n",
    "            try:\n",
    "                alter_stmt = f\"ALTER TABLE \\\"{table_name}\\\" ADD COLUMN \\\"{col_name}\\\" {col_type}\"\n",
    "                new_db_cur.execute(alter_stmt)\n",
    "            except sqlite3.OperationalError as e:\n",
    "                print(f\"Error adding column {col_name} to table {table_name}: {e}\")\n",
    "    \n",
    "    new_db_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the databases into a new file\n",
    "\n",
    "- version 1 simple logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def create_table_from_source(new_db_conn, source_conn, table_name):\n",
    "    \"\"\"\n",
    "    Creates a table in the new database based on the schema of the source table.\n",
    "    \"\"\"\n",
    "    source_cur = source_conn.cursor()\n",
    "    source_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = source_cur.fetchall()\n",
    "    \n",
    "    # Rename 'Clean_Name' column to 'Player' for the master_roster table\n",
    "    if table_name == \"master_roster\":\n",
    "        columns = [(col[0], 'Player' if col[1] == 'Clean_Name' else col[1], col[2], col[3], col[4], col[5]) for col in columns]\n",
    "    \n",
    "    # Construct the CREATE TABLE statement\n",
    "    col_defs = ', '.join([f'\"{col[1]}\" {col[2]}' for col in columns])\n",
    "    create_stmt = f\"CREATE TABLE IF NOT EXISTS {table_name} ({col_defs})\"\n",
    "    \n",
    "    new_db_conn.execute(create_stmt)\n",
    "\n",
    "def insert_data_from_source(new_db_conn, source_conn, table_name):\n",
    "    \"\"\"\n",
    "    Inserts data from the source table into the corresponding table in the new database.\n",
    "    Handles renaming 'Clean_Name' to 'Player' if necessary and quotes column names to avoid syntax errors.\n",
    "    \"\"\"\n",
    "    source_cur = source_conn.cursor()\n",
    "    source_cur.execute(f\"SELECT * FROM {table_name}\")\n",
    "    column_names = [description[0] for description in source_cur.description]\n",
    "    \n",
    "    # Handle potential 'Clean_Name' to 'Player' renaming\n",
    "    if 'Clean_Name' in column_names and table_name == \"master_roster\":\n",
    "        column_names = ['Player' if col == 'Clean_Name' else col for col in column_names]\n",
    "    \n",
    "    # Quote column names to handle reserved words or special characters\n",
    "    columns_str = ', '.join([f'\"{col}\"' for col in column_names])\n",
    "    placeholders = ', '.join(['?'] * len(column_names))\n",
    "    \n",
    "    data = source_cur.fetchall()\n",
    "    new_db_cur = new_db_conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        new_db_cur.executemany(f\"INSERT INTO \\\"{table_name}\\\" ({columns_str}) VALUES ({placeholders})\", data)\n",
    "        new_db_conn.commit()\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        print(f\"Integrity error occurred while inserting data into {table_name}: {e}\")\n",
    "\n",
    "\n",
    "def combine_databases(db_folder, output_db_path):\n",
    "    # Connect to the new database (this will create it if it doesn't exist)\n",
    "    new_db_conn = sqlite3.connect(output_db_path)\n",
    "    \n",
    "    for db_file in os.listdir(db_folder):\n",
    "        if db_file.endswith('.db'):\n",
    "            source_db_path = os.path.join(db_folder, db_file)\n",
    "            source_conn = sqlite3.connect(source_db_path)\n",
    "            \n",
    "            # Get list of tables from the source DB\n",
    "            source_cur = source_conn.cursor()\n",
    "            source_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "            tables = source_cur.fetchall()\n",
    "            \n",
    "            for table_info in tables:\n",
    "                table_name = table_info[0]\n",
    "                \n",
    "                # Ensure the table exists and its schema is up-to-date\n",
    "                create_table_from_source(new_db_conn, source_conn, table_name)\n",
    "                adjust_table_schema(new_db_conn, source_conn, table_name)\n",
    "                \n",
    "                # Then insert data\n",
    "                insert_data_from_source(new_db_conn, source_conn, table_name)\n",
    "\n",
    "            \n",
    "            source_conn.close()\n",
    "    \n",
    "    new_db_conn.close()\n",
    "\n",
    "# Example usage\n",
    "# db_folder = 'path/to/your/db_folder'  # DEFINED ABOVE IN SETUP\n",
    "output_db_path = f'{db_folder}/../Combined_DB_v2.db'  # Choose your output path\n",
    "combine_databases(db_folder, output_db_path)\n",
    "\n",
    "print(\"Databases combined successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your db_folder and the path for the new, combined database\n",
    "# db_folder = 'path/to/your/db_folder'  # Update this path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
