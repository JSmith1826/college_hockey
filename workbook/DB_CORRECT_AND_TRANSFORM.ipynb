{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING AND COMBINING\n",
    "\n",
    "### College Hockey Box score scrape data\n",
    "\n",
    "-Opened 4/3/2024\n",
    "\n",
    "# NOTE - Current version creates combined db with lots of duplicate rows.\n",
    "## Run through the DB_DUP_CHECK_SCRATCH to remove until this can be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW Issue - missing player_ytd summary table for years 2005-2009 and 2012, 2014, 2017\n",
    "- Box Scores only go back to 2005\n",
    "    - scoring summarys go back to 2002 so it is possible we could create very simple (G, A, P) box scores from the data for those years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "database_path = os.path.join('..', 'data', 'db', 'Cleaned_DB_AP_8.db')\n",
    "conn = sqlite3.connect(database_path)\n",
    "c = conn.cursor()\n",
    "\n",
    "# Print table names\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Trouble Years 1997, 1995, 1988\n",
    "- something wrong witht he average age calculation in 2020for every team\n",
    "## CORRECTED - ROSTERS IN QUESTION 4-8-24 NEW FIXES NEEDED\n",
    "\n",
    "\n",
    "- Missing Rosters for at least 2002, 2012 and 2017\n",
    "\n",
    "- Player still has captan information in some of the years '(C)' or '(A)' in between first and last name\n",
    "\n",
    "also need to remove double spaces in the Player Name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('scoring_summary',), ('penalty_summary',), ('goalie_stats',), ('player_stats',), ('linescore',), ('game_details',), ('player_stats_ytd',), ('line_chart',), ('advanced_metrics',), ('master_roster',)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height_Inches</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>NHL_Team</th>\n",
       "      <th>D_Round</th>\n",
       "      <th>Last Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Andy (C) Burnes</td>\n",
       "      <td>4</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>6-0</td>\n",
       "      <td>187</td>\n",
       "      <td>10/2/1981</td>\n",
       "      <td>Battle Creek, Mich.</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Compuware</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Nick Martens</td>\n",
       "      <td>2</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>So</td>\n",
       "      <td>6-1</td>\n",
       "      <td>194</td>\n",
       "      <td>9/11/1982</td>\n",
       "      <td>Ann Arbor, Mich.</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Reilly Olson</td>\n",
       "      <td>6</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>6-0</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grand Prairie, Alb.</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Danny Richmond</td>\n",
       "      <td>7</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>6-0</td>\n",
       "      <td>172</td>\n",
       "      <td>8/1/1984</td>\n",
       "      <td>Buffalo Grove, Ill.</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>USHL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mike Roemensky</td>\n",
       "      <td>23</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>5-11</td>\n",
       "      <td>174</td>\n",
       "      <td>5/29/1981</td>\n",
       "      <td>White Lake, Mich.</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Compuware</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Team           Player  No    Position  Yr    Ht   Wt        DOB  \\\n",
       "0  Michigan  Andy (C) Burnes   4  Defensemen  Jr   6-0  187  10/2/1981   \n",
       "1  Michigan     Nick Martens   2  Defensemen  So   6-1  194  9/11/1982   \n",
       "2  Michigan     Reilly Olson   6  Defensemen  Fr   6-0  181        NaN   \n",
       "3  Michigan   Danny Richmond   7  Defensemen  Fr   6-0  172   8/1/1984   \n",
       "4  Michigan   Mike Roemensky  23  Defensemen  Sr  5-11  174  5/29/1981   \n",
       "\n",
       "              Hometown  Height_Inches  Draft_Year NHL_Team  D_Round  \\\n",
       "0  Battle Creek, Mich.             72         NaN      NaN      NaN   \n",
       "1     Ann Arbor, Mich.             73         NaN      NaN      NaN   \n",
       "2  Grand Prairie, Alb.             72         NaN      NaN      NaN   \n",
       "3  Buffalo Grove, Ill.             72         NaN      NaN      NaN   \n",
       "4    White Lake, Mich.             71         NaN      NaN      NaN   \n",
       "\n",
       "   Last Team League  Season  \n",
       "0  Compuware   NAHL    2002  \n",
       "1      Texas   NAHL    2002  \n",
       "2     Vernon   BCHL    2002  \n",
       "3    Chicago   USHL    2002  \n",
       "4  Compuware   NAHL    2002  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_path = os.path.join('..', 'data', 'db', 'Cleaned_DB_AP_8.db')\n",
    "conn = sqlite3.connect(database_path)\n",
    "c = conn.cursor()\n",
    "\n",
    "# Print table names\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(c.fetchall())\n",
    "\n",
    "# Roster path\n",
    "roster_path = os.path.join('..', 'TEMP', 'roster_data_2002.csv')\n",
    "roster_df = pd.read_csv(roster_path)\n",
    "roster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = roster_df.copy()\n",
    "\n",
    "## Transform the Player column - contains captain and co-captain information in parentheses\n",
    "### Remove and store in new column called 'captain'\n",
    "#### example of '(C)' and '(A)' in the Player column - remove and the letter in parentheses in new column\n",
    "## Then Remove the parentheses and letter from the 'Player' column\n",
    "\n",
    "data['captain'] = data['Player'].str.extract(r'\\((\\w)\\)')\n",
    "data['Player'] = data['Player'].str.replace(r'\\(\\w\\)', '', regex=True)\n",
    "\n",
    "\n",
    "# Remove any leading or trailing white spaces from the 'Player' column\n",
    "data['Player'] = data['Player'].str.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Split the 'Player' column into 'First' and 'Last' columns\n",
    "# data[['First', 'Last']] = data['Player'].str.split(' ', 1, expand=True)\n",
    "\n",
    "data.tail(20)\n",
    "\n",
    "# value_counts() for 'captain' column\n",
    "data['captain'].value_counts()\n",
    "\n",
    "pre_filt1 = data.copy()  \n",
    "# Drop any rows with missing values in the 'Team' column\n",
    "data = data.dropna(subset=['Team'])\n",
    "pre_filt2 = data.copy()\n",
    "# Drop Rows with Empty Season\n",
    "data = data.dropna(subset=['Season'])\n",
    "prefilt3 = data.copy()\n",
    "# drop any rows with missing values in the 'Player' column\n",
    "data = data.dropna(subset=['Player'])\n",
    "\n",
    "# Make sure Season, Height_in & No are ints\n",
    "data['Season'] = data['Season'].astype(int)\n",
    "data['No'] = data['No'].astype(int)\n",
    "data['Height_Inches'] = data['Height_Inches'].astype(int)\n",
    "\n",
    "# If D_Round not Nan then convert to int\n",
    "data['D_Round'] = data['D_Round'].fillna(0)\n",
    "data['D_Round'] = data['D_Round'].astype(int)\n",
    "\n",
    "data['Draft_Year'] = data['Draft_Year'].fillna(0)\n",
    "data['Draft_Year'] = data['Draft_Year'].astype(int)\n",
    "\n",
    "\n",
    "# rename Player to Clean_Name for ease of join\n",
    "data = data.rename(columns={'Player': 'Clean_Name'})\n",
    "\n",
    "\n",
    "\n",
    "# data['D_Round'] = data['D_Round'].astype(str)\n",
    "\n",
    "# Drop any columns that are all NA\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# # Print lengths to check filter\n",
    "# print(len(pre_filt1))\n",
    "# print(len(pre_filt2))\n",
    "# print(len(prefilt3))\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1539"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the database connection and insert the cleaned single season roster to the master_roster table\n",
    "\n",
    "data.to_sql('master_roster', conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in the database does not match the inserted data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, let's fetch the data back from the database to compare\n",
    "query = \"SELECT * FROM master_roster WHERE Season = 2002;\"\n",
    "db_data = pd.read_sql(query, conn)\n",
    "\n",
    "# Assuming 'YOUR_SEASON_YEAR' is the season year of the data you just inserted.\n",
    "# Now, you might want to compare the 'db_data' DataFrame to your 'data' DataFrame to ensure they match\n",
    "\n",
    "# To compare, you can use the following:\n",
    "if db_data.equals(data):\n",
    "    print(\"The data in the database matches the inserted data.\")\n",
    "else:\n",
    "    print(\"The data in the database does not match the inserted data.\")\n",
    "\n",
    "# Close the connection when done\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Clean_Name column from master roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86500 entries, 0 to 86499\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Team           86500 non-null  object\n",
      " 1   Clean_Name     86500 non-null  object\n",
      " 2   No             86500 non-null  int64 \n",
      " 3   Position       86500 non-null  object\n",
      " 4   Yr             62182 non-null  object\n",
      " 5   Ht             86435 non-null  object\n",
      " 6   Wt             86500 non-null  int64 \n",
      " 7   DOB            62810 non-null  object\n",
      " 8   Hometown       78318 non-null  object\n",
      " 9   Height_Inches  86500 non-null  int64 \n",
      " 10  Draft_Year     86500 non-null  int64 \n",
      " 11  NHL_Team       4679 non-null   object\n",
      " 12  D_Round        86500 non-null  int64 \n",
      " 13  Last Team      45018 non-null  object\n",
      " 14  League         38075 non-null  object\n",
      " 15  Season         86500 non-null  int64 \n",
      " 16  file           78557 non-null  object\n",
      " 17  captain        2166 non-null   object\n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "master_roster_query = \"SELECT * FROM master_roster;\"\n",
    "# open the connection\n",
    "conn = sqlite3.connect(database_path)\n",
    "# read the data into a DataFrame\n",
    "\n",
    "\n",
    "master_roster_df = pd.read_sql(master_roster_query, conn)\n",
    "\n",
    "master_roster_df.head()\n",
    "master_roster_df.tail()\n",
    "master_roster_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = master_roster_df.copy()\n",
    "\n",
    "### Clean the Name COlumn of Captain and Co-Captain stuff\n",
    "data['captain'] = data['Clean_Name'].str.extract(r'\\((\\w)\\)')\n",
    "data['Clean_Name'] = data['Clean_Name'].str.replace(r'\\(\\w\\)', '', regex=True)\n",
    "\n",
    "\n",
    "# Remove any leading or trailing white spaces from the 'Player' column\n",
    "data['Clean_Name'] = data['Clean_Name'].str.strip()\n",
    "\n",
    "# Remove any ddouble spaces in the middle of the name\n",
    "data['Clean_Name'] = data['Clean_Name'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(10)\n",
    "# data.tail(10)\n",
    "\n",
    "# # Sort by season and show tail\n",
    "# data = data.sort_values(by=['Season', 'Team', 'Clean_Name'])\n",
    "# data.tail(10)\n",
    "\n",
    "# Overwrite the master_roster table with the cleaned data\n",
    "data.to_sql('master_roster', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_2916\\3854896466.py:5: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  roster = pd.read_csv(roster_path)\n"
     ]
    }
   ],
   "source": [
    "# paths and setup\n",
    "\n",
    "roster_path = os.path.join('..', 'data', 'rosters', 'all_time_combined_roster.csv')\n",
    "# read in the roster\n",
    "roster = pd.read_csv(roster_path)\n",
    "# roster.info() # Display the data types of each column\n",
    "\n",
    "\n",
    "# Database folder path\n",
    "db_folder = os.path.join('..', 'data', 'db', 'box_scores')\n",
    "\n",
    "# list the db files in the directory\n",
    "db_files = os.listdir(db_folder)\n",
    "# db_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the roster data in each .db file\n",
    "### Make corrections - also add Season column to all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify and correct the data in the master_roster table of a .db file\n",
    "\n",
    "# Includes a check to make sure the table is present in the database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correct_db_file(db_file, roster_df):\n",
    "#     year = int(db_file[:4])  # Extract the year from the filename\n",
    "#     db_path = os.path.join(db_folder, db_file)\n",
    "#     conn = sqlite3.connect(db_path)\n",
    "    \n",
    "#     cursor = conn.cursor()\n",
    "#     # Check if master_roster table exists\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='master_roster';\")\n",
    "#     if cursor.fetchone():\n",
    "#         # Check if the Season column exists in the master_roster table\n",
    "#         cursor.execute(\"PRAGMA table_info(master_roster);\")\n",
    "#         columns = [row[1] for row in cursor.fetchall()]\n",
    "#         if \"Season\" not in columns:\n",
    "#             cursor.execute(\"ALTER TABLE master_roster ADD COLUMN Season INTEGER\")\n",
    "        \n",
    "#         # Correct the master_roster table if needed\n",
    "#         cursor.execute(\"SELECT DISTINCT Season FROM master_roster\")\n",
    "#         seasons = cursor.fetchall()\n",
    "#         if len(seasons) != 1 or seasons[0][0] != year:\n",
    "#             cursor.execute(\"DELETE FROM master_roster\")\n",
    "#             # Handle column name variations\n",
    "#             correct_roster = roster_df[roster_df['Season'] == year].copy()\n",
    "#             if 'Clean_Name' not in correct_roster.columns and 'Clean-Name' in correct_roster.columns:\n",
    "#                 correct_roster.rename(columns={'Clean-Name': 'Clean_Name'}, inplace=True)\n",
    "#             elif 'Clean_Name' not in correct_roster.columns and 'player' in correct_roster.columns:\n",
    "#                 correct_roster.rename(columns={'player': 'Clean_Name'}, inplace=True)\n",
    "#             correct_roster.to_sql('master_roster', conn, if_exists='append', index=False)\n",
    "    \n",
    "#     # Add Season column to all tables as redundancy, checking first if it exists\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     for table in tables:\n",
    "#         table_name = table[0]\n",
    "#         cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "#         columns = [row[1] for row in cursor.fetchall()]\n",
    "#         if \"Season\" not in columns:\n",
    "#             try:\n",
    "#                 cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN Season INTEGER\")\n",
    "#                 cursor.execute(f\"UPDATE {table_name} SET Season = {year}\")\n",
    "#             except sqlite3.OperationalError as e:\n",
    "#                 print(f\"Error updating table {table_name}: {str(e)}\")\n",
    "    \n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "#     print(f\"Database {db_file} has been corrected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for db_file in db_files:\n",
    "#     if db_file.endswith('.db'):  # Ensure it's a database file\n",
    "#         correct_db_file(db_file, roster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FIX ie - add season column to the two Full_Stats.db files' tables\n",
    "\n",
    "# # list the files in the directory that contain the string 'Full_Stats'\n",
    "# full_stats_files = [file for file in db_files if 'Full_Stats' in file]\n",
    "# full_stats_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_season_column_to_dbs(db_path, full_stats_files):\n",
    "#     for db_file in full_stats_files:\n",
    "#         year = int(db_file[:4])  # Extract the year from the filename\n",
    "#         full_db_path = os.path.join(db_path, db_file)  # Construct the full path to the database file\n",
    "#         conn = sqlite3.connect(full_db_path)\n",
    "#         cursor = conn.cursor()\n",
    "        \n",
    "#         # Retrieve all table names in the database\n",
    "#         cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "#         tables = cursor.fetchall()\n",
    "        \n",
    "#         for table in tables:\n",
    "#             table_name = table[0]\n",
    "#             # Check if the Season column exists\n",
    "#             cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "#             columns = [row[1] for row in cursor.fetchall()]\n",
    "#             if \"Season\" not in columns:\n",
    "#                 cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN Season INTEGER DEFAULT {year}\")\n",
    "#                 cursor.execute(f\"UPDATE {table_name} SET Season = {year}\")\n",
    "        \n",
    "#         conn.commit()\n",
    "#         conn.close()\n",
    "\n",
    "# # Assume db_path is the directory where your DB files are stored\n",
    "# db_path = '/mnt/data'  # Update this to your actual db directory path\n",
    "\n",
    "# # List of database filenames to process\n",
    "# full_stats_files = ['2021_Full_Stats.db', '2022_Full_Stats.db']\n",
    "\n",
    "# # Add Season column to each table in the listed databases\n",
    "# add_season_column_to_dbs(db_folder, full_stats_files)\n",
    "\n",
    "# print(\"Season column added to all tables in the listed databases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CODE\n",
    "# def adjust_table_schema(new_db_conn, source_conn, table_name):\n",
    "#     \"\"\"\n",
    "#     Adjusts the table schema in the new database based on the source table schema,\n",
    "#     adding any missing columns and renaming 'Clean_Name' to 'Player' if necessary.\n",
    "#     \"\"\"\n",
    "#     source_cur = source_conn.cursor()\n",
    "#     new_db_cur = new_db_conn.cursor()\n",
    "    \n",
    "#     # Get column info from the source table\n",
    "#     source_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "#     source_columns = source_cur.fetchall()\n",
    "    \n",
    "#     # Get column info from the new (combined) table\n",
    "#     new_db_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "#     new_columns = new_db_cur.fetchall()\n",
    "    \n",
    "#     # Convert fetched info into sets of column names for easy comparison\n",
    "#     source_column_names = {col[1] for col in source_columns}\n",
    "#     new_column_names = {col[1] for col in new_columns}\n",
    "    \n",
    "#     # Identify if we're dealing with a 'Clean_Name' to 'Player' transition\n",
    "#     rename_clean_name_to_player = \"Clean_Name\" in new_column_names and \"Player\" not in source_column_names\n",
    "    \n",
    "#     # Determine missing columns and add them to the new table\n",
    "#     missing_columns = source_column_names - new_column_names\n",
    "#     for col in source_columns:\n",
    "#         col_name, col_type = col[1], col[2]\n",
    "#         if col_name in missing_columns:\n",
    "#             # Handle the special case for renaming 'Clean_Name' to 'Player'\n",
    "#             if table_name == \"master_roster\" and rename_clean_name_to_player:\n",
    "#                 if col_name == \"Clean_Name\":\n",
    "#                     # If \"Clean_Name\" should be renamed to \"Player\" and doesn't exist, skip adding \"Clean_Name\"\n",
    "#                     continue\n",
    "#                 elif col_name == \"Player\":\n",
    "#                     # If dealing with \"Player\", ensure it's correctly added or renamed\n",
    "#                     alter_stmt = f\"ALTER TABLE \\\"{table_name}\\\" RENAME COLUMN \\\"Clean_Name\\\" TO \\\"Player\\\"\"\n",
    "#                     new_db_cur.execute(alter_stmt)\n",
    "#                     continue\n",
    "#             else:\n",
    "#                 # Regular column addition for non-special cases\n",
    "#                 alter_stmt = f\"ALTER TABLE \\\"{table_name}\\\" ADD COLUMN \\\"{col_name}\\\" {col_type}\"\n",
    "#                 new_db_cur.execute(alter_stmt)\n",
    "    \n",
    "#     new_db_conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_table_schema(new_db_conn, source_conn, table_name):\n",
    "    \"\"\"\n",
    "    Adjusts the table schema in the new database based on the source table schema,\n",
    "    adding any missing columns and ensuring no duplicate additions.\n",
    "    \"\"\"\n",
    "    source_cur = source_conn.cursor()\n",
    "    new_db_cur = new_db_conn.cursor()\n",
    "    \n",
    "    # Get column info from the source table\n",
    "    source_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    source_columns = source_cur.fetchall()\n",
    "    \n",
    "    # Get column info from the new (combined) table\n",
    "    new_db_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    new_columns = new_db_cur.fetchall()\n",
    "    \n",
    "    new_column_names = {col[1] for col in new_columns}\n",
    "    \n",
    "    for col in source_columns:\n",
    "        col_name, col_type = col[1], col[2]\n",
    "        \n",
    "        # Check directly if the column already exists in the new table\n",
    "        if col_name not in new_column_names:\n",
    "            # Proceed with adding the column\n",
    "            try:\n",
    "                alter_stmt = f\"ALTER TABLE \\\"{table_name}\\\" ADD COLUMN \\\"{col_name}\\\" {col_type}\"\n",
    "                new_db_cur.execute(alter_stmt)\n",
    "            except sqlite3.OperationalError as e:\n",
    "                print(f\"Error adding column {col_name} to table {table_name}: {e}\")\n",
    "    \n",
    "    new_db_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the databases into a new file\n",
    "\n",
    "- version 1 simple logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error adding column Game_ID to table goalie_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table game_details: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table player_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table linescore: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table penalty_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table scoring_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table goalie_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table game_details: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table player_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table linescore: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table penalty_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table scoring_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table goalie_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table game_details: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table player_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table linescore: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table penalty_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table scoring_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table goalie_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table game_details: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table player_stats: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table linescore: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table penalty_summary: duplicate column name: Game_ID\n",
      "Error adding column Game_ID to table scoring_summary: duplicate column name: Game_ID\n",
      "Databases combined successfully.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def create_table_from_source(new_db_conn, source_conn, table_name):\n",
    "    \"\"\"\n",
    "    Creates a table in the new database based on the schema of the source table.\n",
    "    \"\"\"\n",
    "    source_cur = source_conn.cursor()\n",
    "    source_cur.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = source_cur.fetchall()\n",
    "    \n",
    "    # Rename 'Clean_Name' column to 'Player' for the master_roster table\n",
    "    if table_name == \"master_roster\":\n",
    "        columns = [(col[0], 'Player' if col[1] == 'Clean_Name' else col[1], col[2], col[3], col[4], col[5]) for col in columns]\n",
    "    \n",
    "    # Construct the CREATE TABLE statement\n",
    "    col_defs = ', '.join([f'\"{col[1]}\" {col[2]}' for col in columns])\n",
    "    create_stmt = f\"CREATE TABLE IF NOT EXISTS {table_name} ({col_defs})\"\n",
    "    \n",
    "    new_db_conn.execute(create_stmt)\n",
    "\n",
    "def insert_data_from_source(new_db_conn, source_conn, table_name):\n",
    "    \"\"\"\n",
    "    Inserts data from the source table into the corresponding table in the new database.\n",
    "    Handles renaming 'Clean_Name' to 'Player' if necessary and quotes column names to avoid syntax errors.\n",
    "    \"\"\"\n",
    "    source_cur = source_conn.cursor()\n",
    "    source_cur.execute(f\"SELECT * FROM {table_name}\")\n",
    "    column_names = [description[0] for description in source_cur.description]\n",
    "    \n",
    "    # Handle potential 'Clean_Name' to 'Player' renaming\n",
    "    if 'Clean_Name' in column_names and table_name == \"master_roster\":\n",
    "        column_names = ['Player' if col == 'Clean_Name' else col for col in column_names]\n",
    "    \n",
    "    # Quote column names to handle reserved words or special characters\n",
    "    columns_str = ', '.join([f'\"{col}\"' for col in column_names])\n",
    "    placeholders = ', '.join(['?'] * len(column_names))\n",
    "    \n",
    "    data = source_cur.fetchall()\n",
    "    new_db_cur = new_db_conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        new_db_cur.executemany(f\"INSERT INTO \\\"{table_name}\\\" ({columns_str}) VALUES ({placeholders})\", data)\n",
    "        new_db_conn.commit()\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        print(f\"Integrity error occurred while inserting data into {table_name}: {e}\")\n",
    "\n",
    "\n",
    "def combine_databases(db_folder, output_db_path):\n",
    "    # Connect to the new database (this will create it if it doesn't exist)\n",
    "    new_db_conn = sqlite3.connect(output_db_path)\n",
    "    \n",
    "    for db_file in os.listdir(db_folder):\n",
    "        if db_file.endswith('.db'):\n",
    "            source_db_path = os.path.join(db_folder, db_file)\n",
    "            source_conn = sqlite3.connect(source_db_path)\n",
    "            \n",
    "            # Get list of tables from the source DB\n",
    "            source_cur = source_conn.cursor()\n",
    "            source_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "            tables = source_cur.fetchall()\n",
    "            \n",
    "            for table_info in tables:\n",
    "                table_name = table_info[0]\n",
    "                \n",
    "                # Ensure the table exists and its schema is up-to-date\n",
    "                create_table_from_source(new_db_conn, source_conn, table_name)\n",
    "                adjust_table_schema(new_db_conn, source_conn, table_name)\n",
    "                \n",
    "                # Then insert data\n",
    "                insert_data_from_source(new_db_conn, source_conn, table_name)\n",
    "\n",
    "            \n",
    "            source_conn.close()\n",
    "    \n",
    "    new_db_conn.close()\n",
    "\n",
    "# Example usage\n",
    "# db_folder = 'path/to/your/db_folder'  # DEFINED ABOVE IN SETUP\n",
    "output_db_path = f'{db_folder}/../Combined_DB_v2.db'  # Choose your output path\n",
    "combine_databases(db_folder, output_db_path)\n",
    "\n",
    "print(\"Databases combined successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your db_folder and the path for the new, combined database\n",
    "# db_folder = 'path/to/your/db_folder'  # Update this path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
