{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note  book to explore and visualize the results tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "# load results from 1901 to 2001 season\n",
    "part1_df = pd.read_csv('..//data//results_table_1901_2001_new.csv')\n",
    "\n",
    "## load results from 2002 to 2022 season\n",
    "part2_df = pd.read_csv('..//data//results_table_2002_2022_new.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(len(part1_df))\n",
    "print(len(part2_df))\n",
    "\n",
    "# Recreate the Game_ID column in part1 to match the format in part2\n",
    "## Example '2002-10-01_Windsor_Bowling Green'\n",
    "\n",
    "part1_df['Game_ID'] = part1_df['Date'].astype(str) + '_' + part1_df['Home_Team'] + '_' + part1_df['Away_Team']\n",
    "\n",
    "\n",
    "\n",
    "part1_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "drop_cols = ['Metrics_Link', 'Box_Link']\n",
    "# drop the columns that are not needed\n",
    "part2_df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "part2_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the two dataframes into a single dataframe\n",
    "df = pd.concat([part1_df, part2_df])\n",
    "\n",
    "## aBOUT 75 games have null values in the score columns - most (60) are from end of cancelled 2019-2020 season\n",
    "## drop these rows\n",
    "df.dropna(subset=['Home_Score', 'Away_Score'], inplace=True)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df.head(1)\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Save the resulting dataframe to a csv file - This is the cleaned all_time results table\n",
    "# df.to_csv('..//data//results_table_all_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts for the conference column\n",
    "df['Conference'].value_counts()\n",
    "\n",
    "# Get the top 10% of the conferences\n",
    "top_conf = df['Conference'].value_counts().head(30).index.tolist()\n",
    "\n",
    "# # Print a report on the 50 conferences with the most games played\n",
    "# for conf in top_conf:\n",
    "#     print(conf)\n",
    "#     print(df[df['Conference'] == conf]['Home_Score'].describe())\n",
    "#     print('\\n')\n",
    "\n",
    "# Print list of top conferences\n",
    "print(top_conf)\n",
    "\n",
    "# Unique values for the conference column\n",
    "len(df['Conference'].unique())\n",
    "\n",
    "# Clean up the conference column - use list\n",
    "real_conferences = ['WCHA', 'ECAC', 'CCHA', 'Hockey East', 'Atlantic Hockey',\n",
    "                    'NCHC', 'Big Ten','MAAC', 'CHA', 'Ivy League',\n",
    "                    'Intercollegiate', 'Northeast League', 'Non-Conference',\n",
    "                    'Intercollegiate']\n",
    "\n",
    "## Create a copy of the original dataframe\n",
    "masked_df = df.copy()\n",
    "\n",
    "# Drop rows if the conference is not in the list of real conferences\n",
    "masked_df = masked_df[masked_df['Conference'].isin(real_conferences)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save a table with the conference assignments for each team each year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pre-Step - Create a Season_Year column (season lasts from sSept to June - Season_Year is the year the season starts)\n",
    "def get_season_year(date):\n",
    "    year = int(date.split('-')[0])\n",
    "    month = int(date.split('-')[1])\n",
    "    if month < 9:\n",
    "        year -= 1\n",
    "    return year\n",
    "\n",
    "# Pre Process -  Create a Season_Year column\n",
    "masked_df['Season_Year'] = masked_df['Date'].apply(get_season_year)\n",
    "\n",
    "# Full block of code for the revised approach\n",
    "\n",
    "# Step 1: Filter out the relevant columns\n",
    "filtered_df = masked_df[['Season_Year', 'Conference', 'Home_Team', 'Away_Team']]\n",
    "\n",
    "# Step 2: Create a set of unique pairs of Season_Year and Team for both home and away games\n",
    "home_teams = filtered_df[['Season_Year', 'Home_Team', 'Conference']].rename(columns={'Home_Team': 'Team'})\n",
    "away_teams = filtered_df[['Season_Year', 'Away_Team', 'Conference']].rename(columns={'Away_Team': 'Team'})\n",
    "all_teams = pd.concat([home_teams, away_teams])\n",
    "\n",
    "# Step 3: Group the data by Season_Year and Team, then count the occurrences of each Conference\n",
    "grouped = all_teams.groupby(['Season_Year', 'Team', 'Conference']).size().reset_index(name='Count')\n",
    "\n",
    "# Step 4: For each group, pick the conference that appears most frequently (ignoring 'Non-Conference' if other options are available)\n",
    "def choose_most_frequent(group):\n",
    "    group = group.sort_values('Count', ascending=False)\n",
    "    if 'Non-Conference' in group['Conference'].values:\n",
    "        group = group[group['Conference'] != 'Non-Conference']\n",
    "        if group.empty:\n",
    "            return 'None'\n",
    "    return group.iloc[0]['Conference']\n",
    "\n",
    "most_frequent_conference = grouped.groupby(['Season_Year', 'Team']).apply(choose_most_frequent).reset_index(name='Conference')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path_final_automatic = '../data/team_conference_by_year.csv'\n",
    "most_frequent_conference.to_csv(output_path_final_automatic, index=False)\n",
    "\n",
    "output_path_final_automatic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Change the data type of the Score columns to int\n",
    "# drop any rows with null values in the score columns\n",
    "df.dropna(subset=['Home_Score', 'Away_Score'], inplace=True)\n",
    "int_cols = ['Home_Score', 'Away_Score']\n",
    "df[int_cols] = df[int_cols].astype(int)\n",
    "\n",
    "## Store Date as a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "## Store the season_year in a separate column as an int\n",
    "## A season last from September to July of the following year\n",
    "## Example: 2019-2020 season is stored as 2019\n",
    "\n",
    "# simple function to assign the season year to each game\n",
    "def season_year(date):\n",
    "    if date.month >= 9:\n",
    "        return date.year\n",
    "    else:\n",
    "        return date.year - 1\n",
    "    \n",
    "# apply the function to the date column and store the results in a new column\n",
    "df['Season_Year'] = df['Date'].apply(season_year)\n",
    "# store as an int\n",
    "df['Season_Year'] = df['Season_Year'].astype(int)\n",
    "\n",
    "\n",
    "# Save the resulting dataframe to a csv file - This is the cleaned all_time results table\n",
    "df.to_csv('..//data//results_table_all_time.csv', index=False)\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "## value counts for the conference column\n",
    "df['Conference'].value_counts()\n",
    "\n",
    "# are there any exhibitions games in the data set? 'Exhibition' in the COnference column\n",
    "# df[df['Conference'] == 'Exhibition']\n",
    "\n",
    "# drop all rows with 'Exhibition' in the Conference column\n",
    "df = df[df['Conference'] != 'Exhibition']\n",
    "\n",
    "# Create full team list\n",
    "team_list = list(df['Home_Team'].unique())\n",
    "team_list.extend(list(df['Away_Team'].unique()))\n",
    "team_list = list(set(team_list))\n",
    "\n",
    "full_team_list = sorted(team_list)\n",
    "\n",
    "# print(len(team_list))\n",
    "\n",
    "print ('Total number of teams in the data set: ', len(full_team_list))\n",
    "print ('Total number of games in the data set: ', len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "### Take the raw results table to create a dataframe with the year by year breakdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Helper function to calculate wins, loses, ties, winning percentage, goals scored per game, and goals allowed per game\n",
    "def calculate_stats(df, team_column, score_column, opponent_score_column):\n",
    "    wins = len(df[df[score_column] > df[opponent_score_column]])\n",
    "    loses = len(df[df[score_column] < df[opponent_score_column]])\n",
    "    ties = len(df[df[score_column] == df[opponent_score_column]])\n",
    "    total_games = wins + loses + ties\n",
    "    \n",
    "    win_pct = wins / total_games if total_games > 0 else 0\n",
    "    goals_scored_per_game = df[score_column].sum() / total_games if total_games > 0 else 0\n",
    "    goals_allowed_per_game = df[opponent_score_column].sum() / total_games if total_games > 0 else 0\n",
    "    \n",
    "    return wins, loses, ties, win_pct, goals_scored_per_game, goals_allowed_per_game\n",
    "\n",
    "\n",
    "# Integrate tqdm into the function for progress tracking\n",
    "def calculate_team_stats_by_season_with_tqdm(df, unique_teams):\n",
    "    summary_list = []\n",
    "    unique_seasons = sorted(df['Season_Year'].unique())\n",
    "    \n",
    "    # Wrap the outer loop with tqdm for progress tracking\n",
    "    for season in tqdm(unique_seasons, desc=\"Processing seasons\"):\n",
    "        season_data = df[df['Season_Year'] == season]\n",
    "        \n",
    "        for team in unique_teams:\n",
    "            team_data_home = season_data[season_data['Home_Team'] == team]\n",
    "            team_data_away = season_data[season_data['Away_Team'] == team]\n",
    "            \n",
    "            stats = {'Season_Year': season, 'Team': team}\n",
    "            \n",
    "            # Calculate the \"Home\" and \"Away\" stats first\n",
    "            for label, team_data_label, team_column, score_column, opponent_score_column in [\n",
    "                ('Home', team_data_home, 'Home_Team', 'Home_Score', 'Away_Score'),\n",
    "                ('Away', team_data_away, 'Away_Team', 'Away_Score', 'Home_Score')\n",
    "            ]:\n",
    "                stats[f'{label}_Wins'], stats[f'{label}_Loses'], stats[f'{label}_Ties'], stats[f'{label}_Win_Pct'], stats[f'{label}_Goals_Scored_Per_Game'], stats[f'{label}_Goals_Allowed_Per_Game'] = calculate_stats(\n",
    "                    team_data_label, team_column, score_column, opponent_score_column\n",
    "                )\n",
    "            \n",
    "            # Sum the \"Home\" and \"Away\" counts for \"Overall\" stats\n",
    "            stats['Overall_Wins'] = stats['Home_Wins'] + stats['Away_Wins']\n",
    "            stats['Overall_Loses'] = stats['Home_Loses'] + stats['Away_Loses']\n",
    "            stats['Overall_Ties'] = stats['Home_Ties'] + stats['Away_Ties']\n",
    "            ##################\n",
    "            ## ADDING POINT SYSTEM\n",
    "            stats['Overall_Points'] = stats['Overall_Wins'] * 2 + stats['Overall_Ties']\n",
    "            ##################\n",
    "            total_games = stats['Overall_Wins'] + stats['Overall_Loses'] + stats['Overall_Ties']\n",
    "            stats['Overall_Win_Pct'] = stats['Overall_Wins'] / total_games if total_games > 0 else 0\n",
    "            stats['Overall_Goals_Scored_Per_Game'] = (team_data_home['Home_Score'].sum() + team_data_away['Away_Score'].sum()) / total_games if total_games > 0 else 0\n",
    "            stats['Overall_Goals_Allowed_Per_Game'] = (team_data_home['Away_Score'].sum() + team_data_away['Home_Score'].sum()) / total_games if total_games > 0 else 0\n",
    "            \n",
    "            # Calculate the other scenarios\n",
    "            for label, team_data_label, team_column, score_column, opponent_score_column in [\n",
    "                ('Non_Conference', pd.concat([team_data_home[team_data_home['Conference'] == 'Non-Conference'], team_data_away[team_data_away['Conference'] == 'Non-Conference']]), 'Home_Team', 'Home_Score', 'Away_Score'),\n",
    "                ('Conference', pd.concat([team_data_home[team_data_home['Conference'] != 'Non-Conference'], team_data_away[team_data_away['Conference'] != 'Non-Conference']]), 'Home_Team', 'Home_Score', 'Away_Score'),\n",
    "                ('Overtime', pd.concat([team_data_home[team_data_home['Game_Notes'].str.contains('ot|OT', na=False)], team_data_away[team_data_away['Game_Notes'].str.contains('ot|OT', na=False)]]), 'Home_Team', 'Home_Score', 'Away_Score')\n",
    "            ]:\n",
    "                stats[f'{label}_Wins'], stats[f'{label}_Loses'], stats[f'{label}_Ties'], stats[f'{label}_Win_Pct'], stats[f'{label}_Goals_Scored_Per_Game'], stats[f'{label}_Goals_Allowed_Per_Game'] = calculate_stats(\n",
    "                    team_data_label, team_column, score_column, opponent_score_column\n",
    "                )\n",
    "                \n",
    "            summary_list.append(stats)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_list)\n",
    "    return summary_df\n",
    "\n",
    "new_df = df.copy()\n",
    "# Example code to run the function with tqdm on the full dataset\n",
    "# Uncomment the following line to run the function\n",
    "complete_summary_df_with_tqdm = calculate_team_stats_by_season_with_tqdm(new_df, full_team_list)\n",
    "\n",
    "# # Show the example code to run the function\n",
    "# example_code_to_run_function = '''\n",
    "# # Run the function with tqdm on the full dataset\n",
    "# complete_summary_df_with_tqdm = calculate_team_stats_by_season_with_tqdm(new_df, full_team_list)\n",
    "# '''\n",
    "\n",
    "# example_code_to_run_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW AdjustMEnt\n",
    "\n",
    "## trying to calculate the points for the season \n",
    "\n",
    "want to calculate for each scenereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_summary_df_with_tqdm.head(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the results to a csv file\n",
    "complete_summary_df_with_tqdm.to_csv('..//data//tableau//team_stats_by_season_all_time.csv', index=False)\n",
    "\n",
    "# Load the results from the csv file\n",
    "# complete_summary_df_with_tqdm = pd.read_csv('..//data//team_stats_by_season_all_time.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the data by dropping unnecessary / empty rows. \n",
    "\n",
    "## If a team has nothing but 0s in the stats columns, drop the row\n",
    "\n",
    "working_df = complete_summary_df_with_tqdm\n",
    "\n",
    "working_df['Total_Games'] = working_df['Overall_Wins'] + working_df['Overall_Loses'] + working_df['Overall_Ties']\n",
    "\n",
    "working_df['Total_Games'].value_counts()\n",
    "\n",
    "print(len(working_df))\n",
    "# If a row has no total games, drop the row\n",
    "working_df = working_df[working_df['Total_Games'] > 0]\n",
    "\n",
    "print(len(working_df))\n",
    "\n",
    "\n",
    "\n",
    "## Save the results to a csv file CLEANED\n",
    "working_df.to_csv('..//data//VER2_CLEANED_team_stats_by_season_all_time.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe of the location of each school using google places api\n",
    "# This will allow us to do some cool map visualizations\n",
    "\n",
    "# get a unique list of schools in the dataframe from both the home and away columns\n",
    "schools = df['Home_Team'].unique().tolist() + df['Away_Team'].unique().tolist()\n",
    "# remove any duplicates in th list\n",
    "schools = list(set(schools))\n",
    "len(schools)\n",
    "\n",
    "# filter list down to team names that are relevant to the analysis - count the number of games played by each team\n",
    "team_games = df['Home_Team'].value_counts() + df['Away_Team'].value_counts()\n",
    "\n",
    "# sort the list by the number of games played\n",
    "team_games.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# # create a histogram of the number of games played by each team\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# ax.hist(team_games, bins=50)\n",
    "\n",
    "## basic stats on the number of games played by each team\n",
    "team_games.describe()\n",
    "\n",
    "# create a list of the 100 teams that have played the most games\n",
    "team_list = team_games[:100].index.tolist()\n",
    "# create a list of teams that have played at least 500 games\n",
    "# team_list = team_games[team_games >= 50].index.tolist()\n",
    "len(team_list)\n",
    "## print a sample of the schools\n",
    "# team_list[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a dictionary of the location of each school using google places api\n",
    "import sys\n",
    "\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "sys.path.append(\"../TEMP\") # add TEMP folder to path to import api key\n",
    "\n",
    "from keys import API_KEY # import the api key\n",
    "\n",
    "# print(API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### BLOCK THAT LOOKS UP TEAM LOCATIONS - TURNED OFF TO REDUCE THE NUMBER OF API CALLS\n",
    "\n",
    "### THE RESULTS OF THE API CALLS ARE SAVED IN THE FILE THAT IS LOADED BELOW\n",
    "\n",
    "# import requests\n",
    "# import json\n",
    "# import pandas as pd  # Importing pandas for DataFrame\n",
    "# from tqdm import tqdm  # Importing tqdm for the progress bar\n",
    "\n",
    "# # team_list = [\"Harvard\", \"Yale\", \"MIT\"]  # Replace with your actual list\n",
    "# additional_term = \"college hockey\"\n",
    "\n",
    "# def fetch_places(school, term, api_key):\n",
    "#     query = f\"{school} {term}\"\n",
    "#     url = f\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={query}&inputtype=textquery&fields=formatted_address,name,geometry&key={api_key}\"\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # List to store results\n",
    "# coordinates_list = []\n",
    "\n",
    "# # Adding a progress bar with tqdm\n",
    "# for school in tqdm(team_list, desc=\"Fetching Places\"):\n",
    "#     results = fetch_places(school, additional_term, API_KEY)\n",
    "#     if results and results['candidates']:\n",
    "#         best_result = results['candidates'][0]  # Assuming the first result is the best\n",
    "#         lat = best_result['geometry']['location']['lat']\n",
    "#         lng = best_result['geometry']['location']['lng']\n",
    "#         coordinates_list.append({\n",
    "#             'School': school,\n",
    "#             'Latitude': lat,\n",
    "#             'Longitude': lng\n",
    "#         })\n",
    "\n",
    "# # Create DataFrame\n",
    "# places_df = pd.DataFrame(coordinates_list)\n",
    "\n",
    "# # Save DataFrame to CSV\n",
    "# places_df.to_csv(\"school_coordinates.csv\", index=False)\n",
    "\n",
    "# # Show the DataFrame (Optional)\n",
    "# print(places_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the team locations table to a csv file in the data folder\n",
    "# places_df.to_csv('..//data//top100_team_locations.csv', index=False)\n",
    "\n",
    "## Load the team locations table from the csv file from previous step\n",
    "places_df = pd.read_csv('..//data//top100_team_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save teh complete summary table to a csv file for review\n",
    "# complete_summary_df.to_csv('..//data//VER3_complete_summary_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_no_exhibition = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to hold the counts\n",
    "overall_record = defaultdict(lambda: {'Wins': 0, 'Losses': 0, 'Ties': 0, 'OT': 0})\n",
    "home_record = defaultdict(lambda: {'Wins': 0, 'Losses': 0, 'Ties': 0, 'OT': 0})\n",
    "away_record = defaultdict(lambda: {'Wins': 0, 'Losses': 0, 'Ties': 0, 'OT': 0})\n",
    "\n",
    "# Iterate through each row to populate the counts\n",
    "for idx, row in filtered_data_no_exhibition.iterrows():\n",
    "    home_team, home_score = row['Home_Team'], row['Home_Score']\n",
    "    away_team, away_score = row['Away_Team'], row['Away_Score']\n",
    "    is_ot = row['OT']\n",
    "\n",
    "    # Update Overall Records\n",
    "    if home_score > away_score:\n",
    "        overall_record[home_team]['Wins'] += 1\n",
    "        overall_record[away_team]['Losses'] += 1\n",
    "    elif home_score < away_score:\n",
    "        overall_record[home_team]['Losses'] += 1\n",
    "        overall_record[away_team]['Wins'] += 1\n",
    "    else:\n",
    "        overall_record[home_team]['Ties'] += 1\n",
    "        overall_record[away_team]['Ties'] += 1\n",
    "\n",
    "    # Update Home Records\n",
    "    if home_score > away_score:\n",
    "        home_record[home_team]['Wins'] += 1\n",
    "        away_record[away_team]['Losses'] += 1\n",
    "    elif home_score < away_score:\n",
    "        home_record[home_team]['Losses'] += 1\n",
    "        away_record[away_team]['Wins'] += 1\n",
    "    else:\n",
    "        home_record[home_team]['Ties'] += 1\n",
    "        away_record[away_team]['Ties'] += 1\n",
    "\n",
    "    # Update OT Counts\n",
    "    if pd.notna(is_ot):\n",
    "        overall_record[home_team]['OT'] += 1\n",
    "        overall_record[away_team]['OT'] += 1\n",
    "        home_record[home_team]['OT'] += 1\n",
    "        away_record[away_team]['OT'] += 1\n",
    "\n",
    "# Convert dictionaries to DataFrames\n",
    "overall_df = pd.DataFrame.from_dict(overall_record, orient='index').reset_index().rename(columns={'index': 'Team'}).add_prefix('Overall_')\n",
    "home_df = pd.DataFrame.from_dict(home_record, orient='index').reset_index().rename(columns={'index': 'Team'}).add_prefix('Home_')\n",
    "away_df = pd.DataFrame.from_dict(away_record, orient='index').reset_index().rename(columns={'index': 'Team'}).add_prefix('Away_')\n",
    "\n",
    "# Add 'Total_Games' and 'Win_Percent' to each DataFrame\n",
    "for df, prefix in [(overall_df, 'Overall'), (home_df, 'Home'), (away_df, 'Away')]:\n",
    "    df[f'{prefix}_Total_Games'] = df[[f'{prefix}_Wins', f'{prefix}_Losses', f'{prefix}_Ties']].sum(axis=1)\n",
    "    df[f'{prefix}_Win_Percent'] = (df[f'{prefix}_Wins'] / df[f'{prefix}_Total_Games']) * 100\n",
    "\n",
    "# Rename the 'Team' columns for merging\n",
    "overall_df.rename(columns={'Overall_Team': 'Team'}, inplace=True)\n",
    "home_df.rename(columns={'Home_Team': 'Team'}, inplace=True)\n",
    "away_df.rename(columns={'Away_Team': 'Team'}, inplace=True)\n",
    "\n",
    "# Merge DataFrames for a comprehensive view\n",
    "final_df = overall_df.merge(home_df, on='Team').merge(away_df, on='Team')\n",
    "\n",
    "# Fliter the final_df to only include teams in the top 100\n",
    "final_df = final_df[final_df['Team'].isin(team_list)]\n",
    "\n",
    "# Sort by overall winning percentage\n",
    "final_df_sorted = final_df.sort_values('Overall_Win_Percent', ascending=False)\n",
    "\n",
    "\n",
    "final_df_sorted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop teams from data if they have no wins at all\n",
    "final_df_sorted = final_df_sorted[final_df_sorted['Overall_Wins'] > 0]\n",
    "\n",
    "## Plot the tops and bottom teams in overall win percentage and label the teams with their names and win lose records\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot the top 10 teams\n",
    "plt.bar(final_df_sorted['Team'].head(10), final_df_sorted['Overall_Win_Percent'].head(10), color='green')\n",
    "\n",
    "# Plot the bottom 10 teams\n",
    "plt.bar(final_df_sorted['Team'].tail(10), final_df_sorted['Overall_Win_Percent'].tail(10), color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Win Percentage')\n",
    "plt.xlabel('Team')\n",
    "plt.title('Top 10 and Bottom 10 Teams by Overall Win Percentage')\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a histogram of the overall win percentage\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(final_df_sorted['Overall_Win_Percent'], bins=20, color='blue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Win Percentage')\n",
    "plt.title('Histogram of Overall Win Percentage')\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE TO MAKE AND PLOT THE A ROLLING $ YEAR AVERAGE OF THE WIN PERCENTAGE\n",
    "# Convert the 'Date' column to datetime format and extract the year\n",
    "df_orig['Year'] = pd.to_datetime(df_orig['Date']).dt.year\n",
    "\n",
    "# Filter out exhibition games\n",
    "filtered_df = df_orig[df_orig['Conference'] != 'Exhibition']\n",
    "\n",
    "# Initialize a dictionary to hold annual win counts for each team\n",
    "annual_wins = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Initialize a dictionary to hold annual game counts for each team\n",
    "annual_games = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate through each row to populate the counts\n",
    "for idx, row in filtered_df.iterrows():\n",
    "    home_team, home_score, away_team, away_score, year = row['Home_Team'], row['Home_Score'], row['Away_Team'], row['Away_Score'], row['Year']\n",
    "    \n",
    "    # Update annual game counts\n",
    "    annual_games[home_team][year] += 1\n",
    "    annual_games[away_team][year] += 1\n",
    "\n",
    "    # Update annual win counts\n",
    "    if home_score > away_score:\n",
    "        annual_wins[home_team][year] += 1\n",
    "    elif home_score < away_score:\n",
    "        annual_wins[away_team][year] += 1\n",
    "\n",
    "# Calculate annual win percentages and create a DataFrame\n",
    "team_years = []\n",
    "win_percentages = []\n",
    "\n",
    "for team, years in annual_games.items():\n",
    "    for year, total_games in years.items():\n",
    "        win_count = annual_wins[team].get(year, 0)\n",
    "        win_percent = (win_count / total_games) * 100\n",
    "        team_years.append((team, year))\n",
    "        win_percentages.append(win_percent)\n",
    "\n",
    "# Create a DataFrame for the annual win percentages\n",
    "annual_win_df = pd.DataFrame(team_years, columns=['Team', 'Year'])\n",
    "annual_win_df['Win_Percentage'] = win_percentages\n",
    "\n",
    "# Sort the DataFrame by Team and Year\n",
    "annual_win_df.sort_values(['Team', 'Year'], inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the calculations\n",
    "annual_win_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate and add the rolling 4 year average to the DataFrame\n",
    "\n",
    "# Calculate the 4-year rolling average of win percentages for each team\n",
    "annual_win_df['4Yr_Rolling_Avg'] = annual_win_df.groupby('Team')['Win_Percentage'].rolling(window=4).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Display the first few rows to verify the calculations\n",
    "# annual_win_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a plot of the rolling average for big ten teams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define team colors for the plot\n",
    "team_colors = {\n",
    "    'Michigan State': 'green',\n",
    "    'Michigan': 'blue',\n",
    "    'Minnesota': 'maroon',\n",
    "    'Penn State': 'navy',\n",
    "    'Wisconsin': 'red',\n",
    "    'Notre Dame': 'gold',\n",
    "    'Ohio State': 'gray'\n",
    "}\n",
    "\n",
    "# Filter the DataFrame to only include the teams of interest\n",
    "teams_of_interest = ['Michigan State', 'Michigan', 'Minnesota', 'Penn State', 'Wisconsin', 'Notre Dame', 'Ohio State']\n",
    "filtered_annual_win_df = annual_win_df[annual_win_df['Team'].isin(teams_of_interest)]\n",
    "\n",
    "# Plot the 4-year rolling averages\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for team, color in team_colors.items():\n",
    "    team_data = filtered_annual_win_df[filtered_annual_win_df['Team'] == team]\n",
    "    plt.plot(team_data['Year'], team_data['4Yr_Rolling_Avg'], label=team, color=color)\n",
    "\n",
    "plt.title('4-Year Rolling Average of Win Percentage')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('4-Year Rolling Average Win %')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
