{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Book to collect data about the current college hockey season from College Hockey News\n",
    "\n",
    "## Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "## global variables\n",
    "# current_year_url = 'https://www.collegehockeynews.com/schedules/'\n",
    "\n",
    "current_year_url = 'https://www.collegehockeynews.com/schedules/?season=20222023'\n",
    "\n",
    "## Base usl for box scores and metrics\n",
    "base_url = 'https://www.collegehockeynews.com'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_13460\\2541037650.py:83: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2022-10-01_Ontario_Providence' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[row.Index, 'Game_ID'] = game_id\n"
     ]
    }
   ],
   "source": [
    "## Functions\n",
    "### Parse the current season schedule / results page\n",
    "\n",
    "def parse_current_season(url):\n",
    "        # Initialize variables\n",
    "    current_date = None\n",
    "    current_conference = None\n",
    "    game_notes = None\n",
    "\n",
    "    # Initialize an empty list to hold the data\n",
    "    data = []\n",
    "\n",
    "    # Parse the page with BeautifulSoup\n",
    "    # Get the page with requests\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # select the table or tables\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find relevant information\n",
    "    for row in rows:\n",
    "        # Check for date row\n",
    "        if row.get('class') == ['stats-section']:\n",
    "            current_date = row.find('td').text.strip()\n",
    "        # Check for conference row\n",
    "        elif row.get('class') == ['sked-header']:\n",
    "            current_conference = row.find('td').text.strip()\n",
    "        # Check for game notes\n",
    "        elif len(row.find_all('td')) == 2:\n",
    "            game_notes = row.find_all('td')[1].text.strip()\n",
    "        # Process rows with game data\n",
    "        elif row.get('valign') == 'top':\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 9:\n",
    "                home_team = cells[0].text.strip()\n",
    "                home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "                home_score = cells[1].text.strip()\n",
    "                away_team = cells[3].text.strip()\n",
    "                away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "                away_score = cells[4].text.strip()\n",
    "                ot = cells[5].text.strip()\n",
    "                box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "                metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "                # Capture Game Notes\n",
    "                game_notes_cell = cells[-1].find('small')\n",
    "                game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "                # Append data to the list\n",
    "                data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "                game_notes = None  # Reset game notes for the next row\n",
    "    return data\n",
    "\n",
    "## call the function\n",
    "data = parse_current_season(current_year_url)\n",
    "\n",
    "\n",
    "# Create a dataframe from the list\n",
    "\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# remove day of the week from date\n",
    "# format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "### Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Function to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    game_id = f'{row.Date}_{home_team_abbr}_{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}_{row.Home_Team}_{row.Away_Team}', axis=1)\n",
    "\n",
    "## Filter out games that have not been played yet\n",
    "df = df[df['Home_Score'] != '']\n",
    "\n",
    "# Replace Nan values in metrics column with empty string\n",
    "df['Metrics_Link'] = df['Metrics_Link'].fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.tail(10)\n",
    "\n",
    "## Save csv of just the current season results\n",
    "df.to_csv('../TEMP/TEST_season.csv', index=False)\n",
    "\n",
    "# Store the dataframe as games_df\n",
    "games_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for parsing the box score and metrics pages\n",
    "\n",
    "# Initialize logging for Error and Warning messages\n",
    "logging.basicConfig(filename='../TEMP/TEST_scrape.log', level=logging.INFO)\n",
    "\n",
    "#### PARSE PLAYER STATS TABLE ####\n",
    "def parse_player_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the playersums div\n",
    "    playersums_div = soup.find('div', id='playersums')\n",
    "    if playersums_div is None:\n",
    "        return \"Player summaries div not found\"\n",
    "\n",
    "    # Initialize list to store player stats\n",
    "    player_stats = []\n",
    "\n",
    "    # Loop through each playersum div\n",
    "    for player_sum in playersums_div.find_all('div', class_='playersum'):\n",
    "        team = player_sum.find('td').text.strip()\n",
    "        \n",
    "        # Loop through table rows\n",
    "        for row in player_sum.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                player = cols[0].text.strip()\n",
    "                goals = cols[1].text.strip()\n",
    "                assists = cols[2].text.strip()\n",
    "                points = cols[3].text.strip()\n",
    "                plus_minus = cols[4].text.strip()\n",
    "                shots = cols[5].text.strip()\n",
    "                pim = cols[6].text.strip()\n",
    "                fowl = cols[7].text.strip() if len(cols) > 7 else None\n",
    "                \n",
    "                fow, fol = None, None\n",
    "                win_percentage = None\n",
    "                \n",
    "                \n",
    "\n",
    "                try:\n",
    "                    if fowl and '‑' in fowl:  # Checking if it contains a hyphen\n",
    "                        fow, fol = map(int, fowl.split('‑'))\n",
    "                        total_fo = fow + fol\n",
    "                        win_percentage = (fow / total_fo) * 100 if total_fo > 0 else 0\n",
    "                except ValueError:\n",
    "                    fow, fol, win_percentage = None, None, None\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                player_stat = {\n",
    "                    'Team': team,\n",
    "                    'Player': player,\n",
    "                    'G': goals,\n",
    "                    'A': assists,\n",
    "                    'Pt.': points,\n",
    "                    '+/-': plus_minus,\n",
    "                    'Sh': shots,\n",
    "                    'PIM': pim,\n",
    "                    'FOW': fow,\n",
    "                    'FOL': fol,\n",
    "                    'FO%': win_percentage\n",
    "                }\n",
    "                player_stats.append(player_stat)\n",
    "\n",
    "    return pd.DataFrame(player_stats)\n",
    "\n",
    "\n",
    "############# PARSEING SCORING SUMMARY WITH BS4\n",
    "\n",
    "def parse_scoring_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the scoring div and table\n",
    "    scoring_div = soup.find('div', id='scoring')\n",
    "    if scoring_div is None:\n",
    "        logging.error(\"Scoring div not found\")\n",
    "        return None\n",
    "\n",
    "    scoring_table = scoring_div.find('table')\n",
    "    if scoring_table is None:\n",
    "        logging.error(\"Scoring table not found within the scoring div\")\n",
    "        return None\n",
    "\n",
    "    # Initialize list to store scoring events\n",
    "    scoring_events = []\n",
    "    period = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in scoring_table.find_all('tr'):\n",
    "        if 'stats-section' in row.get('class', []):\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                period = td.text.strip()\n",
    "            else:\n",
    "                logging.warning(\"Period name not found in 'stats-section' row\")\n",
    "                period = \"Unknown\"\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                try:\n",
    "                    team = cols[0].text.strip()\n",
    "                    pp = cols[1].text.strip()\n",
    "\n",
    "                    player_data = cols[3].text.strip()\n",
    "                    match = re.match(r\"(.+)\\s\\((\\d+)\\)\", player_data)\n",
    "                    player = match.group(1) if match else player_data\n",
    "                    goals = int(match.group(2)) if match else None\n",
    "\n",
    "                    assist_data_raw = cols[4].text.strip()\n",
    "                    assist_data = assist_data_raw.split(\", \") if assist_data_raw else []\n",
    "                    assist1 = assist_data[0] if len(assist_data) > 0 else None\n",
    "                    assist2 = assist_data[1] if len(assist_data) > 1 else None\n",
    "\n",
    "                    time = cols[5].text.strip()\n",
    "\n",
    "                    scoring_event = {\n",
    "                        'Period': period,\n",
    "                        'Team': team,\n",
    "                        'PP': pp,\n",
    "                        'Player': player,\n",
    "                        'Player_Goals': goals,\n",
    "                        'Assist1': assist1,\n",
    "                        'Assist2': assist2,\n",
    "                        'Time': time\n",
    "                    }\n",
    "                    scoring_events.append(scoring_event)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"An error occurred while parsing a scoring event row: {e}\")\n",
    "            else:\n",
    "                logging.warning(f\"Insufficient columns in scoring row: {len(cols)}\")\n",
    "\n",
    "    return pd.DataFrame(scoring_events)\n",
    "\n",
    "\n",
    "############# PARSEING PENALTY SUMMARY WITH BS4\n",
    "\n",
    "def parse_penalty_summary(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the penalties div and table\n",
    "    penalties_div = soup.find('div', id='penalties')\n",
    "    if penalties_div is None:\n",
    "        logging.error(\"Penalties div not found\")\n",
    "        return None\n",
    "\n",
    "    penalties_table = penalties_div.find('table')\n",
    "    if penalties_table is None:\n",
    "        logging.error(\"Penalties table not found within the penalties div\")\n",
    "        return None\n",
    "\n",
    "    # Initialize list to store penalty events\n",
    "    penalty_events = []\n",
    "    period = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in penalties_table.find_all('tr'):\n",
    "        if 'stats-section' in row.get('class', []):\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                period = td.text.strip()\n",
    "            else:\n",
    "                logging.warning(\"Period name not found in 'stats-section' row\")\n",
    "                period = \"Unknown\"\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                team = cols[0].text.strip()\n",
    "                player = cols[1].text.strip()\n",
    "                pen_length = cols[2].text.strip()\n",
    "                penalty_type = cols[3].text.strip()\n",
    "                time = cols[4].text.strip()\n",
    "\n",
    "                penalty_event = {\n",
    "                    'Period': period,\n",
    "                    'Team': team,\n",
    "                    'Player': player,\n",
    "                    'Pen_Length': pen_length,\n",
    "                    'Penalty_Type': penalty_type,\n",
    "                    'Time': time\n",
    "                }\n",
    "                penalty_events.append(penalty_event)\n",
    "\n",
    "    return pd.DataFrame(penalty_events)\n",
    "\n",
    "\n",
    "############# PARSEING GOALIE SUMMARY WITH BS4\n",
    "\n",
    "def parse_goalie_stats(html_content):\n",
    "    # Initialize BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the goalies div and table\n",
    "    goalies_div = soup.find('div', id='goalies')\n",
    "    if goalies_div is None:\n",
    "        logging.error(\"Goalies div not found\")\n",
    "        return None\n",
    "\n",
    "    goalies_table = goalies_div.find('table')\n",
    "    if goalies_table is None:\n",
    "        logging.error(\"Goalies table not found within the goalies div\")\n",
    "        return None\n",
    "\n",
    "    # Initialize list to store goalie stats\n",
    "    goalie_stats = []\n",
    "    team = None\n",
    "\n",
    "    # Loop through table rows\n",
    "    for row in goalies_table.find_all('tr'):\n",
    "        if 'stats-header' in row.get('class', []):\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                team = td.text.strip()\n",
    "            else:\n",
    "                logging.warning(\"Team name not found in 'stats-header' row\")\n",
    "                team = \"Unknown\"\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                goalie = cols[0].text.strip()\n",
    "                sv = cols[1].text.strip()\n",
    "                ga = cols[2].text.strip()\n",
    "                minutes = cols[3].text.strip()\n",
    "\n",
    "                goalie_stat = {\n",
    "                    'Team': team,\n",
    "                    'Goalie': goalie,\n",
    "                    'SV': sv,\n",
    "                    'GA': ga,\n",
    "                    'Minutes': minutes\n",
    "                }\n",
    "                goalie_stats.append(goalie_stat)\n",
    "\n",
    "    return pd.DataFrame(goalie_stats)\n",
    "\n",
    "\n",
    "#### PARSE THE ADVANCED TEAM METRICS TABLES ####\n",
    "\n",
    "def parse_advanced_metrics_tables(html_content):\n",
    "    # Initialize list to store DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Parse HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table', {'class': 'sortable metrics'})\n",
    "    \n",
    "    for table in tables:\n",
    "        # Initialize list to store column names and data\n",
    "        col_names = []\n",
    "        col_names_final = []\n",
    "        data = []\n",
    "        \n",
    "        # Get headers\n",
    "        headers = table.find_all('th')\n",
    "        for header in headers:\n",
    "            col_names.append(header.text)\n",
    "        \n",
    "        # Add TOTAL, EVEN STRENGTH, POWER PLAY, CLOSE to column names\n",
    "        section_headers = ['TOTAL', 'EVEN STRENGTH', 'POWER PLAY', 'CLOSE']\n",
    "        for col in col_names:\n",
    "            for section in section_headers:\n",
    "                if col in section_headers:\n",
    "                    temp_col = section\n",
    "                else:\n",
    "                    temp_col = f\"{section}_{col}\"\n",
    "            col_names_final.append(temp_col)\n",
    "        \n",
    "        # print(f\"Length of final column names: {len(col_names_final)}\")  # Debug statement\n",
    "        \n",
    "        # Get data rows\n",
    "        rows = table.find_all('tr')[2:]  # skip header rows\n",
    "        for row in rows:\n",
    "            row_data = []\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "        \n",
    "        # print(f\"Length of first row of data: {len(data[0])}\")  # Debug statement\n",
    "        \n",
    "        # Create DataFrame and append to list\n",
    "        df = pd.DataFrame(data, columns=col_names_final)\n",
    "\n",
    "        ## Fix the column names\n",
    "        new_names = ['Player', 'TOTAL_Block', 'TOTAL_Miss', 'TOTAL_Saved', 'TOTAL_Goals', 'TOTAL_Total_Shots',\n",
    "                    'EVEN_Block', 'EVEN_Miss', 'EVEN_Saved', 'EVEN_Goals', 'EVEN_Total_Shots',\n",
    "                     'PP_Block', 'PP_Miss', 'PP_Saved', 'PP_Goals', 'PP_Total_Shots',\n",
    "                      'CLOSE_Block', 'CLOSE_Miss', 'CLOSE_Saved', 'CLOSE_Goals', 'CLOSE_Total_Shots',\n",
    "                      'D_Blocks', 'Faceoffs']\n",
    "        # Apply the column names to the dataframes\n",
    "        df.columns = new_names\n",
    "\n",
    "        # # Convert data types\n",
    "        # for col in df.columns:\n",
    "        #     if col == 'Player':\n",
    "        #         continue\n",
    "        #     elif col == 'Faceoffs':\n",
    "        #         df[col] = df[col].astype('object')  # or another type that suits this column\n",
    "        #     else:\n",
    "        #         df[col] = df[col].astype('int64')\n",
    "\n",
    "        # Append DataFrame to list\n",
    "        dfs.append(df)\n",
    "        \n",
    "\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "\n",
    "# Complete code for parsing the line chart information with specific positions for forwards and defensemen.\n",
    "\n",
    "\n",
    "def parse_line_chart(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    line_chart_div = soup.find('div', id='linechart')\n",
    "\n",
    "    if line_chart_div is None:\n",
    "        logging.error(\"Line chart div not found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    line_data = []\n",
    "\n",
    "    for team_div in line_chart_div.find_all('div', recursive=False):\n",
    "        h3 = team_div.find('h3')\n",
    "        if h3 is None:\n",
    "            logging.warning(\"Team name not found\")\n",
    "            continue\n",
    "        \n",
    "        team_name = h3.text.strip()\n",
    "        \n",
    "        for line_type_div in team_div.find_all('div', recursive=False):\n",
    "            line_type = line_type_div.get('class')[0] if line_type_div.get('class') else None\n",
    "            if line_type is None:\n",
    "                logging.warning(\"Line type not found\")\n",
    "                continue\n",
    "            \n",
    "            if line_type == 'f':\n",
    "                position_types = ['Left Wing', 'Center', 'Right Wing']\n",
    "            elif line_type == 'd':\n",
    "                position_types = ['Left D', 'Right D']\n",
    "            elif line_type == 'x':\n",
    "                position_types = ['Extra']\n",
    "            elif line_type == 'g':\n",
    "                position_types = ['Goalie']\n",
    "                goalie_count = 1  # Initialize goalie count\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            players = line_type_div.find_all('div')\n",
    "            if not players:\n",
    "                logging.warning(f\"No players found for {team_name} in {line_type}\")\n",
    "                continue\n",
    "            \n",
    "            for i, player in enumerate(players):\n",
    "                player_name = player.text.strip()\n",
    "                if line_type == 'x':\n",
    "                    player_name = player_name.split(' ')[0]\n",
    "                if line_type == 'g':\n",
    "                    line_number = f\"Goalie {goalie_count}\"\n",
    "                    goalie_count += 1\n",
    "                else:\n",
    "                    line_number = i // len(position_types) + 1\n",
    "\n",
    "                position = position_types[i % len(position_types)]\n",
    "                line_data.append({\n",
    "                    'Team': team_name,\n",
    "                    'Line': line_number,\n",
    "                    'Position': position,\n",
    "                    'Player': player_name\n",
    "                })\n",
    "\n",
    "    if not line_data:\n",
    "        logging.error(\"No line data was collected\")\n",
    "\n",
    "    df = pd.DataFrame(line_data)\n",
    "    \n",
    "    # # Log DataFrame info for debugging\n",
    "    # if df.empty:\n",
    "    #     logging.warning(\"Generated line chart DataFrame is empty.\")\n",
    "    # else:\n",
    "    #     logging.info(f\"Generated line chart DataFrame with columns: {df.columns.tolist()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "### Get the Linescore Elements - Score, shots, ect by period####\n",
    "\n",
    "def parse_linescore(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    linescore_data = []\n",
    "    \n",
    "    # Parsing the Goals table\n",
    "    goals_table = soup.select_one(\"#goals table\")\n",
    "    if goals_table is None:\n",
    "        logging.error(\"Goals table not found\")\n",
    "        return None\n",
    "    \n",
    "    rows = goals_table.select('tbody tr')\n",
    "    if not rows:\n",
    "        logging.warning(\"No rows found in Goals table\")\n",
    "        return None\n",
    "    \n",
    "    for row in rows:\n",
    "        team_data = {}\n",
    "        td = row.select_one('td')\n",
    "        if td:\n",
    "            team_data['Team'] = td.text\n",
    "        else:\n",
    "            logging.warning(\"Team name not found in Goals table\")\n",
    "            continue\n",
    "\n",
    "        goals = row.select('td')[1:]\n",
    "        for i, goal in enumerate(goals):\n",
    "            period = i + 1\n",
    "            column_name = f'goals{period}' if i < len(goals) - 1 else 'goalsT'\n",
    "            team_data[column_name] = int(goal.text)\n",
    "        \n",
    "        linescore_data.append(team_data)\n",
    "    \n",
    "\n",
    "    # Parsing the Shots table\n",
    "    shots_table = soup.select_one(\"#shots table\")\n",
    "    if shots_table is None:\n",
    "        logging.error(\"Shots table not found\")\n",
    "        return None\n",
    "\n",
    "    rows = shots_table.select('tbody tr')\n",
    "    if not rows:\n",
    "        logging.warning(\"No rows found in Shots table\")\n",
    "        return None\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        shots = row.select('td')[1:]\n",
    "        if not shots:\n",
    "            logging.warning(f\"No shot data found for row {i+1} in Shots table\")\n",
    "            continue\n",
    "\n",
    "        for j, shot in enumerate(shots):\n",
    "            period = j + 1\n",
    "            column_name = f'shots{period}' if j < len(shots) - 1 else 'shotsT'\n",
    "            try:\n",
    "                linescore_data[i][column_name] = int(shot.text.strip())\n",
    "            except ValueError:\n",
    "                logging.warning(f\"Could not convert shot data to integer for row {i+1}, column {j+1}\")\n",
    "                linescore_data[i][column_name] = None\n",
    "\n",
    "    # Parsing the PP table\n",
    "    pp_table = soup.select_one(\"#pp table\")\n",
    "    if pp_table is None:\n",
    "        logging.error(\"PP table not found\")\n",
    "        return None\n",
    "\n",
    "    rows = pp_table.select('tbody tr')\n",
    "    if not rows:\n",
    "        logging.warning(\"No rows found in PP table\")\n",
    "        return None\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            pen_pim = row.select('td')[1].text.split('‑')\n",
    "            linescore_data[i]['Pen'] = int(pen_pim[0])\n",
    "            linescore_data[i]['PIM'] = int(pen_pim[1])\n",
    "\n",
    "            ppg_ppo = row.select('td')[2].text.split('‑')\n",
    "            linescore_data[i]['PPG'] = int(ppg_ppo[0])\n",
    "            linescore_data[i]['PPO'] = int(ppg_ppo[1])\n",
    "\n",
    "            fow_fol = row.select('td')[3].text.split('‑')\n",
    "            linescore_data[i]['FOW'] = int(fow_fol[0])\n",
    "            linescore_data[i]['FOL'] = int(fow_fol[1])\n",
    "            linescore_data[i]['FOW%'] = (linescore_data[i]['FOW'] / (linescore_data[i]['FOW'] + linescore_data[i]['FOL'])) * 100\n",
    "\n",
    "        except (ValueError, IndexError) as e:\n",
    "            logging.warning(f\"Could not process PP data for row {i+1}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(linescore_data)\n",
    "\n",
    "\n",
    "\n",
    "# Function to parse game details\n",
    "\n",
    "\n",
    "def parse_game_details(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    meta_div = soup.find('div', {'id': 'meta'})\n",
    "    if meta_div is None:\n",
    "        logging.error(\"Meta div not found\")\n",
    "        return None\n",
    "    \n",
    "    game_details_div = meta_div.find_all('div')[-1]\n",
    "    if game_details_div is None:\n",
    "        logging.error(\"Game details div not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        date_str = game_details_div.h4.string\n",
    "        day_of_week, date = date_str.split(\", \", 1)\n",
    "        \n",
    "        p_elements = game_details_div.find_all('p')\n",
    "        details_strs = p_elements[0].get_text(separator='|').split('|')\n",
    "        \n",
    "        conference = details_strs[0]\n",
    "        location = details_strs[-1].split('at ')[-1]\n",
    "        details = details_strs[1] if len(details_strs) > 2 else None\n",
    "        \n",
    "        refs_str = p_elements[1].strong.next_sibling\n",
    "        asst_refs_str = p_elements[1].find_all('strong')[1].next_sibling\n",
    "        attendance_str = p_elements[1].find_all('strong')[2].next_sibling\n",
    "        \n",
    "        refs = refs_str.split(', ')\n",
    "        asst_refs = asst_refs_str.split(', ')\n",
    "        refs = [re.sub(r'[^a-zA-Z ]+', '', ref).strip() for ref in refs]\n",
    "        asst_refs = [re.sub(r'[^a-zA-Z ]+', '', ref).strip() for ref in asst_refs]\n",
    "        \n",
    "        attendance = attendance_str.split(\": \")[-1]\n",
    "        # if there is a comma inthe attendance number, remove it\n",
    "        if ',' in attendance:\n",
    "            attendance = int(attendance.replace(',', ''))\n",
    "        \n",
    "        details = details_strs[1] if len(details_strs) > 2 else \"\"\n",
    "\n",
    "        # if details has a '\\n' or '\\t', remove it\n",
    "        if details and '\\n' in details:\n",
    "            details = details.replace('\\n', '').strip()\n",
    "\n",
    "        if details and '\\t' in details:\n",
    "            details = re.sub('\\t', ' ', details)\n",
    "        \n",
    "        game_details = {\n",
    "            'Day': day_of_week,\n",
    "            'Date': date,\n",
    "            'Conference': conference,\n",
    "            'Details': details,\n",
    "            'Location': location,\n",
    "            'Ref1': refs[0],\n",
    "            'Ref2': refs[1] if len(refs) > 1 else None,\n",
    "            'Asst_Ref1': asst_refs[0],\n",
    "            'Asst_Ref2': asst_refs[1] if len(asst_refs) > 1 else None,\n",
    "            'Attendance': attendance\n",
    "        }\n",
    "        \n",
    "        game_details_df = pd.DataFrame([game_details])\n",
    "        return game_details_df\n",
    "\n",
    "    except (AttributeError, IndexError, ValueError) as e:\n",
    "        logging.error(f\"Error while parsing game details: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_box_score(box_score_html):\n",
    "    # Initialize DataFrames to None\n",
    "    scoring_summary = penalty_summary = goalie_stats = player_stats = line_chart = linescore = game_details = None\n",
    "    \n",
    "    try:\n",
    "        scoring_summary = parse_scoring_summary(box_score_html)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_scoring_summary: {e}\")\n",
    "    \n",
    "    try:\n",
    "        penalty_summary = parse_penalty_summary(box_score_html)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_penalty_summary: {e}\")\n",
    "    \n",
    "    try:\n",
    "        goalie_stats = parse_goalie_stats(box_score_html)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_goalie_stats: {e}\")\n",
    "    \n",
    "    try:\n",
    "        player_stats = parse_player_summary(box_score_html)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_player_summary: {e}\")\n",
    "    \n",
    "    try:\n",
    "        line_chart = parse_line_chart(box_score_html)\n",
    "        if line_chart.empty:\n",
    "            logging.info(\"Line chart is empty. Skipping the insert for this game.\")\n",
    "        else:\n",
    "            logging.info(f\"Line chart DataFrame structure: {line_chart.dtypes}\")\n",
    "\n",
    "        # Insert into database (make sure this part works as expected)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in parse_line_chart: {e}\")\n",
    "\n",
    "\n",
    "    \n",
    "    try:\n",
    "        linescore = parse_linescore(box_score_html)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_linescore: {e}\")\n",
    "    \n",
    "    try:\n",
    "        game_details = parse_game_details(box_score_html)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in parse_game_details: {e}\")\n",
    "    \n",
    "    # Combine DataFrames into a list\n",
    "    all_dfs = [game_details, scoring_summary, penalty_summary, goalie_stats, player_stats, line_chart, linescore]\n",
    "    \n",
    "    return all_dfs\n",
    "\n",
    "\n",
    "def rename_duplicate_columns(df):\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in df.columns[df.columns.duplicated()].unique(): \n",
    "        cols[df.columns.get_loc(dup)] = [f\"{dup}_{i}\" if i != 0 else dup for i in range(df.columns.get_loc(dup).sum())]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to save DataFrames to SQLite database\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def save_to_sqlite_db(df_list, table_names, db_name='Game Stats 2022-2023'):\n",
    "    engine = create_engine(f'sqlite:///{db_name}')\n",
    "    \n",
    "    for df, table in zip(df_list, table_names):\n",
    "        # Rename duplicate columns\n",
    "        df = rename_duplicate_columns(df)\n",
    "        df.to_sql(table, engine, if_exists='append', index=False)\n",
    "\n",
    "# Function to fetch and save data\n",
    "def fetch_and_save_data_to_db(box_score_url, advanced_metrics_url, db_name='FRIDAY_NEW2022-2023 College Hockey Data.db'):\n",
    "    # Fetch HTML content for box score\n",
    "    box_score_response = requests.get(box_score_url)\n",
    "    box_score_html = box_score_response.text\n",
    "    \n",
    "    # Fetch HTML content for advanced metrics\n",
    "    advanced_metrics_response = requests.get(advanced_metrics_url)\n",
    "    advanced_metrics_html = advanced_metrics_response.text\n",
    "    \n",
    "    # Parse box score into list of DataFrames\n",
    "    box_score_dfs = parse_box_score(box_score_html)\n",
    "    \n",
    "    # Parse advanced metrics into list of DataFrames\n",
    "    advanced_metrics_dfs = parse_advanced_metrics_tables(advanced_metrics_html)\n",
    "    \n",
    "    # Combine all DataFrames into a list\n",
    "    all_dfs = box_score_dfs + advanced_metrics_dfs\n",
    "    \n",
    "    # Define table names for these DataFrames\n",
    "    table_names = ['game_details', 'scoring_summary', 'penalty_summary', \n",
    "                    'goalie_stats', 'player_stats', 'line_chart', 'linescore',\n",
    "                    'advanced_metrics_team1', 'advanced_metrics_team2']\n",
    "    # for df in all_dfs:\n",
    "    #     # print(type(df))\n",
    "    #     print(df.columns.tolist())\n",
    "\n",
    "    # Create a game_id for the game and apply it to all dataframes\n",
    "    \n",
    "    # Game ID YYYMMDD-HomeTeam-AwayTeam\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    for df in all_dfs:\n",
    "        df['Game_ID'] = game_id\n",
    "    \n",
    "    # Save DataFrames to SQLite database\n",
    "    save_to_sqlite_db(all_dfs, table_names, db_name)\n",
    "    \n",
    "    return all_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping games:   0%|          | 0/1169 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping games: 100%|██████████| 1169/1169 [37:09<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "## Run the scrape to get game data using the functions above and infor from games_df\n",
    "\n",
    "## Change the variable name to reuse the old code\n",
    "sampled_games = games_df\n",
    "\n",
    "# Initialize counters & logs\n",
    "error_count = 0\n",
    "error_games = []\n",
    "\n",
    "# Loop over sampled games and fetch data\n",
    "for idx, row in tqdm(sampled_games.iterrows(), total=sampled_games.shape[0], desc=\"Scraping games\"):\n",
    "    retries = 3  # Number of retries\n",
    "    success = False\n",
    "    \n",
    "    while retries > 0 and not success:\n",
    "        try:\n",
    "            box_score_url = base_url + row['Box_Link']\n",
    "            advanced_metrics_url = base_url + row['Metrics_Link']\n",
    "\n",
    "            # create a unique game id\n",
    "            game_id = str(row['Date']) + '-' + str(row['Home_Team']) + '-' + str(row['Away_Team'])\n",
    "            \n",
    "            logging.info(f\"Fetching data for game: {row['Home_Team']} vs {row['Away_Team']}\")\n",
    "            \n",
    "            # Your existing function to fetch and save data\n",
    "            all_dfs = fetch_and_save_data_to_db(box_score_url, advanced_metrics_url)\n",
    "            \n",
    "            # If reached here, the fetching was successful\n",
    "            success = True\n",
    "            \n",
    "            # Adaptive rate limiting\n",
    "            \n",
    "            \n",
    "        except requests.exceptions.RequestException as e:  # Network-related errors\n",
    "            logging.error(f\"Network error for game: {row['Home_Team']} vs {row['Away_Team']}. Error: {e}\")\n",
    "            retries -= 1\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "        \n",
    "        except Exception as e:  # Other exceptions\n",
    "            logging.error(f\"An error occurred for game: {row['Game_ID']} - {row['Home_Team']} vs {row['Away_Team']}. Error: {e}\")\n",
    "            error_count += 1\n",
    "            error_games.append((row['Home_Team'], row['Away_Team']))\n",
    "            break  # Break the while loop; no retries for these types of errors\n",
    "\n",
    "\n",
    "# Close the logging file\n",
    "logging.shutdown()\n",
    "\n",
    "# Close the database connection\n",
    "# conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games: 1169\n",
      "Total errors: 110\n",
      "Error games: ('Western Ontario', 'Providence')\n",
      "Error games: ('Lake Superior', 'Michigan Tech')\n",
      "Error games: ('Colgate', 'Rensselaer')\n",
      "Error games: ('Toronto', 'Quinnipiac')\n",
      "Error games: ('Prince Ed. Isl.', 'Maine')\n",
      "Error games: ('Sacred Heart', 'Massachusetts')\n",
      "Error games: ('US Under-18', 'Michigan State')\n",
      "Error games: ('Windsor', 'Michigan')\n",
      "Error games: ('Ottawa', 'Clarkson')\n",
      "Error games: ('Manitoba', 'North Dakota')\n",
      "Error games: ('Minnesota State', 'Omaha')\n",
      "Error games: ('Boston College', 'Holy Cross')\n",
      "Error games: ('UNLV', 'Denver')\n",
      "Error games: ('Colorado College', 'Air Force')\n",
      "Error games: ('Providence', 'Quinnipiac')\n",
      "Error games: ('Lakehead', 'Wisconsin')\n",
      "Error games: ('Nipissing', 'Lake Superior')\n",
      "Error games: ('Toronto', 'Rensselaer')\n",
      "Error games: ('Western Ontario', 'Sacred Heart')\n",
      "Error games: ('Guelph', 'Colgate')\n",
      "Error games: ('US Under-18', 'Notre Dame')\n",
      "Error games: ('Lakehead', 'Michigan Tech')\n",
      "Error games: ('Waterloo', 'Boston University')\n",
      "Error games: ('US Under-18', 'St. Thomas')\n",
      "Error games: ('UNLV', 'Alaska-Anchorage')\n",
      "Error games: ('Ottawa', 'Cornell')\n",
      "Error games: ('UNLV', 'Alaska-Anchorage')\n",
      "Error games: ('Guelph', 'Cornell')\n",
      "Error games: ('US Under-18', 'Rensselaer')\n",
      "Error games: ('Guelph', 'Dartmouth')\n",
      "Error games: ('Bemidji State', 'Michigan Tech')\n",
      "Error games: ('Guelph', 'Harvard')\n",
      "Error games: ('US Under-18', 'Army')\n",
      "Error games: ('Mercyhurst', 'Niagara')\n",
      "Error games: ('Providence', 'New Hampshire')\n",
      "Error games: ('Northeastern', 'Maine')\n",
      "Error games: ('Michigan State', 'Notre Dame')\n",
      "Error games: ('Ferris State', 'Bemidji State')\n",
      "Error games: ('Holy Cross', 'Canisius')\n",
      "Error games: ('Sacred Heart', 'Mercyhurst')\n",
      "Error games: ('Brown', 'Dartmouth')\n",
      "Error games: ('North Dakota', 'Omaha')\n",
      "Error games: ('Boston College', 'Northeastern')\n",
      "Error games: ('Connecticut', 'Providence')\n",
      "Error games: ('Colorado College', 'Miami')\n",
      "Error games: ('Lake Superior', 'Michigan Tech')\n",
      "Error games: ('Mercyhurst', 'Ferris State')\n",
      "Error games: ('Providence', 'Connecticut')\n",
      "Error games: ('Alaska-Anchorage', 'UNLV')\n",
      "Error games: ('Liberty', 'Alaska-Anchorage')\n",
      "Error games: ('US Under-18', 'Niagara')\n",
      "Error games: ('Air Force', \"American Int'l\")\n",
      "Error games: ('US Under-18', 'RIT')\n",
      "Error games: ('Assumption', 'Long Island')\n",
      "Error games: ('Army', 'Canisius')\n",
      "Error games: ('US Under-18', 'Boston University')\n",
      "Error games: ('Minnesota State', 'Michigan Tech')\n",
      "Error games: ('US Under-18', 'Yale')\n",
      "Error games: ('Providence', 'Boston College')\n",
      "Error games: ('Simon Fraser', 'Alaska-Anchorage')\n",
      "Error games: ('Boston College', 'Providence')\n",
      "Error games: ('Mass.-Lowell', 'Massachusetts')\n",
      "Error games: ('St. Thomas', 'Bemidji State')\n",
      "Error games: ('Simon Fraser', 'Alaska-Anchorage')\n",
      "Error games: ('Brown', 'Clarkson')\n",
      "Error games: ('North Dakota', 'Western Michigan')\n",
      "Error games: ('Yale', 'Clarkson')\n",
      "Error games: ('Franklin Pierce', 'Long Island')\n",
      "Error games: ('Franklin Pierce', 'Long Island')\n",
      "Error games: ('US Under-18', 'Minnesota')\n",
      "Error games: ('St. Thomas', 'Minnesota-Duluth')\n",
      "Error games: ('US Under-18', 'North Dakota')\n",
      "Error games: ('Minnesota', 'Bemidji State')\n",
      "Error games: ('Toronto', 'Niagara')\n",
      "Error games: ('US Under-18', 'Michigan')\n",
      "Error games: ('Mercyhurst', 'US Under-18')\n",
      "Error games: ('Mercyhurst', 'RIT')\n",
      "Error games: ('Minnesota', 'Notre Dame')\n",
      "Error games: ('US Under-18', 'Wisconsin')\n",
      "Error games: ('Penn State', 'Michigan State')\n",
      "Error games: ('Holy Cross', 'Sacred Heart')\n",
      "Error games: ('Vermont', 'Boston College')\n",
      "Error games: ('Bowling Green', 'St. Thomas')\n",
      "Error games: ('Canisius', 'Bentley')\n",
      "Error games: ('Michigan Tech', 'Ferris State')\n",
      "Error games: ('US Under-18', 'Bowling Green')\n",
      "Error games: ('Boston College', 'Mass.-Lowell')\n",
      "Error games: ('Miami', 'St. Cloud State')\n",
      "Error games: ('Army', 'Niagara')\n",
      "Error games: ('Ferris State', 'Bowling Green')\n",
      "Error games: ('Miami', 'St. Cloud State')\n",
      "Error games: (\"American Int'l\", 'Bentley')\n",
      "Error games: ('Vermont', 'Massachusetts')\n",
      "Error games: ('Northeastern', 'Providence')\n",
      "Error games: ('Cornell', 'Colgate')\n",
      "Error games: ('Vermont', 'Massachusetts')\n",
      "Error games: ('Ohio State', 'Notre Dame')\n",
      "Error games: ('Colorado College', 'Omaha')\n",
      "Error games: ('Maine', 'Mass.-Lowell')\n",
      "Error games: ('Michigan', 'Ohio State')\n",
      "Error games: ('Maine', 'New Hampshire')\n",
      "Error games: ('St. Cloud State', 'North Dakota')\n",
      "Error games: ('Clarkson', 'Colgate')\n",
      "Error games: ('US Under-18', 'Lindenwood')\n",
      "Error games: ('Sacred Heart', \"American Int'l\")\n",
      "Error games: ('Notre Dame', 'Michigan')\n",
      "Error games: ('Colgate', 'Brown')\n",
      "Error games: ('Boston College', 'Merrimack')\n",
      "Error games: ('Mass.-Lowell', 'Merrimack')\n",
      "Error games: ('Colgate', 'Quinnipiac')\n"
     ]
    }
   ],
   "source": [
    "## Print a summary of the errors\n",
    "print(f\"Total games: {sampled_games.shape[0]}\")\n",
    "print(f\"Total errors: {error_count}\")\n",
    "for game in error_games:\n",
    "    print(f\"Error games: {game}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"2022-10-01-American Int'l-Alaska\", 11),\n",
       " ('2022-10-01-Arizona State-Minnesota-Duluth', 8),\n",
       " ('2022-10-01-Bentley-Boston University', 20),\n",
       " ('2022-10-01-Bowling Green-Northern Michigan', 9),\n",
       " ('2022-10-01-Connecticut-Vermont', 9)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database to explore the data\n",
    "\n",
    "db_path = 'FRIDAY_NEW2022-2023 College Hockey Data.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Query to count the number of penalties for each game\n",
    "query_count_penalties = '''\n",
    "SELECT Game_ID, COUNT(*) as Num_Penalties\n",
    "FROM penalty_summary\n",
    "GROUP BY Game_ID;\n",
    "'''\n",
    "\n",
    "# Execute the query and fetch the results\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query_count_penalties)\n",
    "penalty_count_by_game = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Preview the first few rows of the result\n",
    "penalty_count_by_game[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referees who call the most penalties per game:\n",
    "\n",
    "* Andrew Bruggeman: Avg 12.5 penalties/game over 8 games\n",
    "* Michael Forys: Avg 12.2 penalties/game over 6 games\n",
    "* Ryan Hersey: Avg 12.0 penalties/game over 10 games\n",
    "* Jared Waitt: Avg 11.6 penalties/game over 7 games\n",
    "* Sterling Egan: Avg 11.6 penalties/game over 18 games\n",
    "\n",
    "\n",
    "## Referees who call the least penalties per game:\n",
    "* Timm Walsh: Avg 5.4 penalties/game over 10 games\n",
    "* Ryan Sweeney: Avg 6.1 penalties/game over 17 games\n",
    "* Sean Fernandez: Avg 6.3 penalties/game over 9 games\n",
    "* Joe Carusone: Avg 6.5 penalties/game over 6 games\n",
    "* Walker Holton: Avg 6.5 penalties/game over 8 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'Referee': 'Sterling Egan',\n",
       "   'Num_Games': 18,\n",
       "   'Total_Penalties': 208,\n",
       "   'Avg_Penalties_Per_Game': 11.555555555555555},\n",
       "  {'Referee': 'Chris Leavitt',\n",
       "   'Num_Games': 15,\n",
       "   'Total_Penalties': 168,\n",
       "   'Avg_Penalties_Per_Game': 11.2},\n",
       "  {'Referee': 'Mark Dungan',\n",
       "   'Num_Games': 18,\n",
       "   'Total_Penalties': 192,\n",
       "   'Avg_Penalties_Per_Game': 10.666666666666666},\n",
       "  {'Referee': 'Chris Pitoscia',\n",
       "   'Num_Games': 14,\n",
       "   'Total_Penalties': 149,\n",
       "   'Avg_Penalties_Per_Game': 10.642857142857142},\n",
       "  {'Referee': 'Shane Paskey',\n",
       "   'Num_Games': 12,\n",
       "   'Total_Penalties': 126,\n",
       "   'Avg_Penalties_Per_Game': 10.5}],\n",
       " [{'Referee': 'Ryan Sweeney',\n",
       "   'Num_Games': 17,\n",
       "   'Total_Penalties': 103,\n",
       "   'Avg_Penalties_Per_Game': 6.0588235294117645},\n",
       "  {'Referee': 'Terrence Murphy',\n",
       "   'Num_Games': 16,\n",
       "   'Total_Penalties': 109,\n",
       "   'Avg_Penalties_Per_Game': 6.8125},\n",
       "  {'Referee': 'Brad LeBlanc',\n",
       "   'Num_Games': 13,\n",
       "   'Total_Penalties': 90,\n",
       "   'Avg_Penalties_Per_Game': 6.923076923076923},\n",
       "  {'Referee': 'Brendan Blanchard',\n",
       "   'Num_Games': 15,\n",
       "   'Total_Penalties': 105,\n",
       "   'Avg_Penalties_Per_Game': 7.0},\n",
       "  {'Referee': 'Bobby Esposito',\n",
       "   'Num_Games': 18,\n",
       "   'Total_Penalties': 127,\n",
       "   'Avg_Penalties_Per_Game': 7.055555555555555}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database again\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Query to aggregate the number of penalties for each referee\n",
    "query_aggregate_referees = '''\n",
    "WITH PenaltyCounts AS (\n",
    "    SELECT Game_ID, COUNT(*) as Num_Penalties\n",
    "    FROM penalty_summary\n",
    "    GROUP BY Game_ID\n",
    ")\n",
    "SELECT \n",
    "    Ref1 as Referee, \n",
    "    COUNT(*) as Num_Games_Ref1, \n",
    "    SUM(Num_Penalties) as Total_Penalties_Ref1,\n",
    "    AVG(Num_Penalties * 1.0) as Avg_Penalties_Per_Game_Ref1\n",
    "FROM game_details\n",
    "JOIN PenaltyCounts ON game_details.Game_ID = PenaltyCounts.Game_ID\n",
    "GROUP BY Ref1\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    Ref2 as Referee, \n",
    "    COUNT(*) as Num_Games_Ref2, \n",
    "    SUM(Num_Penalties) as Total_Penalties_Ref2,\n",
    "    AVG(Num_Penalties * 1.0) as Avg_Penalties_Per_Game_Ref2\n",
    "FROM game_details\n",
    "JOIN PenaltyCounts ON game_details.Game_ID = PenaltyCounts.Game_ID\n",
    "GROUP BY Ref2;\n",
    "'''\n",
    "\n",
    "# Execute the query and fetch the results\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query_aggregate_referees)\n",
    "referee_penalty_data = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Convert the result into a more readable format (a list of dictionaries)\n",
    "referee_penalty_data_dict = [\n",
    "    {\n",
    "        \"Referee\": row[0],\n",
    "        \"Num_Games\": row[1],\n",
    "        \"Total_Penalties\": row[2],\n",
    "        \"Avg_Penalties_Per_Game\": row[3]\n",
    "    }\n",
    "    for row in referee_penalty_data\n",
    "]\n",
    "\n",
    "# Preview the first few rows of the result\n",
    "referee_penalty_data_dict[:5]\n",
    "\n",
    "# Filter out records with empty \"Referee\" field and referees with 5 or fewer games\n",
    "filtered_referee_data = [\n",
    "    row for row in referee_penalty_data_dict \n",
    "    if row['Referee'] and row['Num_Games'] > 10\n",
    "]\n",
    "\n",
    "# Sort the data by average penalties per game\n",
    "sorted_by_most_penalties = sorted(\n",
    "    filtered_referee_data, \n",
    "    key=lambda x: x['Avg_Penalties_Per_Game'], \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "sorted_by_least_penalties = sorted(\n",
    "    filtered_referee_data, \n",
    "    key=lambda x: x['Avg_Penalties_Per_Game']\n",
    ")\n",
    "\n",
    "# Preview the top and bottom 5 referees by average penalties per game\n",
    "sorted_by_most_penalties[:5], sorted_by_least_penalties[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Stats on Major Penalties:\n",
    "### Average Rate of Major Penalties per Game: ~0.91\n",
    "Standard Deviation: ~0.71\n",
    "Statistically Significant Referees:\n",
    "\n",
    "Three referees call major penalties at a statistically significant different rate compared to the others (using a Z-score threshold of 1.96 for a 95% confidence level):\n",
    "\n",
    "### Brett Sheva:\n",
    "\n",
    "7 games\n",
    "24 major penalties\n",
    "Rate: ~3.43 major penalties/game\n",
    "Z-Score: 3.55\n",
    "\n",
    "### Rick Nelson:\n",
    "\n",
    "6 games\n",
    "18 major penalties\n",
    "Rate: 3.0 major penalties/game\n",
    "Z-Score: 2.95\n",
    "### Anthony Dapuzzo:\n",
    "\n",
    "8 games\n",
    "22 major penalties\n",
    "Rate: 2.75 major penalties/game\n",
    "Z-Score: 2.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9061463756456244,\n",
       " 0.7098036528113367,\n",
       " [{'Referee': 'Brett Sheva',\n",
       "   'Num_Games': 7,\n",
       "   'Num_Major_Penalties': 24,\n",
       "   'Rate_Major_Penalties': 3.4285714285714284,\n",
       "   'Z_Score': 3.5536940996783732},\n",
       "  {'Referee': 'Rick Nelson',\n",
       "   'Num_Games': 6,\n",
       "   'Num_Major_Penalties': 18,\n",
       "   'Rate_Major_Penalties': 3.0,\n",
       "   'Z_Score': 2.9499053943456026},\n",
       "  {'Referee': 'Anthony Dapuzzo',\n",
       "   'Num_Games': 8,\n",
       "   'Num_Major_Penalties': 22,\n",
       "   'Rate_Major_Penalties': 2.75,\n",
       "   'Z_Score': 2.5976953162348195}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Connect to the database again\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Query to find the number of major penalties called by each referee\n",
    "query_major_penalties = '''\n",
    "WITH MajorPenalties AS (\n",
    "    SELECT Game_ID\n",
    "    FROM penalty_summary\n",
    "    WHERE Pen_Length >= 5\n",
    "    GROUP BY Game_ID\n",
    "),\n",
    "RefereeGames AS (\n",
    "    SELECT Ref1 as Referee, COUNT(*) as Num_Games\n",
    "    FROM game_details\n",
    "    GROUP BY Ref1\n",
    "    HAVING COUNT(*) >= 5\n",
    "    UNION ALL\n",
    "    SELECT Ref2 as Referee, COUNT(*) as Num_Games\n",
    "    FROM game_details\n",
    "    GROUP BY Ref2\n",
    "    HAVING COUNT(*) >= 5\n",
    ")\n",
    "SELECT \n",
    "    Referee, \n",
    "    Num_Games,\n",
    "    COUNT(MajorPenalties.Game_ID) as Num_Major_Penalties,\n",
    "    COUNT(MajorPenalties.Game_ID) * 1.0 / Num_Games as Rate_Major_Penalties\n",
    "FROM RefereeGames\n",
    "LEFT JOIN game_details ON RefereeGames.Referee = game_details.Ref1 OR RefereeGames.Referee = game_details.Ref2\n",
    "LEFT JOIN MajorPenalties ON MajorPenalties.Game_ID = game_details.Game_ID\n",
    "WHERE Referee != ''\n",
    "GROUP BY Referee\n",
    "ORDER BY Rate_Major_Penalties DESC;\n",
    "'''\n",
    "\n",
    "# Execute the query and fetch the results\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query_major_penalties)\n",
    "major_penalty_data = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Convert the result into a more readable format (a list of dictionaries)\n",
    "major_penalty_data_dict = [\n",
    "    {\n",
    "        \"Referee\": row[0],\n",
    "        \"Num_Games\": row[1],\n",
    "        \"Num_Major_Penalties\": row[2],\n",
    "        \"Rate_Major_Penalties\": row[3]\n",
    "    }\n",
    "    for row in major_penalty_data\n",
    "]\n",
    "\n",
    "# Extract the rates of major penalties for statistical analysis\n",
    "rates_major_penalties = [row['Rate_Major_Penalties'] for row in major_penalty_data_dict]\n",
    "\n",
    "# Calculate the mean and standard deviation of the rate of major penalties\n",
    "mean_rate = np.mean(rates_major_penalties)\n",
    "std_dev_rate = np.std(rates_major_penalties)\n",
    "\n",
    "# Calculate the Z-scores for each referee\n",
    "z_scores = stats.zscore(rates_major_penalties)\n",
    "\n",
    "# Add Z-scores to the data dictionary\n",
    "for i, row in enumerate(major_penalty_data_dict):\n",
    "    row['Z_Score'] = z_scores[i]\n",
    "\n",
    "# Filter out referees with Z-scores indicating they are statistically significantly different\n",
    "significant_refs = [row for row in major_penalty_data_dict if np.abs(row['Z_Score']) > 1.96]\n",
    "\n",
    "mean_rate, std_dev_rate, significant_refs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Penalized Teams (Overall):\n",
    "RIT: 243 penalties\n",
    "Michigan: 223 penalties\n",
    "HC: 208 penalties\n",
    "ASU: 196 penalties\n",
    "Denver: 192 penalties\n",
    "\n",
    "## Least Penalized Teams (Overall):\n",
    "Stonehill: 25 penalties\n",
    "UMass: 111 penalties\n",
    "BSU: 114 penalties\n",
    "UNH: 115 penalties\n",
    "Harvard: 117 penalties\n",
    "\n",
    "## Most Penalized Teams (Major Penalties):\n",
    "RIT: 14 major penalties\n",
    "Michigan: 13 major penalties\n",
    "Lindenwood: 13 major penalties\n",
    "Canisius: 13 major penalties\n",
    "Wisconsin: 12 major penalties\n",
    "\n",
    "## Least Penalized Teams (Major Penalties):\n",
    "Army: 2 major penalties\n",
    "QU: 2 major penalties\n",
    "Stonehill: 2 major penalties\n",
    "UVM: 2 major penalties\n",
    "MTU: 3 major penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'Team': 'RIT', 'Num_Penalties': 243},\n",
       "  {'Team': 'Michigan', 'Num_Penalties': 223},\n",
       "  {'Team': 'HC', 'Num_Penalties': 208},\n",
       "  {'Team': 'ASU', 'Num_Penalties': 196},\n",
       "  {'Team': 'Denver', 'Num_Penalties': 192}],\n",
       " [{'Team': 'Harvard', 'Num_Penalties': 117},\n",
       "  {'Team': 'UNH', 'Num_Penalties': 115},\n",
       "  {'Team': 'BSU', 'Num_Penalties': 114},\n",
       "  {'Team': 'UMass', 'Num_Penalties': 111},\n",
       "  {'Team': 'Stonehill', 'Num_Penalties': 25}],\n",
       " [{'Team': 'RIT', 'Num_Major_Penalties': 14},\n",
       "  {'Team': 'Michigan', 'Num_Major_Penalties': 13},\n",
       "  {'Team': 'Lindenwood', 'Num_Major_Penalties': 13},\n",
       "  {'Team': 'Canisius', 'Num_Major_Penalties': 13},\n",
       "  {'Team': 'Wisconsin', 'Num_Major_Penalties': 12}],\n",
       " [{'Team': 'MTU', 'Num_Major_Penalties': 3},\n",
       "  {'Team': 'UVM', 'Num_Major_Penalties': 2},\n",
       "  {'Team': 'Stonehill', 'Num_Major_Penalties': 2},\n",
       "  {'Team': 'QU', 'Num_Major_Penalties': 2},\n",
       "  {'Team': 'Army', 'Num_Major_Penalties': 2}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database again\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Query to find the most and least penalized teams based on overall penalties\n",
    "query_overall_penalties = '''\n",
    "SELECT Team, COUNT(*) as Num_Penalties\n",
    "FROM penalty_summary\n",
    "GROUP BY Team\n",
    "ORDER BY Num_Penalties DESC;\n",
    "'''\n",
    "\n",
    "# Query to find the most and least penalized teams based on major penalties\n",
    "query_major_penalties = '''\n",
    "SELECT Team, COUNT(*) as Num_Major_Penalties\n",
    "FROM penalty_summary\n",
    "WHERE Pen_Length >= 5\n",
    "GROUP BY Team\n",
    "ORDER BY Num_Major_Penalties DESC;\n",
    "'''\n",
    "\n",
    "# Execute the queries and fetch the results\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query_overall_penalties)\n",
    "overall_penalty_data = cursor.fetchall()\n",
    "\n",
    "cursor.execute(query_major_penalties)\n",
    "major_penalty_data = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Convert the results into more readable formats (lists of dictionaries)\n",
    "overall_penalty_data_dict = [{\"Team\": row[0], \"Num_Penalties\": row[1]} for row in overall_penalty_data]\n",
    "major_penalty_data_dict = [{\"Team\": row[0], \"Num_Major_Penalties\": row[1]} for row in major_penalty_data]\n",
    "\n",
    "# Preview the top and bottom 5 teams for overall and major penalties\n",
    "overall_penalty_data_dict[:5], overall_penalty_data_dict[-5:], major_penalty_data_dict[:5], major_penalty_data_dict[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3285610691.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    stop asgfadsjgas;\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop asgfadsjgas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM advanced_metrics_team1;': no such table: advanced_metrics_team1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\envs\\data_viz\\lib\\site-packages\\pandas\\io\\sql.py:2264\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2264\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(sql, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   2265\u001b[0m     \u001b[39mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: advanced_metrics_team1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\college_hockey\\workbook\\NEW_FRIDAY_TEMP_season_scrape.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/NEW_FRIDAY_TEMP_season_scrape.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m query_team2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSELECT * FROM advanced_metrics_team2;\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/NEW_FRIDAY_TEMP_season_scrape.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Fetch data into DataFrames\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/NEW_FRIDAY_TEMP_season_scrape.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sample_data_team1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_query(query_team1, conn_new)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/NEW_FRIDAY_TEMP_season_scrape.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m sample_data_team2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_sql_query(query_team2, conn_new)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/NEW_FRIDAY_TEMP_season_scrape.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Add a column to distinguish between Team1 and Team2\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\envs\\data_viz\\lib\\site-packages\\pandas\\io\\sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39massert\u001b[39;00m dtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default\n\u001b[0;32m    485\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[0;32m    487\u001b[0m         sql,\n\u001b[0;32m    488\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    489\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    490\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[0;32m    491\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    492\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    493\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    494\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    495\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\envs\\data_viz\\lib\\site-packages\\pandas\\io\\sql.py:2328\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[0;32m   2318\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2319\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2326\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2328\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[0;32m   2329\u001b[0m     columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[0;32m   2331\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\envs\\data_viz\\lib\\site-packages\\pandas\\io\\sql.py:2276\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2273\u001b[0m     \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39minner_exc\u001b[39;00m\n\u001b[0;32m   2275\u001b[0m ex \u001b[39m=\u001b[39m DatabaseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution failed on sql \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msql\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2276\u001b[0m \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM advanced_metrics_team1;': no such table: advanced_metrics_team1"
     ]
    }
   ],
   "source": [
    "### Try to visualize advanced metrics here in the notebook\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to your SQLite database\n",
    "conn_new = sqlite3.connect('NEW_FRI_2022-23 College Hockey Data.db')\n",
    "\n",
    "# SQL queries to fetch data from the advanced_metrics tables\n",
    "query_team1 = \"SELECT * FROM advanced_metrics_team1;\"\n",
    "query_team2 = \"SELECT * FROM advanced_metrics_team2;\"\n",
    "\n",
    "# Fetch data into DataFrames\n",
    "sample_data_team1 = pd.read_sql_query(query_team1, conn_new)\n",
    "sample_data_team2 = pd.read_sql_query(query_team2, conn_new)\n",
    "\n",
    "# Add a column to distinguish between Team1 and Team2\n",
    "sample_data_team1['Team'] = 'Team1'\n",
    "sample_data_team2['Team'] = 'Team2'\n",
    "\n",
    "# if cell contains empty string replace with NaN\n",
    "sample_data_team1 = sample_data_team1.replace(r'^\\s*$', '0', regex=True)\n",
    "sample_data_team2 = sample_data_team2.replace(r'^\\s*$', '0', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine the data for easier plotting\n",
    "combined_sample_data = pd.concat([sample_data_team1, sample_data_team2])\n",
    "\n",
    "\n",
    "# Convert the data types\n",
    "for col in sample_data_team1.columns:\n",
    "    if col == 'Player':\n",
    "        continue\n",
    "    elif col == 'Faceoffs':\n",
    "        combined_sample_data[col] = combined_sample_data[col].astype('object')  # or another type that suits this column\n",
    "    elif col == 'Team':\n",
    "        combined_sample_data[col] = combined_sample_data[col].astype('object')\n",
    "    elif col == 'Game_ID':\n",
    "        combined_sample_data[col] = combined_sample_data[col].astype('object')\n",
    "    else:\n",
    "        combined_sample_data[col] = combined_sample_data[col].astype('int64')\n",
    "# Now you can proceed to plot this combined data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 954 entries, 0 to 476\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Player             954 non-null    object\n",
      " 1   TOTAL_Block        954 non-null    int64 \n",
      " 2   TOTAL_Miss         954 non-null    int64 \n",
      " 3   TOTAL_Saved        954 non-null    int64 \n",
      " 4   TOTAL_Goals        954 non-null    int64 \n",
      " 5   TOTAL_Total_Shots  954 non-null    int64 \n",
      " 6   EVEN_Block         954 non-null    int64 \n",
      " 7   EVEN_Miss          954 non-null    int64 \n",
      " 8   EVEN_Saved         954 non-null    int64 \n",
      " 9   EVEN_Goals         954 non-null    int64 \n",
      " 10  EVEN_Total_Shots   954 non-null    int64 \n",
      " 11  PP_Block           954 non-null    int64 \n",
      " 12  PP_Miss            954 non-null    int64 \n",
      " 13  PP_Saved           954 non-null    int64 \n",
      " 14  PP_Goals           954 non-null    int64 \n",
      " 15  PP_Total_Shots     954 non-null    int64 \n",
      " 16  CLOSE_Block        954 non-null    int64 \n",
      " 17  CLOSE_Miss         954 non-null    int64 \n",
      " 18  CLOSE_Saved        954 non-null    int64 \n",
      " 19  CLOSE_Goals        954 non-null    int64 \n",
      " 20  CLOSE_Total_Shots  954 non-null    int64 \n",
      " 21  D_Blocks           954 non-null    int64 \n",
      " 22  Faceoffs           954 non-null    object\n",
      " 23  Game_ID            954 non-null    object\n",
      " 24  Team               954 non-null    object\n",
      "dtypes: int64(21), object(4)\n",
      "memory usage: 193.8+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_sample_data.head(10)\n",
    "\n",
    "combined_sample_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of shots that hit the net for both TOTAL and CLOSE situations\n",
    "\n",
    "\n",
    "# Calculate the percentage of shots that hit the net for both TOTAL and CLOSE situations\n",
    "condition_total = combined_sample_data['TOTAL_Total_Shots'] != 0\n",
    "calculation_total = (combined_sample_data['TOTAL_Saved'] + combined_sample_data['TOTAL_Goals']) / combined_sample_data['TOTAL_Total_Shots'] * 100\n",
    "\n",
    "condition_close = combined_sample_data['CLOSE_Total_Shots'] != 0\n",
    "calculation_close = (combined_sample_data['CLOSE_Saved'] + combined_sample_data['CLOSE_Goals']) / combined_sample_data['CLOSE_Total_Shots'] * 100\n",
    "\n",
    "combined_sample_data['TOTAL_Percentage_On_Net'] = np.select([condition_total], [calculation_total], default=np.NaN)\n",
    "combined_sample_data['CLOSE_Percentage_On_Net'] = np.select([condition_close], [calculation_close], default=np.NaN)\n",
    "\n",
    "\n",
    "\n",
    "# Sort the data to find the top players\n",
    "top_players_total = combined_sample_data.sort_values('TOTAL_Percentage_On_Net', ascending=False).head(10)\n",
    "top_players_close = combined_sample_data.sort_values('CLOSE_Percentage_On_Net', ascending=False).head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>TOTAL_Block</th>\n",
       "      <th>TOTAL_Miss</th>\n",
       "      <th>TOTAL_Saved</th>\n",
       "      <th>TOTAL_Goals</th>\n",
       "      <th>TOTAL_Total_Shots</th>\n",
       "      <th>EVEN_Block</th>\n",
       "      <th>EVEN_Miss</th>\n",
       "      <th>EVEN_Saved</th>\n",
       "      <th>EVEN_Goals</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE_Miss</th>\n",
       "      <th>CLOSE_Saved</th>\n",
       "      <th>CLOSE_Goals</th>\n",
       "      <th>CLOSE_Total_Shots</th>\n",
       "      <th>D_Blocks</th>\n",
       "      <th>Faceoffs</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Team</th>\n",
       "      <th>TOTAL_Percentage_On_Net</th>\n",
       "      <th>CLOSE_Percentage_On_Net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tyler Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Isaiah Fox</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0-1</td>\n",
       "      <td>2023-10-08-Long Island-Holy Cross</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Cale Ashcroft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-08-Denver-Alaska</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Kieran Cebrian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2-5</td>\n",
       "      <td>2023-10-08-Denver-Alaska</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Aidan Thompson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3-6</td>\n",
       "      <td>2023-10-08-Denver-Alaska</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Shawn O'Donnell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1-0</td>\n",
       "      <td>2023-10-08-Mass.-Lowell-Alaska-Anchorage</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Jake Stella</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6-7</td>\n",
       "      <td>2023-10-08-Mass.-Lowell-Alaska-Anchorage</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Girts Silkalns</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-08-Mass.-Lowell-Alaska-Anchorage</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Kade Peterson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-08-Long Island-Holy Cross</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Adam Pitters</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9-2</td>\n",
       "      <td>2023-10-08-Long Island-Holy Cross</td>\n",
       "      <td>Team1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player  TOTAL_Block  TOTAL_Miss  TOTAL_Saved  TOTAL_Goals  \\\n",
       "0     Tyler Williams            0           0            4            1   \n",
       "420       Isaiah Fox            0           0            4            0   \n",
       "470    Cale Ashcroft            0           0            1            0   \n",
       "464   Kieran Cebrian            0           0            1            1   \n",
       "460   Aidan Thompson            0           0            3            0   \n",
       "450  Shawn O'Donnell            0           0            1            0   \n",
       "449      Jake Stella            0           0            2            0   \n",
       "441   Girts Silkalns            0           0            5            0   \n",
       "429    Kade Peterson            0           0            1            0   \n",
       "428     Adam Pitters            0           0            1            0   \n",
       "\n",
       "     TOTAL_Total_Shots  EVEN_Block  EVEN_Miss  EVEN_Saved  EVEN_Goals  ...  \\\n",
       "0                    5           0          0           4           1  ...   \n",
       "420                  4           0          0           3           0  ...   \n",
       "470                  1           0          0           1           0  ...   \n",
       "464                  2           0          0           1           0  ...   \n",
       "460                  3           0          0           2           0  ...   \n",
       "450                  1           0          0           1           0  ...   \n",
       "449                  2           0          0           0           0  ...   \n",
       "441                  5           0          0           5           0  ...   \n",
       "429                  1           0          0           0           0  ...   \n",
       "428                  1           0          0           1           0  ...   \n",
       "\n",
       "     CLOSE_Miss  CLOSE_Saved  CLOSE_Goals  CLOSE_Total_Shots  D_Blocks  \\\n",
       "0             0            1            0                  1         0   \n",
       "420           0            3            0                  3         2   \n",
       "470           0            1            0                  1         3   \n",
       "464           0            0            0                  0         1   \n",
       "460           0            2            0                  2         1   \n",
       "450           0            1            0                  1         0   \n",
       "449           0            0            0                  0         1   \n",
       "441           0            4            0                  4         0   \n",
       "429           0            0            0                  0         0   \n",
       "428           0            1            0                  1         0   \n",
       "\n",
       "     Faceoffs                                   Game_ID   Team  \\\n",
       "0           0   2023-10-07-Lake Superior-Michigan State  Team1   \n",
       "420       0-1         2023-10-08-Long Island-Holy Cross  Team1   \n",
       "470         0                  2023-10-08-Denver-Alaska  Team1   \n",
       "464       2-5                  2023-10-08-Denver-Alaska  Team1   \n",
       "460       3-6                  2023-10-08-Denver-Alaska  Team1   \n",
       "450       1-0  2023-10-08-Mass.-Lowell-Alaska-Anchorage  Team1   \n",
       "449       6-7  2023-10-08-Mass.-Lowell-Alaska-Anchorage  Team1   \n",
       "441         0  2023-10-08-Mass.-Lowell-Alaska-Anchorage  Team1   \n",
       "429         0         2023-10-08-Long Island-Holy Cross  Team1   \n",
       "428       9-2         2023-10-08-Long Island-Holy Cross  Team1   \n",
       "\n",
       "     TOTAL_Percentage_On_Net  CLOSE_Percentage_On_Net  \n",
       "0                      100.0                    100.0  \n",
       "420                    100.0                    100.0  \n",
       "470                    100.0                    100.0  \n",
       "464                    100.0                      NaN  \n",
       "460                    100.0                    100.0  \n",
       "450                    100.0                    100.0  \n",
       "449                    100.0                      NaN  \n",
       "441                    100.0                    100.0  \n",
       "429                    100.0                      NaN  \n",
       "428                    100.0                    100.0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_players_total.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
