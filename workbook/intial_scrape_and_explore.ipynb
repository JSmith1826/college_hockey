{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This workbook is used to scrape the data from the College Hockey News and explore the data## \n",
    "\n",
    "## Notes - the site's robots.txt file sets these limits for crawlers\n",
    "# Crawl-delay: 10 (seconds)\n",
    "# Request-rate: 1/5 (5 requests every minute)\n",
    "\n",
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Set the URL to scrape\n",
    "url = 'https://www.collegehockeynews.com/schedules/?season=20222023' # Link to the 2022-2023 season with all results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore page structure\n",
    "\n",
    "# Get the page with requests\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # try reading with pandas # Returns odd table structure - going to try BeautifulSoup\n",
    "# tables = pd.read_html(url)\n",
    "\n",
    "# tables[0]\n",
    "\n",
    "# # output as csv\n",
    "# tables[0].to_csv('../TEMP/2022-2023_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore page structure\n",
    "\n",
    "# Get the page with requests\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# select the table or tables\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# tables[0] # This appears to be the game results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "current_date = None\n",
    "current_conference = None\n",
    "game_notes = None\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Parse the table with BeautifulSoup\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# Loop through each row to find relevant information\n",
    "for row in rows:\n",
    "    # Check for date row\n",
    "    if row.get('class') == ['stats-section']:\n",
    "        current_date = row.find('td').text.strip()\n",
    "    # Check for conference row\n",
    "    elif row.get('class') == ['sked-header']:\n",
    "        current_conference = row.find('td').text.strip()\n",
    "    # Check for game notes\n",
    "    elif len(row.find_all('td')) == 2:\n",
    "        game_notes = row.find_all('td')[1].text.strip()\n",
    "    # Process rows with game data\n",
    "    elif row.get('valign') == 'top':\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 9:\n",
    "            home_team = cells[0].text.strip()\n",
    "            home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "            home_score = cells[1].text.strip()\n",
    "            away_team = cells[3].text.strip()\n",
    "            away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "            away_score = cells[4].text.strip()\n",
    "            ot = cells[5].text.strip()\n",
    "            box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "            metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "             # Capture Game Notes\n",
    "            game_notes_cell = cells[-1].find('small')\n",
    "            game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "            # Append data to the list\n",
    "            data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "            game_notes = None  # Reset game notes for the next row\n",
    "            \n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)\n",
    "\n",
    "# output csv in temp folder\n",
    "df.to_csv('../TEMP/2022-2023_season.csv')\n",
    "\n",
    "## EMPTY DATAFRAME\n",
    "df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(20)\n",
    "\n",
    "# game notes value counts\n",
    "# df['Game_Notes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Michigan State</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pt.</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>FOW‑L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matt Basgall</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiernan Shoudy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11‑5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel Russell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Viktor Hurtig</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karsen Dorwart</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12‑10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tanner Kelly</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Erik Middendorf</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jesse Tucker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jeremy Davidson</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>David Gucciardi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zach Dubinsky</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4‑8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dylan St. Cyr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Christian Krygier</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cole Krygier</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jagger Joshua</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nicolas Muller</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9‑13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nash Nienhuis</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Miroslav Mucha</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Michael Underwood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Justin Jallen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Michigan State  G  A  Pt.  +/-  Sh  PIM  FOW‑L\n",
       "0        Matt Basgall  0  0    0    1   2    0    NaN\n",
       "1      Tiernan Shoudy  1  0    1    1   4    0   11‑5\n",
       "2      Daniel Russell  0  0    0    0   5    2    NaN\n",
       "3       Viktor Hurtig  0  0    0    0   0    0    NaN\n",
       "4      Karsen Dorwart  0  0    0    1   0    0  12‑10\n",
       "5        Tanner Kelly  0  0    0    1   1    0    NaN\n",
       "6     Erik Middendorf  0  1    1    2   0    0    NaN\n",
       "7        Jesse Tucker  0  0    0    0   0    0    NaN\n",
       "8     Jeremy Davidson  1  1    2    3   3    0    NaN\n",
       "9     David Gucciardi  0  0    0    1   3    0    NaN\n",
       "10      Zach Dubinsky  0  0    0    0   0    0    4‑8\n",
       "11      Dylan St. Cyr  0  0    0    0   0    0    NaN\n",
       "12  Christian Krygier  0  0    0    2   2    0    NaN\n",
       "13       Cole Krygier  0  0    0    1   0    0    NaN\n",
       "14      Jagger Joshua  0  0    0    0   0    2    NaN\n",
       "15     Nicolas Muller  2  1    3    3   4    2   9‑13\n",
       "16      Nash Nienhuis  0  2    2    2   2    0    NaN\n",
       "17     Miroslav Mucha  0  1    1    1   1    0    NaN\n",
       "18  Michael Underwood  0  0    0    1   1    2    NaN\n",
       "19      Justin Jallen  0  0    0    0   0    0    NaN"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### mOVING ON TO THE BOX SCORES ####\n",
    "\n",
    "# Example box score link\n",
    "url_box = 'https://www.collegehockeynews.com/box/final/20230305/msu/ndm/'\n",
    "\n",
    "# Example metrics link from same game\n",
    "url_metrics = 'https://www.collegehockeynews.com/box/metrics.php?gd=96398'\n",
    "\n",
    "# # output the entire html into a text file for review\n",
    "# with open('../TEMP/box_score_example.txt', 'w') as file:\n",
    "#     file.write(response.text)\n",
    "\n",
    "# try to read with pandas\n",
    "tables = pd.read_html(url_box)\n",
    "\n",
    "tables[0] # score summary by period\n",
    "tables[1] # shots by period\n",
    "tables[2] # summary of penalties, power play results and faceoffs\n",
    "tables[3] # scoring summary - period by period - periods are deliniated with a row with the \"1st Period\", \"2nd Period\", etc. text - if there is no row with this text, then there is no scoring in that period\n",
    "tables[4] # penalty summary - period by period - periods are deliniated with a row with the \"1st Period\", \"2nd Period\", etc. text - if there is no row with this text, then there are no penalties in that period\n",
    "tables[5] # goalie stats\n",
    "tables[6] # visiting team stats\n",
    "tables[7] # home team stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables[7].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Michigan State</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pt.</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>FOW</th>\n",
       "      <th>FOL</th>\n",
       "      <th>FOW_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matt Basgall</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiernan Shoudy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel Russell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Viktor Hurtig</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karsen Dorwart</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Michigan State  G  A  Pt.  +/-  Sh  PIM FOW FOL   FOW_PCT\n",
       "0    Matt Basgall  0  0    0    1   2    0   0   0       NaN\n",
       "1  Tiernan Shoudy  1  0    1    1   4    0  11   5  0.687500\n",
       "2  Daniel Russell  0  0    0    0   5    2   0   0       NaN\n",
       "3   Viktor Hurtig  0  0    0    0   0    0   0   0       NaN\n",
       "4  Karsen Dorwart  0  0    0    1   0    0  12  10  0.545455"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split Face of Win loss column into two columns and calculate the faceoff percentage\n",
    "def process_fowl_data(df):\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Replace non-standard dash with standard dash\n",
    "    df_copy['FOW‑L'] = df_copy['FOW‑L'].str.replace('‑', '-', regex=False)\n",
    "    \n",
    "    # Fill NaN values\n",
    "    df_copy['FOW‑L'].fillna('0-0', inplace=True)\n",
    "    \n",
    "    # Split the 'FOW‑L' column into two columns\n",
    "    df_copy[['FOW', 'FOL']] = df_copy['FOW‑L'].str.split('-', expand=True)\n",
    "    \n",
    "    # Drop the 'FOW‑L' column\n",
    "    df_copy.drop(columns=['FOW‑L'], inplace=True)\n",
    "    \n",
    "    # Calculate the FOW percentage\n",
    "    df_copy['FOW_PCT'] = df_copy['FOW'].astype(float) / (df_copy['FOW'].astype(float) + df_copy['FOL'].astype(float))\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# Usage example\n",
    "df = tables[7]\n",
    "processed_df = process_fowl_data(df)\n",
    "\n",
    "processed_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "###################### NOT WORKING RIGHT NOW COME BACK TO LATER ##############################\n",
    "# def clean_penalty_summary(parsed_data):\n",
    "#     \"\"\"\n",
    "#     Clean and restructure the penalty_summary DataFrame.\n",
    "    \n",
    "#     Parameters:\n",
    "#         df (DataFrame): The penalty_summary DataFrame.\n",
    "        \n",
    "#     Returns:\n",
    "#         list: A list of dictionaries, each representing a penalty event.\n",
    "#     \"\"\"\n",
    "#     # Flatten multi-level columns\n",
    "#     df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "    \n",
    "#     # Drop columns that are entirely NaN\n",
    "#     df.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "#     # Initialize an empty list to store penalty events\n",
    "#     penalties = []\n",
    "    \n",
    "#     # Loop through the DataFrame to create penalty event dictionaries\n",
    "#     period = None\n",
    "#     for i, row in df.iterrows():\n",
    "#         if 'Period' in row.values:\n",
    "#             period = row.values[0].split(' ')[0]\n",
    "#         else:\n",
    "#             penalty_event = {\n",
    "#                 'Team': row['Penalties Team'],\n",
    "#                 'Period': period,\n",
    "#                 'Time': row['Penalties Time'],\n",
    "#                 'Player': row['Penalties Player'],\n",
    "#                 'Type': row['Penalties Type'],\n",
    "#                 'Length': row['Penalties Length']\n",
    "#             }\n",
    "#             penalties.append(penalty_event)\n",
    "    \n",
    "#     return penalties\n",
    "############################################\n",
    "\n",
    "def parse_box_score(url_box):\n",
    "    \"\"\"\n",
    "    Parse a college hockey game's box score and return structured data.\n",
    "    \n",
    "    Parameters:\n",
    "        url_box (str): The URL containing the box score.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data from the box score.\n",
    "    \"\"\"\n",
    "    # Read the tables using pandas\n",
    "    tables = pd.read_html(url_box)\n",
    "    \n",
    "    # Initialize an empty dictionary to store parsed data\n",
    "    parsed_data = {}\n",
    "    \n",
    "    # Parse each table and store in the dictionary\n",
    "    parsed_data['score_by_period'] = tables[0]\n",
    "    parsed_data['shots_by_period'] = tables[1]\n",
    "    parsed_data['penalties_summary'] = tables[2]\n",
    "    # Clean and restructure the penalty_summary table\n",
    "    # parsed_data['penalty_summary'] = clean_penalty_summary(tables[4]) # NOT WORKING RIGHT NOW COME BACK TO LATER\n",
    "    ########################\n",
    "    parsed_data['scoring_summary'] = tables[3]\n",
    "    parsed_data['penalty_summary'] = tables[4]\n",
    "    parsed_data['goalie_stats'] = tables[5]\n",
    "    parsed_data['visiting_team_stats'] = tables[6]\n",
    "    \n",
    "    # Transform the home_team_stats table using process_fowl_data function\n",
    "    parsed_data['home_team_stats'] = process_fowl_data(tables[7])\n",
    "    \n",
    "    return parsed_data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Note: The function assumes that the URL is valid and accessible. In a real-world scenario, you'd add error handling for network issues.\n",
    "url_box = 'https://www.collegehockeynews.com/box/final/20230303/msu/ndm/'\n",
    "parsed_data = parse_box_score(url_box)\n",
    "# print(parsed_data)  # To display the score summary by period\n",
    "\n",
    "## save parsed data into raw text filew for review\n",
    "with open('../TEMP/parsed_data.txt', 'w') as file:\n",
    "    file.write(str(parsed_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'No meta div found'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PARSE THE BOX SCORE META DATA WITH LOCATION, REFEREES, ATTENDANCE, ETC. ###\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "soup_2 = BeautifulSoup(response.text, 'html.parser')\n",
    "# Collects the game meta data from the standard box score page \n",
    "# - location, referees, attendance, etc.\n",
    "def parse_game_meta(soup):\n",
    "    \"\"\"\n",
    "    Final updated function to parse the game metadata section and return a dictionary containing the parsed information.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): The BeautifulSoup object containing the HTML content.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed game metadata.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store parsed data\n",
    "    meta_data = {}\n",
    "    \n",
    "    # Locate the 'meta' div\n",
    "    meta_div = soup.find('div', id='meta')\n",
    "    \n",
    "    if meta_div is None:\n",
    "        return {\"error\": \"No meta div found\"}\n",
    "    \n",
    "    # Parse visitor and home team information\n",
    "    team_divs = meta_div.find_all('div', class_='team')\n",
    "    \n",
    "    # Visitor team\n",
    "    visitor_div = team_divs[0]\n",
    "    meta_data['visitor_logo'] = visitor_div.find('img', class_='logo')['src']\n",
    "    meta_data['visitor_team'] = visitor_div.find('h4').text.strip().replace('\\xa0', ' ')\n",
    "    meta_data['visitor_score'] = visitor_div.find('h2').text.strip()\n",
    "    meta_data['visitor_record'] = visitor_div.find_all('h4')[1].text.strip()\n",
    "    \n",
    "    # Home team\n",
    "    home_div = team_divs[1]\n",
    "    meta_data['home_logo'] = home_div.find('img', class_='logo')['src']\n",
    "    meta_data['home_team'] = home_div.find('h4').text.strip().replace('\\xa0', ' ')\n",
    "    meta_data['home_score'] = home_div.find('h2').text.strip()\n",
    "    meta_data['home_record'] = home_div.find_all('h4')[1].text.strip()\n",
    "    \n",
    "    # Parse additional game metadata\n",
    "    game_info_div = meta_div.find_all('div')[2]\n",
    "    \n",
    "    meta_data['game_date'] = game_info_div.find('h4').text.strip()\n",
    "    \n",
    "    # Split game notes into multiple parts\n",
    "    game_notes = game_info_div.find_all('p')[0].text.strip().split('\\n')\n",
    "    \n",
    "    # If the location is specified, it's usually the last note\n",
    "    if game_notes:\n",
    "        location = game_notes[-1].split('at ')[-1].strip()\n",
    "        meta_data['location'] = location\n",
    "        game_notes[-1] = game_notes[-1].replace(f\"\\t\\tat {location}\", \"\")\n",
    "    \n",
    "    for i, note in enumerate(game_notes, 1):\n",
    "        meta_data[f'game_note{i}'] = note.strip()\n",
    "    \n",
    "    referees_info = game_info_div.find_all('p')[1].text.strip().split('\\n')\n",
    "    \n",
    "    # Split referees and assistant referees by comma and store in individual columns\n",
    "    meta_data['referee_1'], meta_data['referee_2'] = referees_info[0].split(\":\")[1].strip().split(', ')\n",
    "    meta_data['asst_referee_1'], meta_data['asst_referee_2'] = referees_info[1].split(\":\")[1].strip().split(', ')\n",
    "    \n",
    "    meta_data['attendance'] = referees_info[2].split(\":\")[1].strip()\n",
    "    \n",
    "    return meta_data\n",
    "\n",
    "# Example usage would be the same as before, just use `parse_game_meta_final_v2` instead of the previous versions.\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Note: This function assumes that the BeautifulSoup object contains the relevant 'meta' div.\n",
    "soup_2 = BeautifulSoup(response.text, 'html.parser')\n",
    "game_meta_data = parse_game_meta(soup_2)\n",
    "game_meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_parsed_data(parsed_data):\n",
    "    \"\"\"\n",
    "    Transform the parsed data into a single unified dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "        parsed_data (dict): A dictionary containing parsed tables from the box score.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the transformed data.\n",
    "    \"\"\"\n",
    "    transformed_data = {}\n",
    "    \n",
    "    # Loop through each key in the parsed_data dictionary\n",
    "    for key, table in parsed_data.items():\n",
    "        \n",
    "        # Convert the DataFrame to a list of dictionaries\n",
    "        table_list = table.to_dict(orient='records')\n",
    "        \n",
    "        # Add this list to the transformed_data dictionary\n",
    "        transformed_data[key] = table_list\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming parsed_data is the dictionary returned by your parse_box_score function\n",
    "player_dict = transform_parsed_data(parsed_data)\n",
    "\n",
    "# print(transformed_data)  # To display the score summary by period\n",
    "# player_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\college_hockey\\workbook\\intial_scrape_and_explore.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/intial_scrape_and_explore.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# df_test = pd.DataFrame(master_data)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/intial_scrape_and_explore.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/intial_scrape_and_explore.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Flatten the multi-level columns and rename them\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/intial_scrape_and_explore.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_test\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcol[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcol[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m player_dict\u001b[39m.\u001b[39;49mcolumns]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/intial_scrape_and_explore.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# rename the defensive block column and srop the face of column beacuse we already have the faceoff data in the earlier table\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/college_hockey/workbook/intial_scrape_and_explore.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_test\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mUnnamed: 21_level_0_BLKs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mDefensive_Blocks\u001b[39m\u001b[39m'\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# df_test = pd.DataFrame(master_data)\n",
    "\n",
    "# Flatten the multi-level columns and rename them\n",
    "df_test.columns = [f\"{col[0]}_{col[1]}\" for col in player_dict.columns]\n",
    "# rename the defensive block column and srop the face of column beacuse we already have the faceoff data in the earlier table\n",
    "df_test.rename(columns={'Unnamed: 21_level_0_BLKs': 'Defensive_Blocks'}, inplace=True)\n",
    "\n",
    "# df_test.columns\n",
    "# Drop the 'Unnamed: 0_level_0' column\n",
    "# df_test.drop(columns=['Unnamed: 0_level_0'], inplace=True)\n",
    "\n",
    "# index location of the last column\n",
    "# last_col = df_test.columns.get_loc('Unnamed: 21_level_0')\n",
    "\n",
    "df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_data(meta_data, transformed_data):\n",
    "    \"\"\"\n",
    "    Integrate meta_data and transformed_data into a single dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "        meta_data (dict): Dictionary containing game meta data.\n",
    "        transformed_data (dict): Dictionary containing transformed box score data.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing both meta and box score data.\n",
    "    \"\"\"\n",
    "    # Create a master dictionary and update it with meta_data and transformed_data\n",
    "    master_data = {}\n",
    "    master_data.update(meta_data)\n",
    "    master_data.update(transformed_data)\n",
    "    \n",
    "    return master_data\n",
    "\n",
    "# Example usage:\n",
    "# meta_data is the dictionary returned by your meta data scraping function\n",
    "# transformed_data is the dictionary returned by transform_parsed_data function\n",
    "master_data = integrate_data(game_meta_data, player_dict)\n",
    "\n",
    "# display(master_data)  # To display the score summary by period\n",
    "\n",
    "# # output JSON file\n",
    "# with open('../TEMP/box_score_example.json', 'w') as file:\n",
    "#     json.dump(master_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the dictionary\n",
    "master_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
