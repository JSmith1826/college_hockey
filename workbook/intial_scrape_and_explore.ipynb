{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This workbook is used to scrape the data from the College Hockey News and explore the data## \n",
    "\n",
    "## Notes - the site's robots.txt file sets these limits for crawlers\n",
    "# Crawl-delay: 10 (seconds)\n",
    "# Request-rate: 1/5 (5 requests every minute)\n",
    "\n",
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Set the URL to scrape\n",
    "url = 'https://www.collegehockeynews.com/schedules/?season=20222023' # Link to the 2022-2023 season with all results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore page structure\n",
    "\n",
    "# Get the page with requests\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # try reading with pandas # Returns odd table structure - going to try BeautifulSoup\n",
    "# tables = pd.read_html(url)\n",
    "\n",
    "# tables[0]\n",
    "\n",
    "# # output as csv\n",
    "# tables[0].to_csv('../TEMP/2022-2023_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore page structure\n",
    "\n",
    "# Get the page with requests\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# select the table or tables\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# tables[0] # This appears to be the game results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "current_date = None\n",
    "current_conference = None\n",
    "game_notes = None\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Parse the table with BeautifulSoup\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# Loop through each row to find relevant information\n",
    "for row in rows:\n",
    "    # Check for date row\n",
    "    if row.get('class') == ['stats-section']:\n",
    "        current_date = row.find('td').text.strip()\n",
    "    # Check for conference row\n",
    "    elif row.get('class') == ['sked-header']:\n",
    "        current_conference = row.find('td').text.strip()\n",
    "    # Check for game notes\n",
    "    elif len(row.find_all('td')) == 2:\n",
    "        game_notes = row.find_all('td')[1].text.strip()\n",
    "    # Process rows with game data\n",
    "    elif row.get('valign') == 'top':\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 9:\n",
    "            home_team = cells[0].text.strip()\n",
    "            home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "            home_score = cells[1].text.strip()\n",
    "            away_team = cells[3].text.strip()\n",
    "            away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "            away_score = cells[4].text.strip()\n",
    "            ot = cells[5].text.strip()\n",
    "            box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "            metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "             # Capture Game Notes\n",
    "            game_notes_cell = cells[-1].find('small')\n",
    "            game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "            # Append data to the list\n",
    "            data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "            game_notes = None  # Reset game notes for the next row\n",
    "            \n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14364\\2220396521.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2022-10-01_Ontario_Providence' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[row.Index, 'Game_ID'] = game_id\n"
     ]
    }
   ],
   "source": [
    "## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# remove day of the week from date\n",
    "# format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "### Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Function to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    game_id = f'{row.Date}_{home_team_abbr}_{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}_{row.Home_Team}_{row.Away_Team}', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1169"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)\n",
    "\n",
    "# output csv in temp folder\n",
    "df.to_csv('../TEMP/2022-2023_season.csv')\n",
    "\n",
    "len(df)\n",
    "\n",
    "## EMPTY DATAFRAME\n",
    "# df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Combine DataFrames into a list\n",
    "    all_dfs = [game_details, scoring_summary, penalty_summary, \n",
    "               goalie_stats, player_stats, line_chart, \n",
    "               linescore, home_advanced_stats, away_advanced_stats]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
