{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Code is now integrated to the end of the Scrapper Notebook\n",
    "\n",
    "## This notebook takes the database created by the raw scrape of game results, cleans up some problems with the data \n",
    "\n",
    "### Task List\n",
    "- the advanced metrics tables should have the team name added to each player's row\n",
    "    - can also probably store as a single table instead of two tables\n",
    "        - would also want to add home or away to each row along with Team Name\n",
    "        Should be able to do it with a rather simple if then and the team names in the Game_ID\n",
    "\n",
    "- Import the master rosters that are scraped and stored as CSV into the database so we can join data on age, class rank, ect \n",
    "    - I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('game_details',), ('scoring_summary',), ('penalty_summary',), ('goalie_stats',), ('player_stats',), ('line_chart',), ('linescore',), ('advanced_metrics',)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_8712\\1116062047.py:29: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2023 = pd.read_csv(folder + 'master_roster.csv')\n"
     ]
    }
   ],
   "source": [
    "## Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# db_path = '../data/2022-2023 Season Data.db' # Set FOr 2022-2023 Season\n",
    "\n",
    "# db_path = '../TEMP/2023_Season_Nov 2_Game_Stats.db' # Set For 2023-2024 Season\n",
    "\n",
    "# db_path = '../data/db/Current_Season_YTD_Game_Stats.db' # Set For 2023-2024 Season\n",
    "\n",
    "# db_path = '../TEMP/2022_Game_Stats.db' # 2022 Season\n",
    "\n",
    "# db_path = '../data/db/2021_Season_v1_Game_Stats.db' # 2021 Season\n",
    "\n",
    "db_path = '../TEMP/Most_Recent.db'\n",
    "\n",
    "db_path = '../TEMP/2023_Full_Season_Game_stats.db'\n",
    "\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Roster data\n",
    "folder = '../data/rosters/'\n",
    "\n",
    "df_2023 = pd.read_csv(folder + 'master_roster.csv')\n",
    "# Filter to just the 2023 Roster (based on Season column)\n",
    "df_2023 = df_2023[df_2023['Season'] == 2023]\n",
    "# df_2022 = pd.read_csv(folder + '2022_master_roster.csv')\n",
    "# df_2021 = pd.read_csv(folder + '2021_master_roster.csv')\n",
    "# df_2020 = pd.read_csv(folder + '2020_master_roster.csv')\n",
    "\n",
    "\n",
    "# Load the Correct Roster into the database\n",
    "roster_df = df_2023.copy()\n",
    "\n",
    "# Set the SeasonYear in the database_roster\n",
    "season_year_setting = 2023\n",
    "\n",
    "## Print tables in database\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Clean_Name</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height_Inches</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>NHL_Team</th>\n",
       "      <th>D_Round</th>\n",
       "      <th>Last Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Season</th>\n",
       "      <th>file</th>\n",
       "      <th>captain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76800</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Jack Blanchett</td>\n",
       "      <td>16</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>11-May</td>\n",
       "      <td>185</td>\n",
       "      <td>5/12/2003</td>\n",
       "      <td>Monroe, Mich.</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Powell</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>2023</td>\n",
       "      <td>roster_data_2023.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76801</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Artyom Borshyov</td>\n",
       "      <td>23</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>3-Jun</td>\n",
       "      <td>210</td>\n",
       "      <td>8/22/2000</td>\n",
       "      <td>Vitebsk, Belarus</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Youngstown</td>\n",
       "      <td>USHL</td>\n",
       "      <td>2023</td>\n",
       "      <td>roster_data_2023.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76802</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Evan Bushy</td>\n",
       "      <td>5</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1-Jun</td>\n",
       "      <td>195</td>\n",
       "      <td>3/26/2002</td>\n",
       "      <td>Mankato, Minn.</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Trail</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>2023</td>\n",
       "      <td>roster_data_2023.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76803</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Jacob Conrad</td>\n",
       "      <td>4</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>11-May</td>\n",
       "      <td>180</td>\n",
       "      <td>5/18/2002</td>\n",
       "      <td>Green Bay, Wis.</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>2023</td>\n",
       "      <td>roster_data_2023.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76804</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Jeremy Gervais</td>\n",
       "      <td>25</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>11-May</td>\n",
       "      <td>180</td>\n",
       "      <td>1/9/1999</td>\n",
       "      <td>Prince George, B.C.</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Salmon Arm</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>2023</td>\n",
       "      <td>roster_data_2023.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Team       Clean_Name  No    Position  Yr      Ht   Wt  \\\n",
       "76800  Lake Superior   Jack Blanchett  16  Defensemen  Fr  11-May  185   \n",
       "76801  Lake Superior  Artyom Borshyov  23  Defensemen  Sr   3-Jun  210   \n",
       "76802  Lake Superior       Evan Bushy   5  Defensemen  Fr   1-Jun  195   \n",
       "76803  Lake Superior     Jacob Conrad   4  Defensemen  Fr  11-May  180   \n",
       "76804  Lake Superior   Jeremy Gervais  25  Defensemen  Sr  11-May  180   \n",
       "\n",
       "             DOB             Hometown  Height_Inches  Draft_Year NHL_Team  \\\n",
       "76800  5/12/2003        Monroe, Mich.             71           0      NaN   \n",
       "76801  8/22/2000     Vitebsk, Belarus             75           0      NaN   \n",
       "76802  3/26/2002       Mankato, Minn.             73           0      NaN   \n",
       "76803  5/18/2002      Green Bay, Wis.             71           0      NaN   \n",
       "76804   1/9/1999  Prince George, B.C.             71           0      NaN   \n",
       "\n",
       "       D_Round   Last Team League  Season                  file captain  \n",
       "76800        0      Powell   BCHL    2023  roster_data_2023.csv     NaN  \n",
       "76801        0  Youngstown   USHL    2023  roster_data_2023.csv     NaN  \n",
       "76802        0       Trail   BCHL    2023  roster_data_2023.csv     NaN  \n",
       "76803        0   Fairbanks   NAHL    2023  roster_data_2023.csv     NaN  \n",
       "76804        0  Salmon Arm   BCHL    2023  roster_data_2023.csv     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roster_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of Team Primary Names to Abbreviations\n",
    "\n",
    "- Needed to Add IVY teams becuase of low amount of games. will have to do for harvard, yale, ect next week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe from SQL query\n",
    "df = pd.read_sql_query(\"SELECT * FROM advanced_metrics\", conn)\n",
    "\n",
    "# Function to count the occurrences of primary team names for unmatched abbreviations\n",
    "def count_primary_names_for_abbreviation(abbreviation):\n",
    "    filtered_rows = df[df['Team'] == abbreviation]\n",
    "    team_counts = {}\n",
    "    \n",
    "    for _, row in filtered_rows.iterrows():\n",
    "        teams = row['Game_ID'].split('-')[-2:]\n",
    "        for team in teams:\n",
    "            if team not in team_counts:\n",
    "                team_counts[team] = 0\n",
    "            team_counts[team] += 1\n",
    "            \n",
    "    return team_counts\n",
    "\n",
    "\n",
    "# Attempt to match abbreviations to primary names based on substrings and common naming conventions\n",
    "matched_dict = {}\n",
    "unmatched_abbreviations = []\n",
    "\n",
    "for abbreviation in df['Team'].unique():\n",
    "\n",
    "\n",
    "\n",
    "# Match the abbreviation to the primary team name with the highest occurrence\n",
    "\n",
    "    team_counts = count_primary_names_for_abbreviation(abbreviation)\n",
    "    # Get the team with the highest count\n",
    "    matched_team = max(team_counts, key=team_counts.get)\n",
    "    matched_dict[abbreviation] = matched_team\n",
    "\n",
    "# matched_dict\n",
    "\n",
    "# Manually fix the unmatched abbreviations - IVY League Teams with no of very few games throw a wrench in the above method\n",
    "# Brown: Brown\n",
    "# Cornell: Cornell\n",
    "\n",
    "# Make those substitutions\n",
    "matched_dict['Brown'] = 'Brown'\n",
    "matched_dict['Cornell'] = 'Cornell'\n",
    "# yale\n",
    "matched_dict['Yale'] = 'Yale'\n",
    "# princeton\n",
    "matched_dict['Princeton'] = 'Princeton'\n",
    "\n",
    "# harvard\n",
    "matched_dict['Harvard'] = 'Harvard'\n",
    "# columbia\n",
    "matched_dict['Columbia'] = 'Columbia'\n",
    "\n",
    "# dartmouth\n",
    "matched_dict['Dartmouth'] = 'Dartmouth'\n",
    "\n",
    "# penn\n",
    "matched_dict['Penn'] = 'Penn'\n",
    "\n",
    "# BC\n",
    "matched_dict['BC'] = 'Boston College'\n",
    "\n",
    "\n",
    "\n",
    "# matched_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Transform Advanced Metrics\n",
    "- add, Team and Home-Away columns, combine the two tables into a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team', 'Player', 'Bl', 'Mi', 'SV', 'G', 'TSA', 'Bl_1', 'Mi_1', 'SV_1',\n",
       "       'G_1', 'TSA_1', 'Bl_2', 'Mi_2', 'SV_2', 'G_2', 'TSA_2', 'Bl_3', 'Mi_3',\n",
       "       'SV_3', 'G_3', 'TSA_3', 'BLKs', 'FO', 'Game_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NEW Handling of Advanced Stats\n",
    "# Create dataframe from SQL query\n",
    "df = pd.read_sql_query(\"SELECT * FROM advanced_metrics\", conn)\n",
    "\n",
    "# Rename columns\n",
    "new_names = ['Team', 'Player', 'TOTAL_Block', 'TOTAL_Miss', 'TOTAL_Saved', 'TOTAL_Goals', 'TOTAL_Total_Shots',\n",
    "                'EVEN_Block', 'EVEN_Miss', 'EVEN_Saved', 'EVEN_Goals', 'EVEN_Total_Shots',\n",
    "                'PP_Block', 'PP_Miss', 'PP_Saved', 'PP_Goals', 'PP_Total_Shots',\n",
    "                'CLOSE_Block', 'CLOSE_Miss', 'CLOSE_Saved', 'CLOSE_Goals', 'CLOSE_Total_Shots',\n",
    "\n",
    "                'D_Blocks', 'Faceoffs', 'Game_ID']\n",
    "\n",
    "df.columns = new_names\n",
    "\n",
    "# # Apply the matched_dict to the Team column\n",
    "df['Team'] = df['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "## Fill all NaN values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Display the dataframe\n",
    "df.head()\n",
    "\n",
    "# Save back to the database\n",
    "df.to_sql('advanced_metrics', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE SINCE NOV 2 BECAUSE OF UPDATE TO SCRAPING BOOK\n",
    "# ### NEW Simple - advanced metrics 1 and 2 now have a team column (still contains the secondary team name so will want to address that as well\n",
    "# ## Combine the two tables into advanced_metrics_combined\n",
    "\n",
    "# # Get entire first table of advanced metrics\n",
    "# adv_met_1 = pd.read_sql_query(\"SELECT * FROM advanced_metrics_team1\", conn)\n",
    "\n",
    "\n",
    "# # Get entire second table of advanced metrics\n",
    "# adv_met_2 = pd.read_sql_query(\"SELECT * FROM advanced_metrics_team2\", conn)\n",
    "\n",
    "\n",
    "# # Combine the two tables\n",
    "# adv_met_combined = pd.concat([adv_met_1, adv_met_2], axis=0)\n",
    "\n",
    "# # Apply the matched_dict to the Team column\n",
    "# adv_met_combined['Team'] = adv_met_combined['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "\n",
    "# # Fill NaNs with 0\n",
    "# adv_met_combined = adv_met_combined.fillna(0)\n",
    "\n",
    "# # Add to database\n",
    "# adv_met_combined.to_sql('advanced_metrics_combined', conn, if_exists='replace', index=False)\n",
    "\n",
    "# # View Sample and output CSV\n",
    "# adv_met_combined.head()\n",
    "\n",
    "# # adv_met_combined.to_csv('../TEMP/NEWNEW advanced_metrics_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Home and Away Columns to game_details table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1170"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Read the game_details table into a DataFrame\n",
    "df_game_details = pd.read_sql(\"SELECT * FROM game_details\", conn)\n",
    "\n",
    "# Step 2: Create new columns for Home and Away Teams by parsing Game_ID\n",
    "df_game_details['Away_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_game_details['Home_Team'] = df_game_details['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "# Step 3: Write this updated DataFrame back to the game_details table\n",
    "df_game_details.to_sql('game_details', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up The Column Names and extra header rows in the Player Stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pt.</th>\n",
       "      <th>+/-</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>FOW</th>\n",
       "      <th>FOL</th>\n",
       "      <th>FO%</th>\n",
       "      <th>Game_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Pt.</td>\n",
       "      <td>+/-</td>\n",
       "      <td>Sh</td>\n",
       "      <td>PIM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Gavin O'Connell</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Tommi Männistö</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Maxim Štrbák</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Artyom Levshunov</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team            Player  G  A  Pt.  +/-  Sh  PIM  FOW  FOL  FO%  \\\n",
       "0  Michigan State    Michigan State  G  A  Pt.  +/-  Sh  PIM  NaN  NaN  NaN   \n",
       "1  Michigan State   Gavin O'Connell  0  1    1    2   1    0  NaN  NaN  NaN   \n",
       "2  Michigan State    Tommi Männistö  0  1    1    1   2    0  NaN  NaN  NaN   \n",
       "3  Michigan State      Maxim Štrbák  0  0    0   -1   3    0  NaN  NaN  NaN   \n",
       "4  Michigan State  Artyom Levshunov  0  0    0    2   5    2  NaN  NaN  NaN   \n",
       "\n",
       "                                   Game_ID  \n",
       "0  2023-10-07-Lake Superior-Michigan State  \n",
       "1  2023-10-07-Lake Superior-Michigan State  \n",
       "2  2023-10-07-Lake Superior-Michigan State  \n",
       "3  2023-10-07-Lake Superior-Michigan State  \n",
       "4  2023-10-07-Lake Superior-Michigan State  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "# view sample\n",
    "player_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46618"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a dictionary for column renaming\n",
    "column_renames = {\n",
    "    'Pt.': 'Pts',\n",
    "    '+/-': 'plus_minus'\n",
    "}\n",
    "\n",
    "# Rename columns based on the dictionary\n",
    "player_stats_df.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "\n",
    "# Drop rows where Team name is in the Player column\n",
    "player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "# Print the length of the dataframe\n",
    "len(player_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Change the Column names to be easy to work with\n",
    "############ 'Pt.' should be 'Pts' and '+/-' should be 'plus_minus'\n",
    "#################################\n",
    "player_stats_df = pd.read_sql_query(\"SELECT * FROM player_stats\", conn)\n",
    "\n",
    "if 'Pt.' in player_stats_df.columns:\n",
    "    player_stats_df.rename(columns={'Pt.': 'Pts'}, inplace=True)\n",
    "else:\n",
    "    print(\"Column 'Pt.' not found.\")\n",
    "\n",
    "if '+/-' in player_stats_df.columns:\n",
    "    player_stats_df.rename(columns={'+/-': 'plus_minus'}, inplace=True)\n",
    "else:\n",
    "    print(\"Column '+/-' not found.\")\n",
    "\n",
    "print(len(player_stats_df))\n",
    "\n",
    "# Drop rows if Team name is in the player column\n",
    "# If ['Team'] is the same as ['Player'] then drop that row\n",
    "player_stats_df = player_stats_df[player_stats_df['Team'] != player_stats_df['Player']]\n",
    "\n",
    "# add the dataframe back to the database\n",
    "player_stats_df.to_sql('player_stats', conn, if_exists='replace', index=False)\n",
    "\n",
    "# print(len(player_stats_df))\n",
    "#################################\n",
    "# player_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for other subsitu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>goals1</th>\n",
       "      <th>goals2</th>\n",
       "      <th>goals3</th>\n",
       "      <th>goalsT</th>\n",
       "      <th>shots1</th>\n",
       "      <th>shots2</th>\n",
       "      <th>shots3</th>\n",
       "      <th>shotsT</th>\n",
       "      <th>Pen</th>\n",
       "      <th>...</th>\n",
       "      <th>FOW</th>\n",
       "      <th>FOL</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>goals4</th>\n",
       "      <th>goals5</th>\n",
       "      <th>goals6</th>\n",
       "      <th>shots4</th>\n",
       "      <th>shots5</th>\n",
       "      <th>shots6</th>\n",
       "      <th>Game_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>69.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-07-Lake Superior-Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clarkson</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>48.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-07-Clarkson-Notre Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>51.724138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-07-Clarkson-Notre Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>44.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-07-RIT-St. Lawrence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team  goals1  goals2  goals3  goalsT  shots1  shots2  shots3  \\\n",
       "0   Lake Superior       0       2       0       2       8      11      12   \n",
       "1  Michigan State       1       2       2       5      13      16       8   \n",
       "2        Clarkson       1       0       2       3       8       6      11   \n",
       "3      Notre Dame       0       1       0       1       9       7      12   \n",
       "4             RIT       0       1       2       3       8      15       6   \n",
       "\n",
       "   shotsT  Pen  ...  FOW  FOL       FOW%  goals4  goals5  goals6  shots4  \\\n",
       "0      31    2  ...   20   45  30.769231       0       0       0       0   \n",
       "1      37    3  ...   45   20  69.230769       0       0       0       0   \n",
       "2      25    4  ...   28   30  48.275862       0       0       0       0   \n",
       "3      28    3  ...   30   28  51.724138       0       0       0       0   \n",
       "4      29    6  ...   30   38  44.117647       0       0       0       0   \n",
       "\n",
       "   shots5  shots6                                  Game_ID  \n",
       "0       0       0  2023-10-07-Lake Superior-Michigan State  \n",
       "1       0       0  2023-10-07-Lake Superior-Michigan State  \n",
       "2       0       0           2023-10-07-Clarkson-Notre Dame  \n",
       "3       0       0           2023-10-07-Clarkson-Notre Dame  \n",
       "4       0       0              2023-10-07-RIT-St. Lawrence  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "df_linescores = pd.read_sql(\"SELECT * FROM linescore\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "df_linescores['Team'] = df_linescores['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "df_linescores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Table & Scoring Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add The primary team names to the linescores table\n",
    "# Read the linescores table into a DataFrame\n",
    "\n",
    "df_penalty = pd.read_sql(\"SELECT * FROM penalty_summary\", conn)\n",
    "\n",
    "# Apply the dictionary to the Team column\n",
    "#$ Skip if not found\n",
    "\n",
    "df_penalty['Team'] = df_penalty['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "    \n",
    "\n",
    "# Apply same method to scorring_summary:\n",
    "df_scoring = pd.read_sql(\"SELECT * FROM scoring_summary\", conn)\n",
    "df_scoring['Team'] = df_scoring['Team'].apply(lambda x: matched_dict[x])\n",
    "\n",
    "# Add Home and Away Team columns to scoring_summary\n",
    "df_scoring['Away_Team'] = df_scoring['Game_ID'].apply(lambda x: x.split('-')[3])\n",
    "df_scoring['Home_Team'] = df_scoring['Game_ID'].apply(lambda x: x.split('-')[4])\n",
    "\n",
    "\n",
    "## Add each table back to database\n",
    "# Write the updated linescores DataFrame back to the linescore table\n",
    "df_linescores.to_sql('linescore', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated penalty DataFrame back to the penalty_summary table\n",
    "df_penalty.to_sql('penalty_summary', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Write the updated scoring DataFrame back to the scoring_summary table\n",
    "df_scoring.to_sql('scoring_summary', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A NEW TABLE WITH AGGRIGATED PLAYER STATS YEAR TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>Games_Played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. Hodges</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.J. Macaulay</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ Casperson</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Bohlinger</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Grounds</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clean_Player           Team  G   A  Pts  plus_minus  Sh  PIM  \\\n",
       "0      A.J. Hodges        Bentley  6   9   15          -1  57    2   \n",
       "1    A.J. Macaulay         Alaska  5  10   15           9  44   14   \n",
       "2     AJ Casperson    Long Island  0   1    1           1   7    2   \n",
       "3  Aaron Bohlinger  Massachusetts  3   5    8           1  22    4   \n",
       "4    Aaron Grounds    Long Island  1   2    3          -5  14   16   \n",
       "\n",
       "   Games_Played  \n",
       "0            29  \n",
       "1            34  \n",
       "2            12  \n",
       "3            34  \n",
       "4            11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use player_stats_df from here on, instead of running another SQL query.\n",
    "df_player_stats = player_stats_df.copy()\n",
    "\n",
    "\n",
    "# Clean up the name format in player_stats for easier matching\n",
    "# Replace the non-breaking space with a regular space\n",
    "df_player_stats['Clean_Player'] = df_player_stats['Player'].apply(lambda x: x.replace('\\xa0', ' '))\n",
    "\n",
    "# Remove rows where Player is the team name (e.g., \"Michigan State\")\n",
    "df_player_stats_cleaned = df_player_stats[df_player_stats['Player'] != df_player_stats['Team']]\n",
    "\n",
    "# Convert relevant columns to integers for correct aggregation\n",
    "cols_to_convert = ['G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM']\n",
    "for col in cols_to_convert:\n",
    "    df_player_stats_cleaned[col] = pd.to_numeric(df_player_stats_cleaned[col], errors='coerce')\n",
    "\n",
    "# Aggregate the data for year-to-date stats\n",
    "# Add a column for counting the number of games each player has played\n",
    "agg_player_stats_corrected_with_games = df_player_stats_cleaned.groupby(['Clean_Player', 'Team']).agg({\n",
    "    'G': 'sum',\n",
    "    'A': 'sum',\n",
    "    'Pts': 'sum',\n",
    "    'plus_minus': 'sum',\n",
    "    'Sh': 'sum',\n",
    "    'PIM': 'sum',\n",
    "    'Game_ID': 'count'  # Counting the number of unique Game_IDs for each player\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the Game_ID column to Games_Played\n",
    "agg_player_stats_corrected_with_games.rename(columns={'Game_ID': 'Games_Played'}, inplace=True)\n",
    "\n",
    "# Save the updated aggregated data back to the database, replacing the existing table\n",
    "agg_player_stats_corrected_with_games.to_sql('player_stats_ytd', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Verify by loading some sample data from the updated table\n",
    "sample_updated_ytd = pd.read_sql_query(\"SELECT * FROM player_stats_ytd LIMIT 5;\", conn)\n",
    "sample_updated_ytd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Roster data from the CSVs to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## SET THE ROSTER DATAFRAME TO THE CORRECT YEAR ####################\n",
    "## MATCH THE DATAFRAME NAMES\n",
    "df_master_roster = roster_df.copy()\n",
    "\n",
    "## Season Year Value\n",
    "season_year = season_year_setting\n",
    "\n",
    "# Clean up the name formats for joining\n",
    "# Master roster: Convert \"Last Name, First Name\" to \"First Name Last Name\"\n",
    "# df_master_roster['Clean_Name'] = df_master_roster['Player'].apply(lambda x: ' '.join(reversed(x.split(', '))))\n",
    "\n",
    "# Rename Player to Clean_Name\n",
    "df_master_roster.rename(columns={'Player': 'Clean_Name'}, inplace=True)\n",
    "# Rename School to Team\n",
    "df_master_roster.rename(columns={'School': 'Team'}, inplace=True)\n",
    "\n",
    "# Clean up the Team column, remove '-' and replace with ' '\n",
    "# df_master_roster['School'] = df_master_roster['Team'].apply(lambda x: x.replace('-', ' '))\n",
    "\n",
    "## If there are an period in the column names, remove them\n",
    "df_master_roster.columns = df_master_roster.columns.str.replace('.', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goalie_stats',\n",
       " 'line_chart',\n",
       " 'advanced_metrics',\n",
       " 'game_details',\n",
       " 'player_stats',\n",
       " 'linescore',\n",
       " 'penalty_summary',\n",
       " 'scoring_summary',\n",
       " 'player_stats_ytd',\n",
       " 'master_roster']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finally add the roster to the database as it's own table\n",
    "\n",
    "df_master_roster['SeasonYear'] = season_year\n",
    "\n",
    "# Save the roster data as a new table in the database\n",
    "roster_table_name = 'master_roster'\n",
    "df_master_roster.to_sql(roster_table_name, conn, if_exists='replace', index=False)\n",
    "############################################################\n",
    "\n",
    "# Verify by listing all the tables in the database again\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = conn.execute(tables_query).fetchall()\n",
    "table_names_updated = [table[0] for table in tables]\n",
    "table_names_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT *, COUNT(*) FROM advanced_metrics GROUP BY * HAVING COUNT(*) > 1;': near \"*\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:2262\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2262\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: near \"*\": syntax error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables_to_check:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Query the table\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT *, COUNT(*) FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GROUP BY * HAVING COUNT(*) > 1;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m     duplicates \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(duplicates) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate rows found in table \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:2326\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2317\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2324\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2326\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2327\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\sql.py:2274\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2273\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT *, COUNT(*) FROM advanced_metrics GROUP BY * HAVING COUNT(*) > 1;': near \"*\": syntax error"
     ]
    }
   ],
   "source": [
    "## Go through every table and make sure there are no duplicate rows\n",
    "# List of tables to check\n",
    "tables_to_check = ['advanced_metrics', 'game_details', 'linescore', 'penalty_summary', 'player_stats', 'scoring_summary']\n",
    "\n",
    "# Check for duplicates in each table\n",
    "for table in tables_to_check:\n",
    "    # Query the table\n",
    "    query = f\"SELECT *, COUNT(*) FROM {table} GROUP BY * HAVING COUNT(*) > 1;\"\n",
    "    duplicates = pd.read_sql_query(query, conn)\n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"Duplicate rows found in table '{table}':\")\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(f\"No duplicates found in table '{table}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a backup of the transformed database and proceed to adding the roster info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Output the current state of the database to a new SQLite file in the temp folder\n",
    "# # db_cleaned_path ='../TEMP/new_cleaned_db.db'\n",
    "\n",
    "# ## Save the database to a new file\n",
    "# conn_cleaned = sqlite3.connect(db_cleaned_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
