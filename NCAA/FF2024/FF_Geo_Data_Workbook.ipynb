{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_1736\\1420337596.py:14: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_time_roster_df = pd.read_csv(roster_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Champion</th>\n",
       "      <th>Runner_up</th>\n",
       "      <th>Third</th>\n",
       "      <th>Fourth</th>\n",
       "      <th>Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Dartmouth</td>\n",
       "      <td>Other semifinalists: BC and Colorado College</td>\n",
       "      <td>Other semifinalists: BC and Colorado College</td>\n",
       "      <td>Col. Springs, Colo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>Dartmouth</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Colorado College</td>\n",
       "      <td>Col. Springs, Colo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>Colorado College</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>Col. Springs, Colo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Colorado College</td>\n",
       "      <td>Col. Springs, Colo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Colorado College</td>\n",
       "      <td>Yale</td>\n",
       "      <td>St. Lawrence</td>\n",
       "      <td>Col. Springs, Colo.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year          Champion          Runner_up  \\\n",
       "0  1948          Michigan          Dartmouth   \n",
       "1  1949    Boston College          Dartmouth   \n",
       "2  1950  Colorado College  Boston University   \n",
       "3  1951          Michigan              Brown   \n",
       "4  1952          Michigan   Colorado College   \n",
       "\n",
       "                                          Third  \\\n",
       "0  Other semifinalists: BC and Colorado College   \n",
       "1                                      Michigan   \n",
       "2                                      Michigan   \n",
       "3                             Boston University   \n",
       "4                                          Yale   \n",
       "\n",
       "                                         Fourth                 Site  \n",
       "0  Other semifinalists: BC and Colorado College  Col. Springs, Colo.  \n",
       "1                              Colorado College  Col. Springs, Colo.  \n",
       "2                                Boston College  Col. Springs, Colo.  \n",
       "3                              Colorado College  Col. Springs, Colo.  \n",
       "4                                  St. Lawrence  Col. Springs, Colo.  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# All Time Roster File Path \n",
    "roster_path = os.path.join(\"..\",\"..\",\"data\",\"rosters\",\"all_time.csv\" )\n",
    "\n",
    "# FF Historical Results Table Path\n",
    "ff_path = os.path.join('frozen_four_table.csv')\n",
    "\n",
    "\n",
    "# Open as DFs\n",
    "all_time_roster_df = pd.read_csv(roster_path)\n",
    "all_time_roster_df.head()\n",
    "\n",
    "ff_df = pd.read_csv(ff_path)\n",
    "ff_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Color and Logo Info & Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Team Color Information\n",
    "            # path to table with hex codes\n",
    "team_color_path = os.path.join('..','..', 'NCAA', 'data', 'team_color_book.csv')\n",
    "team_colors = pd.read_csv(team_color_path)\n",
    "highlight_colors = team_colors\n",
    "\n",
    "# Logo Folder path\n",
    "logo_folder = '../../images/logos/'\n",
    "\n",
    "# Dictionary to map team names to their logo filenames\n",
    "logo_mapping = {\n",
    "    \n",
    "    'Michigan State': 'msu.png',\n",
    "    'Michigan Tech': 'mtu.png',\n",
    "    'Boston College': 'bc_.png',\n",
    "    'Michigan': 'mic.png',\n",
    "    'Minnesota': 'min.png',\n",
    "    \"Wisconsin\": \"wis.png\",\n",
    "    'RIT': 'rit.png',\n",
    "    'Quinnipiac': 'qui.png',\n",
    "    'Cornell': 'cor.png',\n",
    "    'Boston University': 'bu_.png',\n",
    "    'Maine': 'mne.png',\n",
    "    'Massachusetts': 'uma.png',\n",
    "    'Denver': 'den.png',\n",
    "    'North Dakota': 'ndk.png',\n",
    "    'Omaha': 'uno.png',\n",
    "    'Western Michigan': 'wmu.png'    \n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABBRIV LIBRARIES AND WHATNOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## State and Province Abbreviation library\n",
    "canada_provinces = {'Ont.':'Ontario', 'B.C.':'British Columbia', 'Alb.':'Alberta', 'Que.':'Quebec', 'Man.':'Manitoba', 'Sask.': 'Saskatchewan', 'MB':'Manitoba', 'Sask':'Saskatchewan', 'N.S.':'Nova Scotia', 'N.B.':'New Brunswick', 'NB.': 'New Brunswick', 'P.E.I.':'Prince Edward Island', 'Newf.':'Newfoundland and Labrador',\n",
    "                    'N.S.':'Nova Scotia', 'N.B.':'New Brunswick', 'NB.': 'New Brunswick', 'P.E.I.':'Prince Edward Island', 'Newf.':'Newfoundland and Labrador', 'YT.':'Yukon', 'N.W.T.':'Northwest Territories',\n",
    "                    'Nun.':'Nunavut', 'NWT.':'Northwest Territories'}\n",
    "\n",
    "us_states = {'Ala.':'Alabama', 'Alaska':'Alaska', 'Ariz.':'Arizona', 'Ark.':'Arkansas', 'Calif.':'California', 'Colo.':'Colorado', 'Conn.':'Connecticut', 'Del.':'Delaware', 'Fla.':'Florida',\n",
    "                'Ga.':'Georgia', 'Hawaii':'Hawaii', 'Idaho':'Idaho', 'Ill.':'Illinois', 'Ind.':'Indiana', 'Iowa':'Iowa', 'Kan.':'Kansas', 'Ky.':'Kentucky', 'La.':'Louisiana', 'Maine':'Maine',\n",
    "                'Md.':'Maryland', 'Mass.':'Massachusetts', 'Mich.':'Michigan', 'Minn.':'Minnesota', 'Miss.':'Mississippi', 'Mo.':'Missouri', 'Mont.':'Montana', 'Neb.':'Nebraska', 'Nev.':'Nevada',\n",
    "                'N.H.':'New Hampshire', 'N.J.':'New Jersey', 'N.M.':'New Mexico', 'N.Y.':'New York', 'N.C.':'North Carolina', 'N.D.':'North Dakota', 'Ohio':'Ohio', 'Okla.':'Oklahoma', 'Ore.':'Oregon',\n",
    "                'Pa.':'Pennsylvania', 'R.I.':'Rhode Island', 'S.C.':'South Carolina', 'S.D.':'South Dakota', 'Tenn.':'Tennessee', 'Tx':'Texas', 'Tex.':'Texas', 'Tex':'Texas', 'Utah':'Utah', 'Vt.':'Vermont', 'Va.':'Virginia',\n",
    "                'Wash.':'Washington', 'W.Va.':'West Virginia', 'Wis.':'Wisconsin', 'Wisc.':'Wisconsin', 'Wyo.':'Wyoming'}\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hometown(hometown):\n",
    "    try:\n",
    "        # Initial split by comma\n",
    "        parts = [part.strip() for part in hometown.split(',')]\n",
    "        \n",
    "        # If more than 2 parts, assume the last part is the country or state/province\n",
    "        # and combine the rest as the city name\n",
    "        if len(parts) > 2:\n",
    "            city = ', '.join(parts[:-1])\n",
    "            state_province_country = parts[-1]\n",
    "        else:\n",
    "            city, state_province_country = parts\n",
    "        \n",
    "        # Normalize state/province for known abbreviations\n",
    "        if state_province_country in us_states:\n",
    "            state_province = us_states[state_province_country]\n",
    "            country = 'USA'\n",
    "        elif state_province_country in canada_provinces:\n",
    "            state_province = canada_provinces[state_province_country]\n",
    "            country = 'Canada'\n",
    "        else:\n",
    "            # Default handling for unexpected formats or international entries\n",
    "            state_province = None\n",
    "            country = state_province_country\n",
    "        \n",
    "        return city, state_province, country\n",
    "    except Exception as e:\n",
    "        # Log error or handle unexpected formats\n",
    "        print(f\"Error processing '{hometown}': {e}\")\n",
    "        return hometown, None, None  # Fallback return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by copying the data to avoid modifying the original dataframe inadvertently\n",
    "location_df = all_time_roster_df.copy()\n",
    "\n",
    "# drop nan values\n",
    "location_df = location_df.dropna(subset=['Hometown'])\n",
    "# Apply preprocessing to each entry in the dataframe\n",
    "location_df['Processed'] = location_df['Hometown'].apply(preprocess_hometown)\n",
    "\n",
    "# Expand the processed tuples into separate columns\n",
    "location_df[['City', 'State/Province', 'Country']] = pd.DataFrame(location_df['Processed'].tolist(), index=location_df.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### REDUNDANT CODE\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# # Split the Hometown column at the comma\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mlocation_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mState_Province_Country\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m location_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Normalize state and province abbreviations and identify countries directly\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_location_data\u001b[39m(row, us_states, canada_provinces):\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\frame.py:4079\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4077\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   4078\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[1;32m-> 4079\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   4081\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\frame.py:4121\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4117\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[0;32m   4118\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[0;32m   4120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 4121\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4122\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m   4123\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:390\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "\n",
    "### REDUNDANT CODE\n",
    "# # Split the Hometown column at the comma\n",
    "location_df[['City', 'State_Province_Country']] = location_df['Processed'].str.split(', ', expand=True)\n",
    "\n",
    "# Normalize state and province abbreviations and identify countries directly\n",
    "def normalize_location_data(row, us_states, canada_provinces):\n",
    "    loc2 = row['State_Province_Country']\n",
    "    \n",
    "    # Normalize state and province abbreviations\n",
    "    if loc2 in us_states:\n",
    "        row['State/Province'] = us_states[loc2]\n",
    "        row['Country'] = 'USA'\n",
    "    elif loc2 in canada_provinces:\n",
    "        row['State/Province'] = canada_provinces[loc2]\n",
    "        row['Country'] = 'Canada'\n",
    "    else:\n",
    "        # Handle special cases and direct country assignments\n",
    "        if loc2 == 'Tx' or loc2 == 'MB' or loc2 == 'Yukon':\n",
    "            special_cases = {\n",
    "                'Tx': ('Texas', 'USA'),\n",
    "                'MB': ('Manitoba', 'Canada'),\n",
    "                'Yukon': ('Yukon', 'Canada'),\n",
    "                'AUT': (None, 'Austria')\n",
    "            }\n",
    "            row['State/Province'], row['Country'] = special_cases.get(loc2, (None, loc2))\n",
    "        elif row['Player'] == 'Tyrone Bronte':  # Specific player correction\n",
    "            row['Country'] = 'Australia'\n",
    "        else:\n",
    "            row['State/Province'] = None\n",
    "            row['Country'] = loc2  # Assume the Loc2 is the country for international players not caught by special cases\n",
    "\n",
    "    return row\n",
    "\n",
    "# Apply normalization and assignments\n",
    "location_df = location_df.apply(normalize_location_data, us_states=us_states, canada_provinces=canada_provinces, axis=1)\n",
    "\n",
    "# Drop the intermediate column as it's no longer needed\n",
    "location_df.drop(columns='State_Province_Country', inplace=True)\n",
    "\n",
    "# Clean up the DataFrame to ensure all strings are stripped of leading/trailing whitespace\n",
    "location_df = location_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Preview the cleaned and updated location data\n",
    "location_df[['Player', 'City', 'State/Province', 'Country']].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_roster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many entries in the Hometown COlumn has 1 comma, how many have 2 commas, do any have 3 commas or 0?\n",
    "## We are looking for the format of City, State/Province, Country\n",
    "\n",
    "## Split the Hometown Column into City, State/Province, Country\n",
    "all_time_roster_df['Hometown'].str.split(',').str.len().value_counts()\n",
    "\n",
    "# Split the Hometown Column into City, State/Province, Country\n",
    "all_time_roster_df[['City', 'State/Province', 'Country']] = all_time_roster_df['Hometown'].str.split(',', expand=True)\n",
    "\n",
    "# Remove leading and trailing white spaces\n",
    "all_time_roster_df['City'] = all_time_roster_df['City'].str.strip()\n",
    "all_time_roster_df['State/Province'] = all_time_roster_df['State/Province'].str.strip()\n",
    "all_time_roster_df['Country'] = all_time_roster_df['Country'].str.strip()\n",
    "\n",
    "# Look at the unique values in the State/Province Column\n",
    "all_time_roster_df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sperate and clean Hometown column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from Player_per_capita.ipynb\n",
    "\n",
    "# Rename roster df to use in this legacy code\n",
    "full_tourney_roster = all_time_roster_df\n",
    "# full_tourney_roster[['Loc2', 'Loc2', 'Loc3']] = full_tourney_roster['Hometown'].str.split(',', expand=True)\n",
    "\n",
    "# Split the Hometown column at the commas into 2 or 3 columns\n",
    "# full_tourney_roster[['Loc1', 'Loc2']] = full_tourney_roster['Hometown'].str.split(',', expand=True)\n",
    "\n",
    "# If the Loc2 column is is 'Alaska' add a period to the end of the Loc2 column\n",
    "full_tourney_roster['Loc2'] = full_tourney_roster['Loc2'].apply(lambda x: x + '.' if x == 'Alaska' else x)\n",
    "# Same with Ohio, Iowa, Maine\n",
    "full_tourney_roster['Loc2'] = full_tourney_roster['Loc2'].apply(lambda x: x + '.' if x in ['Ohio', 'Iowa', 'Maine', 'Utah', 'Texas'] else x)\n",
    "\n",
    "# Same for canada provinces with NB, NWT and YT\n",
    "full_tourney_roster['Loc2'] = full_tourney_roster['Loc2'].apply(lambda x: x + '.' if x in ['NB', 'NWT', 'YT'] else x)\n",
    "\n",
    "# If Loc2 does not have a . it is a country and should be moved to a new Country Column, Loc2 COlumn should be cleared\n",
    "full_tourney_roster['Country'] = full_tourney_roster['Loc2'].apply(lambda x: x if isinstance(x, str) and '.' not in x else None)\n",
    "\n",
    "# replace Loc2 columns without '.' with an empty string\n",
    "full_tourney_roster['Loc2'] = full_tourney_roster['Loc2'].apply(lambda x: '' if isinstance(x, str) and '.' not in x else x)\n",
    "\n",
    "\n",
    "\n",
    "# Country Value Count\n",
    "full_tourney_roster['Country'].value_counts()\n",
    "\n",
    "# Apply the substitution dictionary to the Loc2 column - add countries to the Country column while doing the substitution\n",
    "def assign_country_and_loc(row):\n",
    "    # Check if the Loc2 value is in the canada_provinces dictionary\n",
    "    if row['Loc2'] in canada_provinces:\n",
    "        # Replace the Loc2 value\n",
    "        row['Loc2'] = canada_provinces[row['Loc2']]\n",
    "        # Assign 'Canada' to the Country column\n",
    "        row['Country'] = 'Canada'\n",
    "    # Check if the Loc2 value is in the us_states dictionary\n",
    "    elif row['Loc2'] in us_states:\n",
    "        # Replace the Loc2 value\n",
    "        row['Loc2'] = us_states[row['Loc2']]\n",
    "        # Assign 'USA' to the Country column\n",
    "        row['Country'] = 'USA'\n",
    "    # If the Loc2 value is not in either dictionary, do not change the Country value\n",
    "    return row\n",
    "\n",
    "# Strip the City, State, and COuntry column of any leading or trailing whitespace\n",
    "full_tourney_roster['Loc1'] = full_tourney_roster['Loc1'].str.strip()\n",
    "full_tourney_roster['Loc2'] = full_tourney_roster['Loc2'].str.strip()\n",
    "\n",
    "\n",
    "# Apply the function to each row\n",
    "full_tourney_roster = full_tourney_roster.apply(assign_country_and_loc, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# full_tourney_roster.sample(20)\n",
    "\n",
    "full_tourney_roster['Loc2'].value_counts()\n",
    "# full_tourney_roster['Country'].value_counts()\n",
    "location_df = full_tourney_roster[['Team', 'Player', 'Position', 'Loc1', 'Loc2', 'Country']]\n",
    "# Rename Loc1 and Loc2 to City and State/Province\n",
    "location_df = location_df.rename(columns={'Loc1': 'City', 'Loc2': 'State/Province'})\n",
    "# Strip the City, State, and COuntry column of any leading or trailing whitespace\n",
    "location_df['City'] = location_df['City'].str.strip()\n",
    "location_df['State/Province'] = location_df['State/Province'].str.strip()\n",
    "location_df['Country'] = location_df['Country'].str.strip()\n",
    "\n",
    "# If the State/Province is Alaska. set it to Alaska\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Alaska' if x == 'Alaska.' else x)\n",
    "# Add USA to the Country column for Alaska\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Alaska' else x['Country'], axis=1)\n",
    "# Same for Iowa and Ohio and Utah and Texas\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Texas' if x == 'Texas.' else x)\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Texas' else x['Country'], axis=1)\n",
    "\n",
    "\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Utah' if x == 'Utah.' else x)\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Utah' else x['Country'], axis=1)\n",
    "\n",
    "\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Idaho' if x == 'Idaho.' else x)\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Idaho' else x['Country'], axis=1)\n",
    "\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Iowa' if x == 'Iowa.' else x)\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Iowa' else x['Country'], axis=1)\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Ohio' if x == 'Ohio.' else x)\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Ohio' else x['Country'], axis=1)\n",
    "# Same for Maine\n",
    "location_df['State/Province'] = location_df['State/Province'].apply(lambda x: 'Maine' if x == 'Maine.' else x)\n",
    "location_df['Country'] = location_df.apply(lambda x: 'USA' if x['State/Province'] == 'Maine' else x['Country'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "location_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
